{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ff254a8b40322fa7b626fd05176b333fb787fc2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from pandas.io.parsers import read_csv\nfrom sklearn.utils import shuffle\n\nFTRAIN = '../input/training/training.csv'\nFTEST = '../input/test/test.csv'\n\n\ndef load(test=False, cols=None):\n    \"\"\"Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n    Pass a list of *cols* if you're only interested in a subset of the\n    target columns.\n    \"\"\"\n    fname = FTEST if test else FTRAIN\n    df = read_csv(os.path.expanduser(fname))  # load pandas dataframe\n\n    # The Image column has pixel values separated by space; convert\n    # the values to numpy arrays:\n    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n\n    if cols:  # get a subset of columns\n        df = df[list(cols) + ['Image']]\n\n    print(df.count())  # prints the number of values for each column\n    df = df.dropna()  # drop all rows that have missing values in them\n\n    X = np.vstack(df['Image'].values) / 255.  # scale pixel values to [0, 1]\n    X = X.astype(np.float32)\n\n    if not test:  # only FTRAIN has any target columns\n        y = df[df.columns[:-1]].values\n        y = (y - 48) / 48  # scale target coordinates to [-1, 1]\n        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n        y = y.astype(np.float32)\n    else:\n        y = None\n\n    return X, y\n\n\nX, y = load()\nprint(\"X.shape == {}; X.min == {:.3f}; X.max == {:.3f}\".format(\n    X.shape, X.min(), X.max()))\nprint(\"y.shape == {}; y.min == {:.3f}; y.max == {:.3f}\".format(\n    y.shape, y.min(), y.max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b77ac552e001cb777c0d9e2710ddfdd9275a0335"},"cell_type":"code","source":"#  I changed the X dimension structure to have (Nsample, Nrows in frame, N columns in frame, 1) in load2d.\ndef load2d(test=False,cols=None):\n\n    re = load(test, cols)\n    \n    X = re[0].reshape(-1,96,96,1)\n    y = re[1]\n\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ae930d7cf28102a71542d7dd89368d6ab3575ab"},"cell_type":"markdown","source":"## Benchmark models"},{"metadata":{"_uuid":"19048eeed4ca44b48bbc51e93fbfe4957e193e24"},"cell_type":"markdown","source":"## A Fully connected model"},{"metadata":{"trusted":true,"_uuid":"9099b5ace142b2dea77acc28eb43e680254c682f"},"cell_type":"code","source":"%%time\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.layers import Dropout\n\nmodel = Sequential()\nmodel.add(Dense(128,input_dim=X.shape[1]))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dense(30))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30f08683f85145c34ac23d1e16c875c1dde11842"},"cell_type":"code","source":"sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\nmodel.compile(loss='mean_squared_error', optimizer=sgd)\n\nhist = model.fit(X, y, nb_epoch=50,batch_size=128, validation_split=0.2,verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a4b208465c23bbccf52cc9e27201640461fca43"},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef plot_loss(hist,name,plt,RMSE_TF=False):\n    '''\n    RMSE_TF: if True, then RMSE is plotted with original scale \n    '''\n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    if RMSE_TF:\n        loss = np.sqrt(np.array(loss))*48 \n        val_loss = np.sqrt(np.array(val_loss))*48 \n        \n    plt.plot(loss,\"--\",linewidth=3,label=\"train:\"+name)\n    plt.plot(val_loss,linewidth=3,label=\"val:\"+name)\n\nplot_loss(hist.history,\"model 1\",plt)\nplt.legend()\nplt.grid()\nplt.yscale(\"log\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"log loss\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b007544f16a451f091a6497cdc5e33ae28d4108f"},"cell_type":"code","source":"X_test, _ = load(test=True)\ny_test = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13bd824178c64ce0ffde24f24e46125334f227e1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c21b78af01f721dfd11ec4963ced7d5088e6aa7a"},"cell_type":"code","source":"#converting the images back to 96*96 pixels so i can check the performance of my model on the image dataset\n\ndef plot_sample(x, y, axis):\n    img = x.reshape(96, 96)\n    axis.imshow(img, cmap='gray')\n    axis.scatter(y[0::2] * 48 + 48, y[1::2] * 48 + 48, marker='x', s=10)\n\n\nfig = plt.figure(figsize=(10, 7))\nfig.subplots_adjust(\n    left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n\nfor i in range(16):\n    axis = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n    plot_sample(X_test[i], y_test[i], axis)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2917366bc546c358fd32f541761a2b102c0ab32b"},"cell_type":"code","source":"from keras.models import load_model\n# import h5py\nmodel.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n# del model  # deletes the existing model\n\n# # returns a compiled model\n# # identical to the previous one\nmodel = load_model('my_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b30c7368b03a6965651782001d1f6974d353d049"},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7af87709e569f3c832359a6d20f83c6c1918b674"},"cell_type":"code","source":"# #Deleting these as i will use a new structure\n\n# del X, y, X_test, y_test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc611acfe36a3c982d8b363956e84f12baf9ca1b"},"cell_type":"markdown","source":"## Convolutional Neural Network"},{"metadata":{"trusted":true,"_uuid":"ecfb1fd2a83dda444770193197354624176896c4"},"cell_type":"code","source":"X,y = load2d()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ae782e020aa0bbdafee73a19e1ab3a6f5cea546"},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ec71f97278c023a60c5d1dd582a69002baed5cf"},"cell_type":"code","source":"from keras.layers import MaxPooling2D, Conv2D , Flatten, Dropout\nfrom keras.layers.normalization import BatchNormalization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e6bf33c30dc8c426f1bfaa0ea846dd6ae0f2fc9"},"cell_type":"code","source":"def CNN():\n    model2 = Sequential()\n\n    model2.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(96,96,1)))\n    model2.add(Dropout(0.1))\n    model2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode=\"valid\"))\n    model2.add(BatchNormalization())\n\n    model2.add(Conv2D(32, 5, 5,activation=\"relu\"))\n    # model.add(Activation(\"relu\"))\n    model2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode=\"valid\"))\n    model2.add(Dropout(0.2))\n    model2.add(BatchNormalization())\n\n    model2.add(Conv2D(64, 5, 5,activation=\"relu\"))\n    # model.add(Activation(\"relu\"))\n    model2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode=\"valid\"))\n    model2.add(BatchNormalization())\n\n    model2.add(Conv2D(128, 3, 3,activation=\"relu\"))\n    # model.add(Activation(\"relu\"))\n    model2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode=\"valid\"))\n    model2.add(Dropout(0.4))\n    model2.add(BatchNormalization())\n\n    model2.add(Flatten())\n\n    model2.add(Dense(500, activation=\"relu\"))\n    model2.add(Dropout(0.1))\n\n    model2.add(Dense(128, activation=\"relu\"))\n    model2.add(Dropout(0.1))\n\n    model2.add(Dense(30))\n\n\n    model2.summary()\n    model2.compile(optimizer='adam', \n              loss='mse',\n              metrics=['mae','accuracy'])\n    return(model2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c29683a38bb999ee1154651a04de1d0598cadb23"},"cell_type":"code","source":"model2 = CNN()\nhist2 = model2.fit(X, y, nb_epoch=500,batch_size=128, validation_split=0.2,verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b61d7f4b6c677a543669ddfbdfe46deba12210a"},"cell_type":"code","source":"# print(hist2.history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1382606a3900f6e1211e1893f37da9043d6541b8"},"cell_type":"code","source":"# hist2.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1f757b6c62579448b3bf9993f73ae14ed6a6b89","scrolled":true},"cell_type":"code","source":"# Comparing model1 and model2\nplt.figure(figsize=(4,4))\nplot_loss(hist.history,\"model 1\",plt)\nplt.legend()\nplt.grid()\nplt.yscale(\"log\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.show()\n\nplot_loss(hist2.history,\"model 2\",plt)\nplt.legend()\nplt.grid()\nplt.yscale(\"log\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cc846f31a0d8110bbab89c152f6539519c392b5"},"cell_type":"code","source":"sample1,_ = load(test=True)\nsample2,_ = load2d(test=True)\ny_pred1 = model.predict(sample1)\ny_pred2 = model2.predict(sample2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f530670cf498fbaf8c65aad371775a5d83b90f3","scrolled":true},"cell_type":"code","source":"#Comparing model1 and model2 on images\n\nfig = plt.figure(figsize=(10,10))\nfig.subplots_adjust(hspace=0.001,wspace=0.001,\n                    left=0,right=1,bottom=0, top=1)\nNpicture = 5\ncount = 1\nfor irow in range(Npicture):\n    ipic = np.random.choice(sample2.shape[0])\n    ax = fig.add_subplot(Npicture, 2, count,xticks=[],yticks=[])        \n    plot_sample(sample1[ipic],y_pred1[ipic],ax)\n    if count < 3:\n        ax.set_title(\"model 1\")\n        \n    count += 1\n    ax = fig.add_subplot(Npicture, 2, count,xticks=[],yticks=[])  \n    plot_sample(sample2[ipic],y_pred2[ipic],ax)\n    if count < 3:\n        ax.set_title(\"model 2\")\n    count += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61561d96d3bf8ef9e8236ae6fab21782924e4617"},"cell_type":"code","source":"model2.save('my_model2.h5')  # creates a HDF5 file 'my_model.h5'\n# del model  # deletes the existing model\n\n# # returns a compiled model\n# # identical to the previous one\nmodel2 = load_model('my_model2.h5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f147f649dc4f45373739fbd8d03e1b952f9e5162"},"cell_type":"markdown","source":"## Using Image Augmentation\n\n### Image Flipping\n\nUsing augmentation to flip the images but to flip the image i also have to flip the data points:\nLike :\nleft_eye_centre_x       --> right_eye_centre_x,\nleft_eye_center_y       --> right_eye_center_y,\nleft_eye_inner_corner_x --> right_eye_inner_corner_x\n\nBut nose_tip will remain same.\nSo i will flip the remaining data points"},{"metadata":{"trusted":true,"_uuid":"3cd8b5d5b27418c099e9a97ee2593d1c3d553661"},"cell_type":"code","source":"# from keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n#     samplewise_center=False,\n#     featurewise_std_normalization=False,\n#     samplewise_std_normalization=False,\n#     zca_whitening=False,\n#     rotation_range=0.,\n#     width_shift_range=0.,\n#     height_shift_range=0.,\n#     shear_range=0.,\n#     zoom_range=0.,\n#     channel_shift_range=0.,\n#     fill_mode='nearest',\n#     cval=0.,\n#     horizontal_flip=False,\n#     vertical_flip=False,\n#     dim_ordering='th')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1319b1f6b2284db735f2bd16fa5796e267e224fd"},"cell_type":"code","source":"## Using ImageDataGenerator to flip the images and flip indices will be used to manually flipping\n## the keypoints on the face\n\nfrom keras.preprocessing.image import ImageDataGenerator\nclass FlippedImageDataGenerator(ImageDataGenerator):\n    flip_indices = [\n        (0, 2), (1, 3),\n        (4, 8), (5, 9), (6, 10), (7, 11),\n        (12, 16), (13, 17), (14, 18), (15, 19),\n        (22, 24), (23, 25),\n        ]\n\n    def next(self):\n        X_batch, y_batch = super(FlippedImageDataGenerator, self).next()\n        batch_size = X_batch.shape[0]\n        indices = np.random.choice(batch_size, batch_size/2, replace=False)\n        X_batch[indices] = X_batch[indices, :, :, ::-1]\n\n        if y_batch is not None:\n            \n            y_batch[indices, ::2] = y_batch[indices, ::2] * -1\n\n            # left_eye_center_x -> right_eye_center_x のようにフリップ\n            for a, b in self.flip_indices:\n                y_batch[indices, a], y_batch[indices, b] = (\n                    y_batch[indices, b], y_batch[indices, a]\n                )\n\n        return X_batch, y_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf4f3ceb47869cbeadb5b6494d1e7435f465923c"},"cell_type":"code","source":"## splitting the data\nfrom sklearn.model_selection import train_test_split\n\nX, y = load2d()\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"970fd2704d396e48aea80ccbc8dc2231035909a3"},"cell_type":"code","source":"model3 = CNN()\nflipgen = FlippedImageDataGenerator()\nhist3 = model3.fit_generator(flipgen.flow(X_train, y_train),\n                             samples_per_epoch=X_train.shape[0],\n                             nb_epoch=300,\n                             validation_data=(X_val, y_val))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afecccf0402890f3bb1eaecdbe282ba809a348b1"},"cell_type":"code","source":"## Comparing mode1, model2 and model3 using pyplot\nplt.figure(figsize=(8,8))\nplot_loss(hist.history,\"model 1\",plt)\nplt.legend()\nplt.grid()\nplt.yscale(\"log\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.show()\n\nplot_loss(hist2.history,\"model 2\",plt)\nplt.legend()\nplt.grid()\nplt.yscale(\"log\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.show()\n\nplot_loss(hist3.history,\"model 3\",plt)\nplt.legend()\nplt.grid()\nplt.yscale(\"log\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce4cc9bbe0c09bc03b826f920e2aa0108586b45e"},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bbea635f63ca4c8398f6805ad1770eddf15913b"},"cell_type":"code","source":"model3.save('my_model3.h5')  # creates a HDF5 file 'my_model.h5'\n# del model  # deletes the existing model\n\n# # returns a compiled model\n# # identical to the previous one\nmodel3 = load_model('my_model3.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cdc34d268da7f303b0d8dcf645feaac9e0c886d"},"cell_type":"markdown","source":"## Specialist Setting\n\n### I have divided my dataset into 6 different groups.\n### I will train my model on each of these 6 groups separately.\n### All 6 models contains the same CNN architecture but the final output layer is adjusted for different number of outputs: for example we have a model for left eye and right eye center landmark prediction. As there are x and y coordinates for both eye centers, we have 4 nodes in the output layer of this model.\n"},{"metadata":{"trusted":true,"_uuid":"405f74e3944b9320a66c9e8038120096f42330fc"},"cell_type":"code","source":"SPECIALIST_SETTINGS = [\n    dict(\n        columns=(\n            'left_eye_center_x', 'left_eye_center_y',\n            'right_eye_center_x', 'right_eye_center_y',\n            ),\n        flip_indices=((0, 2), (1, 3)),\n        ),\n\n    dict(\n        columns=(\n            'nose_tip_x', 'nose_tip_y',\n            ),\n        flip_indices=(),\n        ),\n\n    dict(\n        columns=(\n            'mouth_left_corner_x', 'mouth_left_corner_y',\n            'mouth_right_corner_x', 'mouth_right_corner_y',\n            'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n            ),\n        flip_indices=((0, 2), (1, 3)),\n        ),\n\n    dict(\n        columns=(\n            'mouth_center_bottom_lip_x',\n            'mouth_center_bottom_lip_y',\n            ),\n        flip_indices=(),\n        ),\n\n    dict(\n        columns=(\n            'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n            'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n            'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n            'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n            ),\n        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n        ),\n\n    dict(\n        columns=(\n            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n            ),\n        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n        ),\n    ]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7e1be2493686181e89e13cce412734f64fa993b"},"cell_type":"markdown","source":"## Training special model with model3"},{"metadata":{"trusted":true,"_uuid":"d24871ae59bab25165bec9f11c752282ea05504d"},"cell_type":"code","source":"from collections import OrderedDict\n\ndef fit_specialists(freeze=True,\n                    print_every=10,\n                    epochs=100,\n                    prop=0.1,\n                    name_transfer_model=\"my_model3.h5\"):\n    specialists = OrderedDict()\n \n\n    for setting in SPECIALIST_SETTINGS:\n        \n        cols = setting['columns']\n        flip_indices = setting['flip_indices']\n        \n        X, y = load2d(cols=cols)\n        X_train, X_val, y_train, y_val = train_test_split(X, y, \n                                                          test_size=0.2, \n                                                          random_state=42)\n        model4 = load_model(name_transfer_model) \n        if freeze:\n            for layer in model.layers:\n                layer.trainable = False\n            \n        model4.layers.pop() # get rid of output layer\n        model4.outputs = [model4.layers[-1].output]\n        model4.layers[-1].outbound_nodes = []\n        model4.add(Dense(len(cols))) # add new output layer\n\n        model4.compile(loss='mean_squared_error', optimizer=\"adam\")\n        \n        flipgen = FlippedImageDataGenerator()\n        flipgen.flip_indices = setting['flip_indices']\n        print(X_train.shape)\n        print(y_train.shape)\n        print(X_val.shape)\n        print(y_val.shape)\n        hist_final = model4.fit_generator(flipgen.flow(X_train, y_train),\n                                     samples_per_epoch=X_train.shape[0],\n                                     nb_epoch=epochs,\n                                     validation_data=(X_val, y_val))\n        \n        ## print(model.summary()) \n        \n       \n        specialists[cols] = model4\n    return(specialists)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8199f34bd5fa4b73deffb5e636ad0e56eda3c9be"},"cell_type":"code","source":"%%time\nspecialists1 = fit_specialists(freeze=True,\n                    print_every=10,\n                    epochs=100,\n                    name_transfer_model=\"my_model3.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56ad2a119c799b54b90cbea8531d229af097d755"},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99ab5552cbcdb2eafebee371eae45702faa7d05d"},"cell_type":"code","source":"type(specialists1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed0bc41ced269eb00fb481f1215dbde95bd1bb17"},"cell_type":"code","source":"from pandas import DataFrame, concat\n\nX_test,_ = load2d(test=True)\n\n## prediction with model 3\ny_pred3 = model3.predict(X_test)\nlandmark_nm = read_csv(os.path.expanduser(FTRAIN)).columns[:-1].values\ndf_y_pred3 = DataFrame(y_pred3,columns = landmark_nm)\n\n## prediction with specialist model\ndef predict_specialist(specialists1,X_test):\n    y_pred_s = []\n    for columns, value in specialists1.items():\n        smodel = value\n\n        y_pred = smodel.predict(X_test)\n        y_pred = DataFrame(y_pred,columns=columns)\n        y_pred_s.append(y_pred)\n\n    df_y_pred_s = concat(y_pred_s,axis=1)\n    return(df_y_pred_s)\ndf_y_pred_s = predict_specialist(specialists1,X_test)\ny_pred_s = df_y_pred_s.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e43ddb5c469fe35d7a5be3c6d5befea96df62fba"},"cell_type":"markdown","source":"## Creating submission files for both the models"},{"metadata":{"trusted":true,"_uuid":"6d3c66147aada91b3acc42a1f3a60ecce3bae2a3"},"cell_type":"code","source":"FIdLookup = '../input/IdLookupTable.csv'\n\nIdLookup = read_csv(os.path.expanduser(FIdLookup))\n\ndef prepare_submission(y_pred4,filename):\n    '''\n    save a .csv file that can be submitted to kaggle\n    '''\n    ImageId = IdLookup[\"ImageId\"]\n    FeatureName = IdLookup[\"FeatureName\"]\n    RowId = IdLookup[\"RowId\"]\n    \n    submit = []\n    for rowId,irow,landmark in zip(RowId,ImageId,FeatureName):\n        submit.append([rowId,y_pred4[landmark].iloc[irow-1]])\n    \n    submit = DataFrame(submit,columns=[\"RowId\",\"Location\"])\n    ## adjust the scale \n    submit[\"Location\"] = submit[\"Location\"]*48 + 48\n    print(submit.shape)\n#     loc = \"result/\" + filename + \".csv\"\n    if filename == \"model3\":\n       submit.to_csv(\"model3.csv\",index=False) \n    else:\n        submit.to_csv(\"special.csv\",index=False)\n    \n#     print(\"File is saved at:\" +  loc)\n\nprepare_submission(df_y_pred_s,\"special\")    \nprepare_submission(df_y_pred3,\"model3\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f7eeda4dfc858bcafd093981023282d1f9e3557"},"cell_type":"code","source":"# sample3,_ = load2d(test=True)\n# sample_special,_ = load2d(test=True)\n\n# y_pred3 = model3.predict(X_test)\n\n# def predict_specialist_case(specialists1,X_test):\n#     for columns, value in specialists1.items():\n#         smodel = value\n\n#         y_pred_sample = smodel.predict(X_test)\n#         return y_pred_sample\n\n# y_pred_sample = predict_specialist_case(specialists1,X_test)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7074bd2979ebda68e1097fd42c3e0e36c3d8014","scrolled":true},"cell_type":"code","source":"# fig = plt.figure(figsize=(12, 20))\n# fig.subplots_adjust(hspace=0.001,wspace=0.001,\n#                     left=0,right=1,bottom=0, top=1)\n# Npicture = 7\n# count = 1\n# for irow in range(Npicture):\n#     ipic = np.random.choice(X_test.shape[0])\n#     ax = fig.add_subplot(Npicture, 2, count,xticks=[],yticks=[])        \n#     plot_sample(X_test[ipic],y_pred3[ipic],ax)\n#     if count < 3:\n#         ax.set_title(\"model 3\")\n        \n#     count += 1\n#     ax = fig.add_subplot(Npicture, 2, count,xticks=[],yticks=[])  \n#     plot_sample(X_test[ipic],y_pred_sample[ipic],ax)\n#     if count < 3:\n#         ax.set_title(\"special model\")\n#     count += 1\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"825e9e8838ac9271432120f6564d1ad817527695"},"cell_type":"code","source":"df_y_pred_s = df_y_pred_s[df_y_pred3.columns]\ndf_compare = {}\ndf_compare[\"difference\"] = ((df_y_pred_s - df_y_pred3)**2).mean(axis=1)\ndf_compare[\"RowId\"] = range(df_y_pred_s.shape[0])\ndf_compare = DataFrame(df_compare)\ndf_compare = df_compare.sort_values(\"difference\",ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0ce3554e164babfdc436431407f5034af495c4c"},"cell_type":"code","source":"fig = plt.figure(figsize=(12,35))\n\nNsample = 13\npic_index = df_compare[\"RowId\"].iloc[:Nsample].values\npic_index_good = df_compare[\"RowId\"].iloc[-Nsample:].values\ncount = 1\n\n\nfor ipic_g,ipic in zip(pic_index_good,pic_index):\n    ## good model 3\n    ax = fig.add_subplot(Nsample,4,count,xticks=[],yticks=[])\n    count += 1\n    plot_sample(X_test[ipic_g],y_pred3[ipic_g],ax)\n    ax.set_title(\"Good:model3:pic\"+str(ipic_g))\n    \n    ## good special\n    ax = fig.add_subplot(Nsample,4,count,xticks=[],yticks=[])\n    count += 1\n    plot_sample(X_test[ipic_g],y_pred_s[ipic_g],ax)\n    ax.set_title(\"Good:special:pic\"+str(ipic_g))\n    \n    ## bad model 3\n    ax = fig.add_subplot(Nsample,4,count,xticks=[],yticks=[])\n    count += 1\n    plot_sample(X_test[ipic],y_pred3[ipic],ax)\n    ax.set_title(\"Bad:model3:pic\"+str(ipic))\n    \n    ## bad special\n    ax = fig.add_subplot(Nsample,4,count,xticks=[],yticks=[])\n    count += 1\n    plot_sample(X_test[ipic],y_pred_s[ipic],ax)\n    ax.set_title(\"Bad:special:pic\"+str(ipic))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7508d5b664f98c2aa0ffa813b60e8f07104c4b52"},"cell_type":"markdown","source":"## Training special model with model2"},{"metadata":{"trusted":true,"_uuid":"bbe0efe0b113816788934e032a46ad85839b9e42"},"cell_type":"code","source":"def fit_specialists(freeze=True,\n                    print_every=10,\n                    epochs=100,\n                    prop=0.1,\n                    name_transfer_model=\"my_model2.h5\"):\n    specialists = OrderedDict()\n \n\n    for setting in SPECIALIST_SETTINGS:\n        \n        cols = setting['columns']\n        flip_indices = setting['flip_indices']\n        \n        X, y = load2d(cols=cols)\n        X_train, X_val, y_train, y_val = train_test_split(X, y, \n                                                          test_size=0.2, \n                                                          random_state=42)\n        model4 = load_model(name_transfer_model) \n        if freeze:\n            for layer in model.layers:\n                layer.trainable = False\n            \n        model4.layers.pop() # get rid of output layer\n        model4.outputs = [model4.layers[-1].output]\n        model4.layers[-1].outbound_nodes = []\n        model4.add(Dense(len(cols))) # add new output layer\n\n        model4.compile(loss='mean_squared_error', optimizer=\"adam\")\n        \n        flipgen = FlippedImageDataGenerator()\n        flipgen.flip_indices = setting['flip_indices']\n        \n        print(X_train.shape)\n        print(y_train.shape)\n        print(X_val.shape)\n        print(y_val.shape)\n        \n        hist_final = model4.fit_generator(flipgen.flow(X_train, y_train),\n                                     samples_per_epoch=X_train.shape[0],\n                                     nb_epoch=epochs,\n                                     validation_data=(X_val, y_val))\n        \n        \n       \n        specialists[cols] = model4\n    return(specialists)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c6686c6a8967e95f82e9548d204ed41d96e4cbe"},"cell_type":"code","source":"%%time\nspecialists2 = fit_specialists(freeze=True,\n                    print_every=10,\n                    epochs=100,\n                    name_transfer_model=\"my_model2.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d4f38f11218cc3b0eb41310c3133c61161a62df"},"cell_type":"code","source":"X_test,_ = load2d(test=True)\n\ndef predict_specialist(specialists2,X_test):\n    y_pred_s = []\n    for columns, value in specialists2.items():\n        smodel = value\n\n        y_pred = smodel.predict(X_test)\n        y_pred = DataFrame(y_pred,columns=columns)\n        y_pred_s.append(y_pred)\n\n    df_y_pred_s = concat(y_pred_s,axis=1)\n    return(df_y_pred_s)\ndf_y_pred_s = predict_specialist(specialists2,X_test)\ny_pred_s = df_y_pred_s.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11dedde49f03a32bf1e789c19fcd41c4ee3d8b05"},"cell_type":"code","source":"## prediction with model 2\ny_pred2 = model2.predict(X_test)\nlandmark_nm = read_csv(os.path.expanduser(FTRAIN)).columns[:-1].values\ndf_y_pred2 = DataFrame(y_pred2,columns = landmark_nm)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfa1e0a867ae2f22a7be2f32c62c1902f0274570"},"cell_type":"markdown","source":"## Creating submission files for both the models"},{"metadata":{"trusted":true,"_uuid":"be67d07e8aecd02a930bce5ee926ba83baca1576"},"cell_type":"code","source":"FIdLookup = '../input/IdLookupTable.csv'\n\nIdLookup = read_csv(os.path.expanduser(FIdLookup))\n\ndef prepare_submission(y_pred2,filename):\n    '''\n    save a .csv file that can be submitted to kaggle\n    '''\n    ImageId = IdLookup[\"ImageId\"]\n    FeatureName = IdLookup[\"FeatureName\"]\n    RowId = IdLookup[\"RowId\"]\n    \n    submit = []\n    for rowId,irow,landmark in zip(RowId,ImageId,FeatureName):\n        submit.append([rowId,y_pred2[landmark].iloc[irow-1]])\n    \n    submit = DataFrame(submit,columns=[\"RowId\",\"Location\"])\n    ## adjust the scale \n    submit[\"Location\"] = submit[\"Location\"]*48 + 48\n    print(submit.shape)\n\n    if filename == \"model2\":\n        submit.to_csv(\"model2.csv\",index=False) \n    else:\n        submit.to_csv(\"special_model2.csv\",index=False)\n    \n\nprepare_submission(df_y_pred_s,\"special_model2\")    \nprepare_submission(df_y_pred2,\"model2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f9d7bfbe35d287e8ca0e4a4bc6bc6b86e9743eb"},"cell_type":"code","source":"df_y_pred_s = df_y_pred_s[df_y_pred3.columns]\ndf_compare = {}\ndf_compare[\"difference\"] = ((df_y_pred_s - df_y_pred2)**2).mean(axis=1)\ndf_compare[\"RowId\"] = range(df_y_pred_s.shape[0])\ndf_compare = DataFrame(df_compare)\ndf_compare = df_compare.sort_values(\"difference\",ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b573e218769393e30ac16f8eadd1b5136521b50"},"cell_type":"code","source":"fig = plt.figure(figsize=(12,35))\n\nNsample = 13\npic_index = df_compare[\"RowId\"].iloc[:Nsample].values\npic_index_good = df_compare[\"RowId\"].iloc[-Nsample:].values\ncount = 1\n\n\nfor ipic_g,ipic in zip(pic_index_good,pic_index):\n    ## good model 2\n    ax = fig.add_subplot(Nsample,4,count,xticks=[],yticks=[])\n    count += 1\n    plot_sample(X_test[ipic_g],y_pred2[ipic_g],ax)\n    ax.set_title(\"Good:model2:pic\"+str(ipic_g))\n    \n    ## good special\n    ax = fig.add_subplot(Nsample,4,count,xticks=[],yticks=[])\n    count += 1\n    plot_sample(X_test[ipic_g],y_pred_s[ipic_g],ax)\n    ax.set_title(\"Good:special:pic\"+str(ipic_g))\n    \n    ## bad model 2\n    ax = fig.add_subplot(Nsample,4,count,xticks=[],yticks=[])\n    count += 1\n    plot_sample(X_test[ipic],y_pred2[ipic],ax)\n    ax.set_title(\"Bad:model2:pic\"+str(ipic))\n    \n    ## bad special\n    ax = fig.add_subplot(Nsample,4,count,xticks=[],yticks=[])\n    count += 1\n    plot_sample(X_test[ipic],y_pred_s[ipic],ax)\n    ax.set_title(\"Bad:special:pic\"+str(ipic))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20403cee503c369eb74787013d63a76e5ec9438e"},"cell_type":"code","source":"# def fit_specialists(freeze=True,\n#                     print_every=10,\n#                     epochs=100,\n#                     prop=0.1,\n#                     name_transfer_model=\"my_model.h5\"):\n#     specialists = OrderedDict()\n \n\n#     for setting in SPECIALIST_SETTINGS:\n        \n#         cols = setting['columns']\n#         flip_indices = setting['flip_indices']\n        \n#         X, y = load2d(cols=cols)\n# #         X.reshape(7049, 96, 96, 1)\n#         X_train, X_val, y_train, y_val = train_test_split(X, y, \n#                                                           test_size=0.2, \n#                                                           random_state=42)\n# #         X_val = np.expand_dims(X_val, axis=0)\n#         model4 = load_model(name_transfer_model) \n#         if freeze:\n#             for layer in model.layers:\n#                 layer.trainable = False\n            \n#         model4.layers.pop() # get rid of output layer\n#         model4.outputs = [model4.layers[-1].output]\n#         model4.layers[-1].outbound_nodes = []\n#         model4.add(Dense(len(cols))) # add new output layer\n\n#         model4.compile(loss='mean_squared_error', optimizer=\"adam\")\n        \n#         flipgen = FlippedImageDataGenerator()\n#         flipgen.flip_indices = setting['flip_indices']\n# #         print(y_val.shape)\n# # #         X_val.reshape(1407,9216)\n# # #         y_val.reshape()\n# #         print(X_train.shape)\n#         print(X_train.shape)\n#         print(y_train.shape)\n#         print(X_val.shape)\n#         print(y_val.shape)\n#         X_train.reshape(5626,9216)\n#         X_val.reshape(1407,9216)\n#         hist_final = model4.fit_generator(flipgen.flow(X_train, y_train),\n#                                      samples_per_epoch=X_train.shape[0],\n#                                      nb_epoch=epochs,\n#                                      validation_data=(X_val, y_val))\n    \n       \n#         specialists[cols] = model4\n#     return(specialists)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f99f79daba3e89c6376fe34638db5d13b0067a51"},"cell_type":"code","source":"# %%time\n# specialists3 = fit_specialists(freeze=True,\n#                     print_every=10,\n#                     epochs=100,\n#                     name_transfer_model=\"my_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70bb42d67df7afb6adab1ec9bc674fdb8e9aca97"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fe4aea54df90db700761bc24b80c3d540c8f147"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
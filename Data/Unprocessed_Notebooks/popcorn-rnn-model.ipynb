{"cells":[{"metadata":{"trusted":true,"_uuid":"54b8f7dc1ba10d7a46e7efc907c22cb17660889e"},"cell_type":"markdown","source":"The key idea of this kernel is mainly from https://github.com/bluelight773/Kaggle_IMDB_Bags_of_Popcorn/blob/master/imdb.py. The purpose is to demo the effectiveness of sequence models in semantic anlaysis and sentiment classification."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom bs4 import BeautifulSoup\nimport pickle\nimport os, re\nprint(os.listdir(\"../input\"))\nfrom nltk.corpus import stopwords\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"053dcdb1ed3f2256398eb114fc246fcc34aaa8cf"},"cell_type":"code","source":"train = pd.read_csv(\"../input/labeledTrainData.tsv\", header = 0, delimiter = '\\t')\ntest = pd.read_csv(\"../input/testData.tsv\", header = 0, delimiter = '\\t')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84dffa97fd0491bca52637ab8620524a0575318e"},"cell_type":"markdown","source":"Extract out the labels from the test data, due to the data leakage issue as pointed in the post https://www.kaggle.com/c/word2vec-nlp-tutorial/discussion/27022 . The label from the test data will be used for evaluation purpose."},{"metadata":{"trusted":true,"_uuid":"5d7f2d3250b2e4c13182065cf1162e82750b6401"},"cell_type":"code","source":"test[\"sentiment\"] = test[\"id\"].map(lambda x: 1 if int(x.strip('\"').split(\"_\")[1]) >= 5 else 0)\ny_test = test[\"sentiment\"]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Define some pre-processing functions"},{"metadata":{"trusted":true,"_uuid":"31de028b5dd4ff71f59e5ed9552e826db5730d18","_kg_hide-input":false},"cell_type":"code","source":"def html_to_text(review):\n    \"\"\"Return extracted text string from provided HTML string.\"\"\"\n    review_text = BeautifulSoup(review, \"lxml\").get_text()\n    if len(review_text) == 0:\n        review_text = review\n    review_text = re.sub(r\"\\<.*\\>\", \"\", review_text)\n    try:\n        review_text = review_text.encode('ascii', 'ignore').decode('ascii')#ignore \\xc3 etc.\n    except UnicodeDecodeError:\n        review_text = review_text.decode(\"ascii\", \"ignore\")\n    return review_text\n\n\ndef letters_only(text):\n    \"\"\"Return input string with only letters (no punctuation, no numbers).\"\"\"\n    # It is probably worth experimenting with milder prepreocessing (eg just removing punctuation)\n    return re.sub(\"[^a-zA-Z]\", \" \", text)\n\ndef rnn_tokenizer_review_preprocess(review):\n    \"\"\"Preprocessing used before fitting/transforming RNN tokenizer - Html->text, remove punctuation/#s, lowercase.\"\"\"\n    return letters_only(html_to_text(review)).lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08b563cc57a7d167b8d3d339766b3e2fa2b2a9bc","_kg_hide-input":false},"cell_type":"code","source":"def get_train_val_data(reviews_to_features_fn=None, df = train):\n    \"\"\"Extracts features (using reviews_to_features_fn), splits into train/test data, and returns\n    x_train, y_train, x_test, y_test.  If no feature extraction function is provided, x_train/x_test will\n    simply consist of a Series of all the reviews.\n    \"\"\"\n#     df = pd.read_csv('labeledTrainData.tsv', header=0, quotechar='\"', sep='\\t')\n    SEED = 1000\n    # Shuffle data frame rows\n    np.random.seed(SEED)\n    df = df.iloc[np.random.permutation(len(df))]\n\n    if reviews_to_features_fn:\n        feature_rows = df[\"review\"].map(reviews_to_features_fn)\n        if type(feature_rows[0]) == np.ndarray:\n            num_instances = len(feature_rows)\n            num_features = len(feature_rows[0])\n            x = np.concatenate(feature_rows.values).reshape((num_instances, num_features))\n        else:\n            x = feature_rows\n    else:\n        x = df[\"review\"]\n\n    y = df[\"sentiment\"]\n\n    # Split 80/20\n    test_start_index = int(df.shape[0] * .8)\n    x_train = x[0:test_start_index]\n    y_train = y[0:test_start_index]\n    x_val = x[test_start_index:]\n    y_val = y[test_start_index:]\n\n    return x_train, y_train, x_val, y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b8a570f1bd8ce43d430223bf0c2ea198f63987e"},"cell_type":"markdown","source":"## Propcessed the data"},{"metadata":{"trusted":true,"_uuid":"a5157a1e02bebed4beba493b320fbe55b86b6d0d"},"cell_type":"code","source":"x_train, y_train, x_val, y_val = get_train_val_data(rnn_tokenizer_review_preprocess)\nx_test = test[\"review\"].map(rnn_tokenizer_review_preprocess)\ny_test = test[\"sentiment\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a25e020f8ef1f4fa2331797db431f03190f4cd94"},"cell_type":"markdown","source":"## Generate the text sequence for RNN model"},{"metadata":{"trusted":true,"_uuid":"1f297e492c8ee5ad668a10a44752b2a8a7662ed5"},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"536dd9544c9c7a65648ff798cf954ee93c799c3b"},"cell_type":"code","source":"np.random.seed(1000)\nnum_most_freq_words_to_include = 5000\nMAX_REVIEW_LENGTH_FOR_KERAS_RNN = 500\nembedding_vector_length = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"958394bdd673d0a6436b312a6ae2608a74392be5"},"cell_type":"code","source":"# train_review_list = [s.encode('ascii') for s in x_train.tolist()]\n# val_review_list = [s.encode('ascii') for s in x_val.tolist()]\n# all_review_list = train_review_list + val_review_list\ntrain_review_list = x_train.tolist()\nval_review_list = x_val.tolist()\ntest_review_list = x_test.tolist()\nall_review_list = x_train.tolist() + x_val.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bad7335af88ddfc4860759be06fa33b4489163ac"},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=num_most_freq_words_to_include)\ntokenizer.fit_on_texts(all_review_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b344baa63948e98603c8ab1a521267847afa767","trusted":true},"cell_type":"code","source":"train_reviews_tokenized = tokenizer.texts_to_sequences(train_review_list)\nx_train = pad_sequences(train_reviews_tokenized, maxlen=MAX_REVIEW_LENGTH_FOR_KERAS_RNN)\nval_review_tokenized = tokenizer.texts_to_sequences(val_review_list)\nx_val = pad_sequences(val_review_tokenized, maxlen=MAX_REVIEW_LENGTH_FOR_KERAS_RNN)\ntest_review_tokenized = tokenizer.texts_to_sequences(test_review_list)\nx_test = pad_sequences(test_review_tokenized, maxlen=MAX_REVIEW_LENGTH_FOR_KERAS_RNN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a46c9ed6f109dd2ddcd0ef3dbf950919ae836a5"},"cell_type":"markdown","source":"## Architecture the RNN Model\n\n"},{"metadata":{"trusted":true,"_uuid":"bde593b0733640e3a94c5763be24c5953b41a87a"},"cell_type":"code","source":"from keras.layers import Input, Embedding, Dropout, Conv1D, MaxPool1D, GRU, LSTM, Dense\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ee5933ffcb3bffe6b9dcd291a9584176b9b7cfa"},"cell_type":"code","source":"def rnn_model(use_cnn = True, use_lstm = False):\n    input_sequences = Input(shape = (MAX_REVIEW_LENGTH_FOR_KERAS_RNN,))\n    initial_dropout = 0.2\n    embedding_layer = Embedding(input_dim = num_most_freq_words_to_include, \n                                output_dim = embedding_vector_length,\n                                input_length = MAX_REVIEW_LENGTH_FOR_KERAS_RNN)\n    X = embedding_layer(input_sequences)\n    X = Dropout(0.2)(X)\n    if use_cnn:\n        X = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(X)\n        X = MaxPool1D(pool_size=2)(X)\n        \n    # Add GRU layers\n    dropout_W = 0.0\n    dropout_U = 0.0\n    \n    if use_lstm:\n        X = LSTM(100, dropout = dropout_W, recurrent_dropout = dropout_U)(X)\n    else:\n        X = GRU(100, dropout=dropout_W, recurrent_dropout=dropout_U)(X)\n    X = Dropout(0.2)(X)\n    outputs= Dense(1, activation='sigmoid')(X)\n    model = Model(inputs = input_sequences, outputs = outputs)\n    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f311cc8bd5b90757075c20063cc2a3e3aa527abf"},"cell_type":"markdown","source":"## GRU Model"},{"metadata":{"trusted":true,"_uuid":"f7ab8324306bca315aaa53e04bd8f2590af7d16d"},"cell_type":"code","source":"gru_model = rnn_model(use_lstm=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"146ac0f707f73121ed21d78492e9bea9d4f6daa6"},"cell_type":"code","source":"gru_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6578a457e309241a4e46b7548ee6df0ceb8bb55e"},"cell_type":"code","source":"gru_model.fit(x_train, y_train, batch_size=64, epochs=3, validation_data=[x_val, y_val])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90f26217c71dd73a12c0af3b30ccf30461553e93"},"cell_type":"code","source":"y_test_pred_gru = gru_model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc6234580406c761bdf9c4ffb7a4fe8addb07c53"},"cell_type":"markdown","source":"## LSTM Model"},{"metadata":{"trusted":true,"_uuid":"d0c1e33a37728207ce8a43d132cfb77c00387529"},"cell_type":"code","source":"lstm_model = rnn_model(use_lstm=True)\nlstm_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe8ed887418e7769f36aa88c036393e6043d2882"},"cell_type":"code","source":"lstm_model.fit(x_train, y_train, batch_size = 64, epochs = 3, validation_data=[x_val, y_val])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5f2da506eefc143b721536a0f336497da6779c0"},"cell_type":"code","source":"y_test_pred_lstm = lstm_model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c073746af3da66c91b85f275540b949011ab099"},"cell_type":"markdown","source":"### Evaluate the Model Performance on Test Data"},{"metadata":{"trusted":true,"_uuid":"85f2b40fea79b40da88381bab748ab4d9eb94e44"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c39ac1d57518a7a17dc1fc1976763902001fc0b"},"cell_type":"code","source":"print(\"The AUC socre for GRU model is : %.4f.\" %roc_auc_score(y_test, y_test_pred_gru))\nprint(\"The AUC socre for LSTM model is : %.4f.\" %roc_auc_score(y_test, y_test_pred_lstm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7e2fca20c0f9673faca44317955e4a00e4ce1e8"},"cell_type":"code","source":"y_pred_list = [y_test_pred_gru, y_test_pred_lstm]\nlabel_list = [\"GRU\", \"LSTM\"]\npred_label = zip(y_pred_list, label_list)\nfor y_pred, lbl in pred_label:\n    fpr, tpr, _ = roc_curve(y_test, y_pred)\n    plt.plot(fpr, tpr, label = lbl)\n\nplt.xlabel(\"True Postive Rate\")\nplt.ylabel(\"False Positive Rate\")\nplt.title(\"ROC Curve for RNN Models\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18b827d13a008791947e1583c6a75d144c4cb306"},"cell_type":"markdown","source":"Overall, GRU model performs slightly well than LSTM, but the difference is very small."},{"metadata":{"trusted":true,"_uuid":"77f63266dbcbff9a11f22940dddc3162dd0565f6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
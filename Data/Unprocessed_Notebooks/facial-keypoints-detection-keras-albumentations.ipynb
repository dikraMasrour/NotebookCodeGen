{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport albumentations as A # Should be version 0.4.6\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.layers import Convolution2D, MaxPool2D, Dropout, BatchNormalization, Dropout, LeakyReLU\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.python.keras.utils.data_utils import Sequence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reproducible results (set to None if you want to keep the randomness)\nimport os\nimport random\n\nSEED = 1\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\nrandom.seed(SEED)\n\nif SEED is not None:\n    os.environ['PYTHONHASHSEED'] = str(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Data extraction","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!mkdir ../data/\n!unzip -q /kaggle/input/facial-keypoints-detection/training.zip -d ../data/train\n!unzip -q /kaggle/input/facial-keypoints-detection/test.zip -d ../data/test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data analysis and preprocessing\n\nIn this section we tackle the following topics:\n- Loading and formatting the data (image normaliation).\n- Getting a visual and statistical overview of the dataset.\n- Handling missing data and outliers.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper functions of this section\ndef format_dataset(dataframe):\n    X = np.array([ format_image(x) for x in dataframe['Image'] ])\n    \n    if len(dataframe.columns) > 2:\n        y = dataframe.drop('Image', axis=1).values\n        return X, y\n    \n    return X\n\ndef format_image(img_row):\n    \"\"\" Extract image from a pandas DataFrame row and normalize it in a [0,1] range. \"\"\"\n    img = img_row.split(' ')\n    img = np.array(img, dtype=np.float32)\n    img = img.reshape((96,96,1))\n    img = img / 255.\n    return img\n\ndef format_keypoints(keypoint):\n    \"\"\" Normalize keypoints coordinates to lie in a [-1,1] range. \"\"\"\n    return (keypoint - 48.) /  48.\n\ndef unformat_keypoints(keypoint):\n    \"\"\" Unormalize keypoints coordinates to lie in a [0,96] range. \"\"\"\n    return keypoint*48 + 48\n\ndef show_sample(img, keypoints, axis=None, color='b'):\n    \"\"\" Display the target keypoints on top of the input image. \"\"\"\n    if axis is None:\n        fig, axis = plt.subplots()\n    \n    axis.scatter(keypoints[0::2], keypoints[1::2], s=10, c=color)\n    axis.imshow(img.squeeze(), cmap='gray')\n\ndef show_random_samples(X, y, n_rows=2, n_cols=5):\n    \"\"\" Display a random subset of image-keypoints samples. \"\"\"\n    fig = plt.figure(figsize=(2*n_cols, 2*n_rows), dpi=100)\n\n    for i, idx in enumerate(np.random.randint(0, len(y), n_rows*n_cols)):\n        axis = fig.add_subplot(n_rows, n_cols, i+1, xticks=[], yticks=[])\n        show_sample(X[idx], y[idx], axis=axis)\n        axis.set_title(f'Sample #{idx}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data\ntrain_dir = '../data/train/training.csv'\ntest_dir = '../data/test/test.csv'\n\ntrain_data = pd.read_csv(train_dir)\ntest_data = pd.read_csv(test_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data overview\ntrain_data.sample(5).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the target keypoints statistics\ntrain_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing training data\nprint(f'Train sample: {len(train_data)}')\n\nprint('Pourcentage of missing values:')\ntrain_data.isna().mean().round(4) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute missing values\n\n# Solution 1 - Drop all samples with one or multiple missing values\n# train_data.dropna(inplace=True)\n\n# Solution 2 - Replace NaN values by last valid value\n# train_data.fillna(method = 'ffill', inplace=True)\n\n# Solution 3 - Replace NaN values with each feature median\ntrain_data.fillna(train_data.describe().T['50%'], inplace=True)\n\n# Solution 4 - Replace NaN values with each feature mean\n# train_data.fillna(train_data.describe().T['mean'], inplace=True)\n\n# Solution 5 - DON'T RUN THIS CELL (go directly to section 4)\n\n# Check imputed data\ntrain_data.sample(5).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Format the data\nX_train, y_train = format_dataset(train_data)\nX_test = format_dataset(test_data)\nprint(X_train.shape, y_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display a random subset of training samples\nshow_random_samples(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper functions of this section\ndef show_random_preds(model, X, n_rows=2, n_cols=5):\n    fig = plt.figure(figsize=(2*n_cols, 2*n_rows), dpi=100)\n\n    for i, idx in enumerate(np.random.randint(0, len(X), n_rows*n_cols)):\n        X_input = X[idx:idx+1, ...]\n        y_pred = model.predict(X_input).flatten()\n        \n        axis = fig.add_subplot(n_rows, n_cols, i+1, xticks=[], yticks=[])\n        show_sample(X_input.squeeze(), y_pred, axis=axis)\n        axis.set_title(f'Sample #{idx}')\n\ndef plot_loss(hist, metric='loss'):\n    plt.plot(hist.history[metric])\n    plt.plot(hist.history[f'val_{metric}'])\n    plt.title(f'{metric.upper()} vs Epoch')\n    plt.ylabel(metric.upper())\n    plt.xlabel('Epochs')\n    plt.legend(['train', 'validation'], loc='upper right')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Input size: {X_train.shape}')\nprint(f'Output size: {y_train.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 1 - Small dense network\n\n**Kaggle score (public/private):** 4.67/4.69","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Architecture 1\ndef create_small_dense_network():\n    model = Sequential()\n    model.add(Input(shape=(96, 96, 1)))\n    model.add(Flatten())\n    model.add(Dense(units=100, activation='relu'))\n    model.add(Dense(units=30, activation=None))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Train model\nmodel1 = create_small_dense_network()\n\nes = EarlyStopping(monitor='val_loss', patience=10)\nmc = ModelCheckpoint('best_model1.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n\nmodel1.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\nhist1 = model1.fit(X_train, y_train, epochs=500, batch_size=256, verbose=0, validation_split=0.2, callbacks=[es, mc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show training and validation loss\nplot_loss(hist1, metric='mae')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize prediction on random test samples\nmodel1.load_weights('best_model1.h5')\nshow_random_preds(model1, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 2 - ConvNet\nInspired from [this notebook](https://www.kaggle.com/karanjakhar/facial-keypoint-detection)\n\n**Kaggle score (public/private):** 2.41/2.74","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Architecture 2\ndef create_convnet(n_outputs=30):\n    model = Sequential()\n\n    model.add(Convolution2D(32, (5,5), padding='same', input_shape=(96,96,1)))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(32, (5,5), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n\n    model.add(Convolution2D(64, (3,3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(64, (3,3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n\n    model.add(Convolution2D(96, (3,3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(96, (3,3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n\n    model.add(Convolution2D(128, (3,3),padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(128, (3,3),padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n\n    model.add(Convolution2D(256, (3,3),padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(256, (3,3),padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n\n    model.add(Convolution2D(512, (3,3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(512, (3,3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(n_outputs))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Train model\nmodel2 = create_convnet()\n\nes = EarlyStopping(monitor='val_loss', patience=10)\nmc = ModelCheckpoint('best_model2.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n\nmodel2.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\nhist2 = model2.fit(X_train, y_train, epochs=50, batch_size=128, verbose=0, validation_split=0.10, callbacks=[es, mc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show training and validation loss\nplot_loss(hist2, metric='mae') # 1.377 -> 1.298","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize prediction on random test samples\nmodel2.load_weights('best_model2.h5')\nshow_random_preds(model2, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 3 - Augmentation + ConvNet\n\n**Kaggle score (public/private):** 2.01/2.36","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper functions of this section\nclass DataLoader(Sequence):\n    def __init__(self, X, y, batch_size, augmentations=None, as_rgb=False):\n        self.X, self.y = X, y\n        self.batch_size = batch_size\n        self.augment = augmentations\n        self.shuffle = True\n        self.as_rgb = as_rgb\n        self.on_epoch_end()\n\n    def __len__(self):\n        \"\"\" Corresponds to the number of steps in one epoch. \"\"\"\n        return int(np.ceil(len(self.X) / float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        indexes = self.indexes[idx*self.batch_size: (idx+1)*self.batch_size]\n        batch_X = self.X[indexes, ...]\n        batch_y = self.y[indexes, :]\n        \n        # Convert grayscale to RGB if needed (if you want to use a pre-trained ResNet for example)\n        if self.as_rgb:\n            batch_X = np.tile(batch_X, reps=(1,1,1,3))\n\n        # Apply transformations on both images and keypoints\n        if self.augment is not None:\n            keypoints = np.array([ tuple(zip(point[::2], point[1::2])) for point in batch_y ])\n            transformed = [ self.augment(image=x, keypoints=y) for x,y in zip(batch_X, keypoints) ]\n            batch_X = np.stack([ z['image'] for z in transformed ], axis=0)\n            batch_y = np.stack([ np.array(z['keypoints']).flatten(order='C') for z in transformed ], axis=0)\n\n        return batch_X, batch_y\n\n    def on_epoch_end(self):\n        \"\"\" Shuffle the data after each epoch to avoid oscillation patterns in the loss. \"\"\"\n        self.indexes = np.arange(len(self.X))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add splitting to avoid leakage\nX_train2, X_valid, y_train2, y_valid = train_test_split(X_train, y_train, test_size=0.10, shuffle=True)\n\n# Define augmentation strategy\ntransform = A.Compose([\n    A.ShiftScaleRotate(rotate_limit=30, p=0.5),\n    A.RandomBrightnessContrast(p=0.5),\n    A.GaussianBlur(p=0.5),\n    A.GaussNoise(var_limit=(1e-5, 1e-3), p=0.5),\n], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n\ntrain_loader = DataLoader(X_train2, y_train2, batch_size=128, augmentations=transform)\nprint(X_train2.shape, y_train2.shape)\nprint(X_valid.shape, y_valid.shape)\n\n# Visualize augmented data\nx_batch, y_batch = train_loader[1]\nshow_random_samples(x_batch.squeeze(), y_batch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', patience=20)\nmc = ModelCheckpoint('best_model3.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n\nmodel3 = create_convnet()\nmodel3.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\nhist3 = model3.fit(train_loader, steps_per_epoch=len(train_loader),\n                   validation_data=(X_valid, y_valid),\n                   epochs=500, verbose=0, callbacks=[es, mc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss(hist3, metric='mae')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.load_weights('best_model3.h5')\nshow_random_preds(model3, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Hierarchical approach with training specialists\n\n**Kaggle score (public/private):** 1.89/2.06\n\nIdea originated and adapted from [this blog](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/#training-specialists)\n\nWe divide the facial keypoints into 5 regions and train one model per region. <br>\nEach model is initialized with the weights of a model trained on the whole dataset (see section 3).\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_specialist(n_outputs=30, weights=None, freeze=False):\n    model = create_convnet()\n    \n    if weights is not None:\n        model.load_weights(weights)\n    \n    if freeze:\n        for layers in model.layers[:-10]:\n            layers.trainable = False\n        \n    if n_outputs != 30:\n        model.layers.pop()\n        model.add(Dense(n_outputs))\n    return model\n\ndef train_specialist(model, keypoints_range, model_name):\n    # Prepare dataset\n    train_data = pd.read_csv(train_dir)\n    \n    select_col_idx = list(range(*keypoints_range[model_name])) + [-1]\n    subdata = train_data.iloc[:, select_col_idx]\n    subdata = subdata.dropna()\n    \n    X_train, y_train = format_dataset(subdata)\n    X_train2, X_valid, y_train2, y_valid = train_test_split(X_train, y_train, test_size=0.10, shuffle=True)\n\n    # Define augmentation strategy\n    transform = A.Compose([A.ShiftScaleRotate(rotate_limit=30, p=0.5),\n                           A.RandomBrightnessContrast(p=0.5),\n                           A.GaussianBlur(p=0.5),\n                           A.GaussNoise(var_limit=(1e-5, 1e-3), p=0.5)],\n                          keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n\n    train_loader = DataLoader(X_train2, y_train2, batch_size=128, augmentations=transform)\n    \n    # Train specialist model\n    es = EarlyStopping(monitor='val_loss', patience=10)\n    mc = ModelCheckpoint(f'best_model_{model_name}.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n\n    model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n    hist = model.fit(train_loader, steps_per_epoch=len(train_loader),\n                     validation_data=(X_valid, y_valid),\n                     epochs=250, verbose=0, callbacks=[es, mc])\n    model.load_weights(f'best_model_{model_name}.h5')    \n    \n    return model, hist\n\n\nclass ConcatenateSpecialists:\n    def __init__(self, models):\n        self.models = models\n        \n    def predict(self, X):\n        return np.hstack([ m.predict(X) for m in self.models ])\n    \n# TODO: https://www.deeplearningbook.org/contents/regularization.html (page 245-246) -> retrain on whole dataset  ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"specialist_keypoints = {'eyes_centers':(0,4), 'eyes_corners':(4,12), 'eyebrows': (12,20), 'nose': (20,22), 'mouth': (22,30)}\nmodels = {}\n\nfor region, keypoint_ids in specialist_keypoints.items():\n    print(f'Training model {region}...')\n    model = create_specialist(n_outputs=keypoint_ids[1]-keypoint_ids[0], weights='best_model3.h5', freeze=False)\n    models[region] = train_specialist(model, specialist_keypoints, region)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4 = ConcatenateSpecialists([m[0] for m in models.values()])\nshow_random_preds(model4, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Visualizing Intermediate Representations\nInspired from [this tutorial](https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%202%20-%20Lesson%202%20-%20Notebook.ipynb).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model3\nlayer_names = [layer.name for layer in model.layers]\nintermediate_outputs = [layer.output for layer in model.layers]\nvisualization_model = Model(inputs = model.input, outputs = intermediate_outputs)\n\nn = 10 # number of random filters to display per layer\nx = X_test[0:2]\nfeature_maps = visualization_model.predict(x)\n\nfor layer_name, feature_map in zip(layer_names, feature_maps):    \n    if len(feature_map.shape) == 4:\n        # Just do this for the conv / maxpool layers, not the fully-connected layers\n        n_features = feature_map.shape[-1] \n        size = feature_map.shape[ 1]\n\n        # We will tile our images in this matrix\n        display_grid = np.zeros((size, size * n))\n\n        # Postprocess the feature to be visually palatable\n        for i, idx in enumerate(np.random.randint(0, n_features, n)):\n            x  = feature_map[0, :, :, i]\n            x -= x.mean()\n            x /= x.std ()\n            x *=  64\n            x += 128\n            x  = np.clip(x, 0, 255).astype('uint8')\n            display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n\n        # Display the grid\n        scale = 3\n        plt.figure(figsize=(scale * n, scale))\n        plt.title(layer_name)\n        plt.grid(False)\n        plt.imshow(display_grid, aspect='auto', cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_submission_file(model, X_test, save_name='model_preds'):\n    predictions = model.predict(X_test)\n    print(f'Shape: {predictions.shape} - Min: {predictions.min()} - Max: {predictions.max()}')\n\n    # Post-process predictions\n    predictions[predictions > 96] = 96\n    \n    # Lookup table filters out the expected prediction points landmarks for each test image\n    lookid_data = pd.read_csv('/kaggle/input/facial-keypoints-detection/IdLookupTable.csv')\n\n    image_id = list(lookid_data['ImageId']-1)\n    landmark_names = list(lookid_data['FeatureName'])\n    landmark_ids = [ landmark_names.index(f) for f in landmark_names ]\n\n    expected_preds = [ predictions[x,y] for x,y in zip(image_id, landmark_ids) ]\n\n    rowid = pd.Series(lookid_data['RowId'], name = 'RowId')\n    loc = pd.Series(expected_preds, name = 'Location')\n    submission = pd.concat([rowid, loc], axis = 1)\n    \n    submission.to_csv(f'{save_name}.csv',index = False)\n    print(f'Successfully created {save_name}.csv !')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_submission_file(model1, X_test, 'model_preds1')\ncreate_submission_file(model2, X_test, 'model_preds2')\ncreate_submission_file(model3, X_test, 'model_preds3')\ncreate_submission_file(model4, X_test, 'model_preds4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
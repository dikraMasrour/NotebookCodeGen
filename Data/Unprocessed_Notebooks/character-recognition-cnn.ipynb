{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport random\nimport datetime\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\nimport functools\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.enable_eager_execution()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"TRAIN_CSV_PATH = '/kaggle/input/street-view-getting-started-with-julia/trainLabels.csv'\nTRAIN_IMGS_BASE_PATH = '/kaggle/input/street-view-getting-started-with-julia/trainresized/trainResized/'\nTEST_IMGS_BASE_PATH = '/kaggle/input/street-view-getting-started-with-julia/testresized/testResized/'\nBATH_SIZE = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(TRAIN_CSV_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LABELS = train_data['Class']\nUNIQUE_LABELS = list(set(LABELS))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LABEL_IDX = [UNIQUE_LABELS.index(l) for l in LABELS]\nLABEL_IDX = np.array(LABEL_IDX, dtype=np.float32)\ntrain_data['label'] = LABEL_IDX","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove grey images"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop([283, 2289, 3135], inplace=True)\ntrain_data.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_id = random.choice(train_data['ID'].values)\nsample_img = TRAIN_IMGS_BASE_PATH + str(random_id) + '.Bmp'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!find {sample_img}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_cnt = tf.read_file(filename=sample_img)\nimg = tf.io.decode_bmp(img_cnt, channels=3)\nprint(img.shape)\nplt.imshow(img)\nplt.title(LABELS[random_id-1])\nprint(LABEL_IDX[random_id - 1])\nprint(UNIQUE_LABELS.index(LABELS[random_id-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['img'] = [TRAIN_IMGS_BASE_PATH + str(id) + '.Bmp' for id in train_data['ID'].values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_img(img, label=None):\n    img_cnt = tf.read_file(img)\n    img_cnt = tf.io.decode_bmp(img_cnt, channels=3)\n#     img_cnt = tf.keras.applications.resnet50.preprocess_input(img_cnt)\n    img_cnt /= 255\n#     mean = tf.math.reduce_mean(img_cnt)\n#     std = tf.math.reduce_std(img_cnt)\n#     img_cnt = (img_cnt - std) / mean\n    return img_cnt, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dataset(imgs, labels=None):\n    dataset = (\n        tf.data.Dataset.from_tensor_slices((imgs, labels))\n        .shuffle(len(imgs))\n        .map(transform_img)\n        .batch(BATH_SIZE)\n        .repeat()\n        .prefetch(1)\n    )\n    iterator = dataset.make_one_shot_iterator()\n    return iterator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train_data['img'], train_data['label'], test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"steps_per_epoch, validation_steps = X_train.shape[0]/BATH_SIZE, X_test.shape[0]/BATH_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_steps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_iter = get_dataset(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_iter = get_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfor i in range(1, 5):\n    plt.subplot(5, 5, i)\n    imgs, lbs = train_iter.get_next()\n#     print(imgs.numpy().shape)\n#     print(lbs.numpy().shape)\n    plt.imshow(imgs[3])\n    plt.title(UNIQUE_LABELS[int(lbs[3])])\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tf Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"Activation = 'elu'\nInput = tf.keras.layers.Input\nConv2D = functools.partial(\n        tf.keras.layers.Conv2D,\n        activation=Activation,\n        padding='same'\n        )\nDense = functools.partial(\n        tf.keras.layers.Dense\n        )\nDropout = tf.keras.layers.Dropout\nAvgpool = tf.keras.layers.AveragePooling2D\nMaxPool2D = tf.keras.layers.MaxPool2D\nBatchNorm = tf.keras.layers.BatchNormalization\nFlatten = tf.keras.layers.Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(outputs_shape):\n    input = Input(shape=(20, 20, 3,))\n    conv_1 = Conv2D(16, (2, 2))(input)\n    conv_2 = Conv2D(16, (2, 2))(conv_1)\n    conv_3 = Conv2D(32, (3, 3))(conv_2)\n    avg_1 = Avgpool((2, 2))(conv_2)\n    batch_norm_2 = BatchNorm()(conv_2)\n    \n    conv_3 = Conv2D(64, (3, 3))(batch_norm_2)\n    conv_4 = Conv2D(64, (3, 3))(conv_3)\n#     avg_2 = Avgpool((2, 2))(conv_4)\n    batch_norm_4 =  BatchNorm()(conv_4)\n    \n    conv_5 = Conv2D(32, (3, 3))(batch_norm_4)\n    conv_6 = Conv2D(32, (5, 5))(conv_5)\n    dropout_1 = Dropout(0.3)(conv_6)\n    batch_norm_6 =  BatchNorm()(dropout_1)\n    \n    conv_7 = Conv2D(16, (5, 5))(batch_norm_6)\n    conv_8 = Conv2D(16, (5, 5))(conv_7)\n    batch_norm_7 =  BatchNorm()(conv_8)\n    \n    flat_1 = Flatten()(batch_norm_7)\n    dense_1 = Dense(512, activation=Activation)(flat_1)\n    outputs = Dense(outputs_shape, activation='softmax')(dense_1)\n    \n    model = tf.keras.Model(input, outputs)\n    model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy' ,metrics=['accuracy'])\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_labels_count = len(list(set(LABELS)))\nprint(unique_labels_count)\nmodel = get_model(unique_labels_count)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"logdir = os.path.join(\"/tmp/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(filepath='./weights.hdf5', verbose=1, save_best_only=True),\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n    tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_iter, steps_per_epoch=20, epochs=50, validation_data=validation_iter, validation_steps=5, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inferance"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs = []\nfor dirname, _, filenames in os.walk(TEST_IMGS_BASE_PATH):\n    for filename in filenames:\n        test_imgs.append(os.path.join(dirname, filename))\nprint(test_imgs[:5])\ntest_imgs = np.array(test_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_imgs)/256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grey_imgs = []\nfor i, img in enumerate(test_imgs):\n    try:\n        img_cnt = tf.read_file(img)\n        img_cnt = tf.image.decode_bmp(img_cnt, channels=3)\n    except:\n        print(i)\n        grey_imgs.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs = np.delete(test_imgs, grey_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pipeline = get_dataset(test_imgs, tf.zeros(len(test_imgs)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test_pipeline, steps=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_img = random.choice(range(len(test_imgs)))\nimg_cnt = tf.read_file(test_imgs[rand_img])\nimg_cnt = tf.image.decode_bmp(img_cnt)\nplt.imshow(img_cnt)\nplt.title(UNIQUE_LABELS[np.argmax(predictions[rand_img])])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}
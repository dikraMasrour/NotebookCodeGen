{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import necessary packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nfrom math import sin, cos, pi\n\nfrom keras.applications import ResNet50\nfrom keras.layers import Conv2D, LeakyReLU, GlobalAveragePooling2D, Dropout, Dense\nfrom keras.models import Sequential","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-22T14:55:02.426164Z","iopub.execute_input":"2021-08-22T14:55:02.426548Z","iopub.status.idle":"2021-08-22T14:55:03.36002Z","shell.execute_reply.started":"2021-08-22T14:55:02.426465Z","shell.execute_reply":"2021-08-22T14:55:03.359096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:03.361623Z","iopub.execute_input":"2021-08-22T14:55:03.362047Z","iopub.status.idle":"2021-08-22T14:55:03.369123Z","shell.execute_reply.started":"2021-08-22T14:55:03.361997Z","shell.execute_reply":"2021-08-22T14:55:03.367837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"!unzip ../input/facial-keypoints-detection/training.zip\n!unzip ../input/facial-keypoints-detection/test.zip","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:03.371704Z","iopub.execute_input":"2021-08-22T14:55:03.372719Z","iopub.status.idle":"2021-08-22T14:55:07.721259Z","shell.execute_reply.started":"2021-08-22T14:55:03.372677Z","shell.execute_reply":"2021-08-22T14:55:07.72036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_file = pd.read_csv('./training.csv')\ntest_file = pd.read_csv('./test.csv')\nidlookup_file = pd.read_csv('../input/facial-keypoints-detection/IdLookupTable.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:07.723152Z","iopub.execute_input":"2021-08-22T14:55:07.723507Z","iopub.status.idle":"2021-08-22T14:55:10.307146Z","shell.execute_reply.started":"2021-08-22T14:55:07.723466Z","shell.execute_reply":"2021-08-22T14:55:10.306333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_file.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:10.308443Z","iopub.execute_input":"2021-08-22T14:55:10.308804Z","iopub.status.idle":"2021-08-22T14:55:10.348302Z","shell.execute_reply.started":"2021-08-22T14:55:10.30877Z","shell.execute_reply":"2021-08-22T14:55:10.34721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training file include 31 columns - represents for 30 features and 1 for the image","metadata":{}},{"cell_type":"code","source":"test_file.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:10.349837Z","iopub.execute_input":"2021-08-22T14:55:10.350212Z","iopub.status.idle":"2021-08-22T14:55:10.362314Z","shell.execute_reply.started":"2021-08-22T14:55:10.350173Z","shell.execute_reply":"2021-08-22T14:55:10.361397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idlookup_file.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:10.36401Z","iopub.execute_input":"2021-08-22T14:55:10.364748Z","iopub.status.idle":"2021-08-22T14:55:10.377406Z","shell.execute_reply.started":"2021-08-22T14:55:10.364708Z","shell.execute_reply":"2021-08-22T14:55:10.376267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for the null values","metadata":{}},{"cell_type":"code","source":"train_file.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:10.380395Z","iopub.execute_input":"2021-08-22T14:55:10.380937Z","iopub.status.idle":"2021-08-22T14:55:10.392966Z","shell.execute_reply.started":"2021-08-22T14:55:10.380891Z","shell.execute_reply":"2021-08-22T14:55:10.392081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can observe that approximate 68% of data is missing for several keypoints\nSo, we can drop all rows with missing data or fill nullvalues","metadata":{}},{"cell_type":"code","source":"clean_train_file = train_file.dropna() # we use this for augmentation\ntrain_file = train_file.fillna(method='ffill')","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:10.39504Z","iopub.execute_input":"2021-08-22T14:55:10.39541Z","iopub.status.idle":"2021-08-22T14:55:10.422614Z","shell.execute_reply.started":"2021-08-22T14:55:10.395374Z","shell.execute_reply":"2021-08-22T14:55:10.421826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_file.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:10.423872Z","iopub.execute_input":"2021-08-22T14:55:10.424211Z","iopub.status.idle":"2021-08-22T14:55:10.435567Z","shell.execute_reply.started":"2021-08-22T14:55:10.424178Z","shell.execute_reply":"2021-08-22T14:55:10.434545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load images and keypints","metadata":{}},{"cell_type":"code","source":"def load_images(image_data):\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)/255.\n    return images\n\ndef load_keypoints(keypoint_data):\n    keypoint_data = keypoint_data.drop(['Image'], axis=1)\n    keypoint_features = []\n    for idx, features in keypoint_data.iterrows():\n        keypoint_features.append(features)\n    keypoint_features = np.array(keypoint_features, dtype=float)\n    return keypoint_features\n\ntrain_images = load_images(train_file)\nimages = load_images(clean_train_file)\ntrain_keypoints = load_keypoints(train_file)\nkeypoints = load_keypoints(clean_train_file)\ntest_images = load_images(test_file)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:10.436858Z","iopub.execute_input":"2021-08-22T14:55:10.437187Z","iopub.status.idle":"2021-08-22T14:55:42.635793Z","shell.execute_reply.started":"2021-08-22T14:55:10.437154Z","shell.execute_reply":"2021-08-22T14:55:42.634871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Augmentation","metadata":{}},{"cell_type":"code","source":"class aug_config:\n    rotation_augmentation = True\n    brightness_augmentation = True\n    shift_augmentation = True\n    random_noise_augmentation = True\n    rotation_angles = [15]\n    pixel_shifts = [15]","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:42.637217Z","iopub.execute_input":"2021-08-22T14:55:42.637578Z","iopub.status.idle":"2021-08-22T14:55:42.643148Z","shell.execute_reply.started":"2021-08-22T14:55:42.637543Z","shell.execute_reply":"2021-08-22T14:55:42.642358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rotation","metadata":{}},{"cell_type":"code","source":"def rotate_augmentation(images, keypoints, rotation_angles):\n    rotated_images = []\n    rotated_keypoints = []\n    for angle in rotation_angles:\n        for angle in [angle, -angle]:\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.)\n            angle_rad = -angle*pi/180.\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.\n                for idx in range(0, len(rotated_keypoint), 2):\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   \n                rotated_keypoints.append(rotated_keypoint)\n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n\nif aug_config.rotation_augmentation:\n    rotated_train_images, rotated_train_keypoints = rotate_augmentation(images, keypoints, aug_config.rotation_angles)\n    train_images = np.concatenate((train_images, rotated_train_images))\n    train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(rotated_train_images[19], rotated_train_keypoints[19], axis, \"Rotation Augmentation\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:42.644365Z","iopub.execute_input":"2021-08-22T14:55:42.644882Z","iopub.status.idle":"2021-08-22T14:55:44.322849Z","shell.execute_reply.started":"2021-08-22T14:55:42.644846Z","shell.execute_reply":"2021-08-22T14:55:44.322044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Change Brightness","metadata":{}},{"cell_type":"code","source":"def alter_brightness(images, keypoints):\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    \n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    \n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\nif aug_config.brightness_augmentation:\n    altered_brightness_images, altered_brightness_keypoints = alter_brightness(images, keypoints)\n    train_images = np.concatenate((train_images, altered_brightness_images))\n    train_keypoints = np.concatenate((train_keypoints, altered_brightness_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(altered_brightness_images[19], altered_brightness_keypoints[19], axis, \"Alter Brightness Augmentation\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:44.324134Z","iopub.execute_input":"2021-08-22T14:55:44.324476Z","iopub.status.idle":"2021-08-22T14:55:45.195431Z","shell.execute_reply.started":"2021-08-22T14:55:44.324426Z","shell.execute_reply":"2021-08-22T14:55:45.194485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Shift images","metadata":{}},{"cell_type":"code","source":"def shift_images(images, keypoints, pixel_shifts):\n    shifted_images = []\n    shifted_keypoints = []\n    for shift in pixel_shifts:    \n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            for image, keypoint in zip(images, keypoints):\n                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96,96,1))\n                    shifted_keypoints.append(shifted_keypoint)\n    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n    return shifted_images, shifted_keypoints\n\nif aug_config.shift_augmentation:\n    shifted_train_images, shifted_train_keypoints = shift_images(images, keypoints, aug_config.pixel_shifts)\n    train_images = np.concatenate((train_images, shifted_train_images))\n    train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(shifted_train_images[19], shifted_train_keypoints[19], axis, \"Shift Augmentation\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:45.196854Z","iopub.execute_input":"2021-08-22T14:55:45.197191Z","iopub.status.idle":"2021-08-22T14:55:47.995313Z","shell.execute_reply.started":"2021-08-22T14:55:45.197158Z","shell.execute_reply":"2021-08-22T14:55:47.993632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Add noise","metadata":{}},{"cell_type":"code","source":"def add_noise(images):\n    noisy_images = []\n    for image in images:\n        noisy_image = cv2.add(image, 0.008*np.random.randn(96,96,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n        noisy_images.append(noisy_image.reshape(96,96,1))\n    return noisy_images\n\nif aug_config.random_noise_augmentation:\n    noisy_train_images = add_noise(images)\n    train_images = np.concatenate((train_images, noisy_train_images))\n    train_keypoints = np.concatenate((train_keypoints, keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(noisy_train_images[19], keypoints[19], axis, \"Random Noise Augmentation\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:47.9973Z","iopub.execute_input":"2021-08-22T14:55:47.997752Z","iopub.status.idle":"2021-08-22T14:55:49.676957Z","shell.execute_reply.started":"2021-08-22T14:55:47.997708Z","shell.execute_reply":"2021-08-22T14:55:49.67615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_images.shape)\nprint(train_keypoints.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:49.678106Z","iopub.execute_input":"2021-08-22T14:55:49.678593Z","iopub.status.idle":"2021-08-22T14:55:49.683848Z","shell.execute_reply.started":"2021-08-22T14:55:49.678557Z","shell.execute_reply":"2021-08-22T14:55:49.68293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"model = Sequential()\npretrained_model = ResNet50(input_shape=(96,96,3), include_top=False, weights='imagenet')\npretrained_model.trainable = True\n\nmodel.add(Conv2D(3, (1,1), padding='same', input_shape=(96,96,1)))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(pretrained_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:54.023756Z","iopub.execute_input":"2021-08-22T14:55:54.024344Z","iopub.status.idle":"2021-08-22T14:55:56.954056Z","shell.execute_reply.started":"2021-08-22T14:55:54.024298Z","shell.execute_reply":"2021-08-22T14:55:56.952964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the Model","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearlyStopping = EarlyStopping(monitor='loss', patience=30, mode='min',\n                             baseline=None)\n\nrlp = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, min_lr=1e-15, mode='min', verbose=1)\n\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n\nhistory = model.fit(train_images, train_keypoints, epochs=200, batch_size=64, validation_split=0.15, callbacks=[earlyStopping, rlp])","metadata":{"execution":{"iopub.status.busy":"2021-08-22T14:55:56.963645Z","iopub.execute_input":"2021-08-22T14:55:56.963984Z","iopub.status.idle":"2021-08-22T15:38:46.147007Z","shell.execute_reply.started":"2021-08-22T14:55:56.963948Z","shell.execute_reply":"2021-08-22T15:38:46.14609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('darkgrid')\n\nfig, ax = plt.subplots(2, 1, figsize=(20, 10))\ndf = pd.DataFrame(history.history)\ndf[['loss', 'val_loss']].plot(ax=ax[0])\ndf[['accuracy', 'val_accuracy']].plot(ax=ax[1])\nax[0].set_title('Model Loss', fontsize=12)\nax[1].set_title('Model Acc', fontsize=12)\nfig.suptitle('Model Metrics', fontsize=18);","metadata":{"execution":{"iopub.status.busy":"2021-08-22T15:44:25.4639Z","iopub.execute_input":"2021-08-22T15:44:25.464216Z","iopub.status.idle":"2021-08-22T15:44:25.940629Z","shell.execute_reply.started":"2021-08-22T15:44:25.464189Z","shell.execute_reply":"2021-08-22T15:44:25.9397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predicting on Test Set and Submission","metadata":{}},{"cell_type":"code","source":"test_preds = model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T15:44:31.83657Z","iopub.execute_input":"2021-08-22T15:44:31.836921Z","iopub.status.idle":"2021-08-22T15:44:32.767602Z","shell.execute_reply.started":"2021-08-22T15:44:31.836889Z","shell.execute_reply":"2021-08-22T15:44:32.766748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = list(idlookup_file['FeatureName'])\nimage_ids = list(idlookup_file['ImageId']-1)\nrow_ids = list(idlookup_file['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_preds[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T15:46:12.646272Z","iopub.execute_input":"2021-08-22T15:46:12.646634Z","iopub.status.idle":"2021-08-22T15:46:12.806676Z","shell.execute_reply.started":"2021-08-22T15:46:12.646601Z","shell.execute_reply":"2021-08-22T15:46:12.805843Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
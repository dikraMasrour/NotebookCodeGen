{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the generated documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu, sentence_bleu\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'C:\\\\Users\\\\dmasrour\\\\Documents\\\\CodeDoc_Generation\\\\Data_backup\\\\DocGen_Unprocessed_Notebooks\\\\kaggle-courses-master\\\\intro_to_machine_learning\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + '03-your-first-machine-learning-model.ipynb', encoding=\"utf8\") as jsonfile:\n",
    "    original_nb = json.load(jsonfile)\n",
    "original_nb = pd.json_normalize(original_nb['cells'])[['cell_type', 'source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + '03-your-first-machine-learning-model.ipynbPLBART_documented.ipynb', encoding=\"utf8\") as jsonfile:\n",
    "    docgen_nb = json.load(jsonfile)\n",
    "docgen_nb = pd.json_normalize(docgen_nb['cells'])[['cell_type', 'source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  cell_type                                             source\n",
       " 0  markdown  [**[Introduction to Machine Learning Home Page...\n",
       " 1  markdown  [## Recap\\n, So far, you have loaded your data...\n",
       " 2      code  [# Code you have previously used to load data\\...\n",
       " 3  markdown  [# Exercises\\n, \\n, ## Step 1: Specify Predict...\n",
       " 4      code  [# print the list of columns in the dataset to...,\n",
       " (22, 2))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_nb.head(), original_nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  cell_type                                             source\n",
       " 0  markdown      [Loads the data from the previous used code.]\n",
       " 1      code  [# Code you have previously used to load data\\...\n",
       " 2  markdown  [Print the list of columns in the dataset to t...\n",
       " 3      code  [# print the list of columns in the dataset to...\n",
       " 4  markdown                  [Check the value of thealePrice.],\n",
       " (16, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docgen_nb.head(), docgen_nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**[Introduction to Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**\\n',\n",
       " '\\n',\n",
       " '---\\n']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_nb.loc[0, 'source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT score (takes too long without GPU -> see GoogleCollab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoothed BLEU-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_doc = pd.read_csv('../data/generated_doc.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>markdown</th>\n",
       "      <th>generated_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear algebra</td>\n",
       "      <td>Import numpy as np</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data processing, CSV file I O e.g. pd.read csv</td>\n",
       "      <td>Import pandas data frame.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For example, running this by clicking run or p...</td>\n",
       "      <td>Import datetime module.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some statistics</td>\n",
       "      <td>Imports the scipy. stats module and imports th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Load data</td>\n",
       "      <td>Reads the data from the house prices training ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            markdown  \\\n",
       "0                                     linear algebra   \n",
       "1    data processing, CSV file I O e.g. pd.read csv    \n",
       "2  For example, running this by clicking run or p...   \n",
       "3                                for some statistics   \n",
       "4                                          Load data   \n",
       "\n",
       "                                       generated_doc  \n",
       "0                                 Import numpy as np  \n",
       "1                          Import pandas data frame.  \n",
       "2                            Import datetime module.  \n",
       "3  Imports the scipy. stats module and imports th...  \n",
       "4  Reads the data from the house prices training ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_doc.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(ref, gen):\n",
    "    ''' \n",
    "    calculate pair wise bleu score. uses nltk implementation\n",
    "    Args:\n",
    "        references : a list of reference sentences \n",
    "        candidates : a list of candidate(generated) sentences\n",
    "    Returns:\n",
    "        bleu score(float)\n",
    "    '''\n",
    "    ref_bleu = []\n",
    "    gen_bleu = []\n",
    "    for l in gen:\n",
    "        gen_bleu.append(l.split())\n",
    "    for i,l in enumerate(ref):\n",
    "        ref_bleu.append([l.split()])\n",
    "    cc = SmoothingFunction()\n",
    "    score_bleu = corpus_bleu(ref_bleu, gen_bleu, weights=(1, 0, 0, 0), smoothing_function=cc.method4)\n",
    "    return score_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03583534217950505"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = list(generated_doc.generated_doc)\n",
    "references = list(generated_doc.markdown)\n",
    "bleu(references, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT vectors cosine similarity (inaccurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = \"Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.\"\n",
    "code_ref = \"home_data.columns\"\n",
    "toks_ref = tokenizer.tokenize(ref)\n",
    "code_toks_ref = tokenizer.tokenize(code_ref)\n",
    "\n",
    "tokens = [tokenizer.cls_token] + toks_ref + [tokenizer.sep_token] + code_toks_ref + [tokenizer.sep_token] \n",
    "\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ref_embeddings = model(torch.tensor(tokens_ids)[None,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = 'hi'\n",
    "code_gen = \"home_data.columns\"\n",
    "toks_gen = tokenizer.tokenize(gen)\n",
    "code_toks_gen = tokenizer.tokenize(code_gen)\n",
    "\n",
    "tokens = [tokenizer.cls_token] + toks_gen + [tokenizer.sep_token] + code_toks_gen + [tokenizer.sep_token] \n",
    "\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "gen_embeddings = model(torch.tensor(tokens_ids)[None,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tensor into np array\n",
    "tensor_np_ref = ref_embeddings.cpu().detach().numpy()\n",
    "tensor_np_gen = gen_embeddings.cpu().detach().numpy()\n",
    "# average of embeddings of the tokens in the sequence\n",
    "avg_ref = np.mean(tensor_np_ref[0], axis=0)\n",
    "avg_gen = np.mean(tensor_np_gen[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9559369683265686"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = 1 - cosine(avg_ref, avg_gen)\n",
    "cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data reference data pairs to be documented using PLBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>markdown</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear algebra</td>\n",
       "      <td>import numpy as np</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data processing, CSV file I O e.g. pd.read csv</td>\n",
       "      <td>import pandas as pd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For example, running this by clicking run or p...</td>\n",
       "      <td>from datetime import datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some statistics</td>\n",
       "      <td>from scipy . stats import skew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Load data</td>\n",
       "      <td>train = pd.read_csv('../input/house-prices-adv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            markdown  \\\n",
       "0                                     linear algebra   \n",
       "1    data processing, CSV file I O e.g. pd.read csv    \n",
       "2  For example, running this by clicking run or p...   \n",
       "3                                for some statistics   \n",
       "4                                          Load data   \n",
       "\n",
       "                                                code  \n",
       "0                              import numpy as np     \n",
       "1                             import pandas as pd     \n",
       "2                   from datetime import datetime     \n",
       "3                  from scipy . stats import skew     \n",
       "4  train = pd.read_csv('../input/house-prices-adv...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ref_pairs = pd.read_csv('../data/data_pairs_2.csv', index_col = 0)[['markdown', 'code']]\n",
    "data_ref_pairs.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49ab456e11cde720218fba409a85456f40f210cf294d5c8f56d5f4fb69af5c6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

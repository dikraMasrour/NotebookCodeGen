{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Training word2vec model for moroccan and algerian dialect"
=======
    "## Predicting ad positioning using Q-Learning"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92164cd7",
   "metadata": {},
   "source": [
    "🪄Imports data from the Icetea package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import glob"
=======
   "metadata": {},
   "source": [
    "Placement of ads on website is the primary problem for companies that operate on ad revenue. The position where the ad is placed plays pivotal role on whether or not the ad will be clicked. Here we have the following choices:\n",
    "\t1. Place them randomly, or\n",
    "\t2. Place the ad on the same position\n",
    "\n",
    "The problem with placing the ad on the same position is the user, after a certain time, will start ignoring the space since he's used to seeing ad at the place, he will end up ignoring that particular position hereafter. Hence, this will reduce the number of clicks on ads. The problem with the former option, placing them randomly, is it wouldn't take optimal positions into consideration. For instance, text beside images are viewed higher number of times than those text which are placed at a distance. It is infeasible to go through every website and repeat the procedure. \n",
    "\n",
    "Solution: Reinforcement Learning\n",
    "Using Reinforcement Learning we can approximate the human behavior. \n",
    "\n",
    "Why Reinforcement Learning? \n",
    "We cannot use traditional Machine Learning here, since it requires:\n",
    "\t1. Huge data\n",
    "\t2. Features\n",
    "\t3. Tuning of many hyperparameters\n",
    "And we neither have huge data, nor features. The only data we have is the position of the baner/ad and whether or not it was clicked. We will use this dataset from Kaggle: https://www.kaggle.com/akram24/ads-ctr-optimisation. We will solve this problem using Q-Learning. The reason for using Q-Learning here is :\n",
    "\t1. It is model free, so it doesn't require to know all the states.\n",
    "\t2. Intuitive to understand, and converges faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8db08a",
   "metadata": {},
   "source": [
    "🪄Import routine data from Python arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import routines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our environment will be the dataset. It contains 10 ads position per row having values either 1, when the ad is clicked, or 0 when it is not. Every row can be considered as a state in the space, considering it kind of a navigation across multiple pages (on website, for instance) Lets load the dataset and visualize the first few rows"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "54cbb3a1",
   "metadata": {},
   "source": [
    "🪄Loads data from one - drive dataset."
=======
   "id": "3670d521",
   "metadata": {},
   "source": [
    "🪄Reads the header of the environment and parses the data as a CSV."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 2,
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>comments</th>\n",
=======
       "      <th>Ad 1</th>\n",
       "      <th>Ad 2</th>\n",
       "      <th>Ad 3</th>\n",
       "      <th>Ad 4</th>\n",
       "      <th>Ad 5</th>\n",
       "      <th>Ad 6</th>\n",
       "      <th>Ad 7</th>\n",
       "      <th>Ad 8</th>\n",
       "      <th>Ad 9</th>\n",
       "      <th>Ad 10</th>\n",
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>عادو الناس يتباكاو بديت نهدر من قلبي تقول نهد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بكيت الناس كامل سكتو تخلعت في روحي تقول كنت ننوم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ناضو ﭭﺎع سلمو عليا و يهدرو معايا نص بكا و نص ل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عرضونا للعشا و كان لعشا يكفي ليزاﻧڢيتي ﭭﺎع</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>جوزت ايامات روعة ما ننساهاش طول حياتي</td>\n",
=======
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                                            comments\n",
       "0   عادو الناس يتباكاو بديت نهدر من قلبي تقول نهد...\n",
       "1   بكيت الناس كامل سكتو تخلعت في روحي تقول كنت ننوم\n",
       "2  ناضو ﭭﺎع سلمو عليا و يهدرو معايا نص بكا و نص ل...\n",
       "3         عرضونا للعشا و كان لعشا يكفي ليزاﻧڢيتي ﭭﺎع\n",
       "4              جوزت ايامات روعة ما ننساهاش طول حياتي"
      ]
     },
     "execution_count": 26,
=======
       "   Ad 1  Ad 2  Ad 3  Ad 4  Ad 5  Ad 6  Ad 7  Ad 8  Ad 9  Ad 10\n",
       "0     1     0     0     0     1     0     0     0     1      0\n",
       "1     0     0     0     0     0     0     0     0     1      0\n",
       "2     0     0     0     0     0     0     0     0     0      0\n",
       "3     0     1     0     0     0     0     0     1     0      0\n",
       "4     0     0     0     0     0     0     0     0     0      0"
      ]
     },
     "execution_count": 2,
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "path = r'C:\\\\Users\\\\zbook\\\\OneDrive - UIR\\\\UIR\\\\S8\\\\AutoTranslate\\\\word2vec_trainingdata'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df_elem = pd.read_csv(filename, index_col=None, header=0, on_bad_lines='skip')\n",
    "    li.append(df_elem)\n",
    "\n",
    "df = pd.concat(li, ignore_index=True)\n",
    "df.head()"
=======
    "env = pd.read_csv('Ads_CTR_Optimisation.csv')\n",
    "env.head()"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "7ac1b13a",
   "metadata": {},
   "source": [
    "🪄shape of dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
=======
   "metadata": {},
   "source": [
    "## Random policy\n",
    "\n",
    "If we were to not have Q-Learning, we would place the ads randomly at given positions. We will now simulate the same.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e0a30",
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115226, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "df.shape"
=======
    "🪄total rewards earned reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward collected: 1245\n"
     ]
    }
   ],
   "source": [
    "# total rewards earned\n",
    "reward = 0\n",
    "# random policy: for every state, choose a random\n",
    "# position for displaying the ad\n",
    "for x in range(len(env)):\n",
    "    action = np.random.randint(0, 10)\n",
    "    # if the guess was correct, increase the reward\n",
    "    if env.values[x][action] == 1:\n",
    "        reward += 1\n",
    "print(\"Reward collected: {}\".format(reward))"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "##### Tokenizing"
=======
    "## Using Max Policy\n",
    "Another question we might ask, is to display the ad where it is clicked the most number of times. For instance, there might be a certain position where the ad clicked with a higher probability. Since the values of the rows is either 1 or 0, we can sum across the columns and count the number of times ad in the position was clicked. "
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "159c98b3",
   "metadata": {},
   "source": [
    "🪄Tokenize the comments."
=======
   "id": "5e5bba82",
   "metadata": {},
   "source": [
    "🪄counts of the most common values in the environment."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [عادو, الناس, يتباكاو, بديت, نهدر, من, قلبي, ت...\n",
       "1         [بكيت, الناس, كامل, سكتو, تخلعت, في, روحي, تقو...\n",
       "2         [ناضو, ﭭﺎع, سلمو, عليا, و, يهدرو, معايا, نص, ب...\n",
       "3         [عرضونا, للعشا, و, كان, لعشا, يكفي, ليزاﻧڢيتي,...\n",
       "4             [جوزت, ايامات, روعة, ما, ننساهاش, طول, حياتي]\n",
       "                                ...                        \n",
       "115221    [شكرا, لقد, استمتعت, بهذا, الفيديو, كثيرا, خبي...\n",
       "115222    [فيديو, ممتع, والله, روووعة, يعطيك, الصحة, خوي...\n",
       "115223            [برااافو, عليك, تستاهل, الشهرة, العالمية]\n",
       "115224    [الله, يبارك, ،, ما, شاء, الله, خويا, خبيبيسّر...\n",
       "115225                     [أفضل, صانع, محتوى, في, الجزائر]\n",
       "Name: comments, Length: 115226, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized = df.comments.apply(nltk.word_tokenize)\n",
    "df_tokenized"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    counts\n",
       "ad        \n",
       "1     1703\n",
       "2     1295\n",
       "3      728\n",
       "4     1196\n",
       "5     2695\n",
       "6      126\n",
       "7     1112\n",
       "8     2091\n",
       "9      952\n",
       "10     489"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicked_counts = env.values.sum(axis=0)\n",
    "counts = pd.DataFrame({\"ad\": np.arange(1, 11), \"counts\": clicked_counts})\n",
    "counts.set_index(\"ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which indicates ad 5 was clicked 2695 times. So if we were to always place an ad on position 5, it would be click around 2695 times. But can we do better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Policy Iteration (Dynamic Programming) "
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Initializing word2vec model"
=======
   "id": "1be4ab47",
   "metadata": {},
   "source": [
    "🪄Get action space from the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total episodes trained: 11\n"
     ]
    }
   ],
   "source": [
    "action_space = np.arange(0, 100)\n",
    "# starting with random policy, choose a random choice for\n",
    "# every state in the environment\n",
    "state_size = len(env)\n",
    "policy = [random.choice(action_space) for x in range(state_size)]\n",
    "# will take random action for the first time\n",
    "first_time = True\n",
    "small_change = 1e-20\n",
    "gamma = 0.9\n",
    "episodes = 0\n",
    "max_episodes = 10\n",
    "\n",
    "V = dict()\n",
    "# last positions reward will be 1\n",
    "V[10000] = 1\n",
    "\n",
    "# initially the value function for all states\n",
    "# will be random values close to zero\n",
    "for i in range(state_size):\n",
    "    V[i] = np.random.random()\n",
    "\n",
    "while episodes < max_episodes:\n",
    "    # policy evaluation\n",
    "    while True:\n",
    "        if episodes > max_episodes:\n",
    "            break\n",
    "        episodes += 1\n",
    "        if episodes % 100 == 0:\n",
    "            print(\"Current episode: {}\".format(episodes))\n",
    "        biggest_change = 0\n",
    "        # loop through every state present\n",
    "        for state in range(state_size):\n",
    "            old_V = V[state]\n",
    "            # take random action according to policy\n",
    "            action = policy[state]\n",
    "            new_state = state + 1\n",
    "            reward = env.values[state][action]\n",
    "            V[state] = reward + gamma * V[new_state]\n",
    "            biggest_change = max(biggest_change, abs(V[state] - old_V))\n",
    "        if biggest_change < small_change:\n",
    "            break\n",
    "            \n",
    "    # policy improvement\n",
    "    policy_changed = False\n",
    "    for state in range(state_size):\n",
    "        best_val = -np.inf\n",
    "        best_action = -1\n",
    "        for action in action_space:\n",
    "            new_state = state + 1\n",
    "            reward = env.values[state][action]\n",
    "            future_reward = reward + gamma * V[new_state]\n",
    "            if future_reward > best_val:\n",
    "                best_val = future_reward\n",
    "                best_action = action\n",
    "        assert best_action != -1\n",
    "        if policy[state] != best_action:\n",
    "            policy_changed = True\n",
    "        policy[state] = best_action\n",
    "\n",
    "    if not policy_changed:\n",
    "        break\n",
    "print(\"Total episodes trained: {}\".format(episodes))"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "7a53ba37",
   "metadata": {},
   "source": [
    "🪄Create a new word2Vec model for use with the HMM module."
=======
   "id": "e08cf300",
   "metadata": {},
   "source": [
    "🪄total rewards earned reward = 0"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(window=5, min_count=2, workers=2)"
=======
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward collected: 10000\n"
     ]
    }
   ],
   "source": [
    "# total rewards earned\n",
    "reward = 0\n",
    "# random policy: for every state, choose a random\n",
    "# position for displaying the ad\n",
    "for x in range(len(env)):\n",
    "    action = policy[x]\n",
    "    # if the guess was correct, increase the reward\n",
    "    if env.values[x][action] == 1:\n",
    "        reward += 1\n",
    "print(\"Reward collected: {}\".format(reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Q-Learning\n",
    "\n"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Building vovab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec978ed",
   "metadata": {},
   "source": [
    "🪄Builds the vocabulary from the input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(df_tokenized, progress_per=5)"
=======
   "id": "6e2c2a12",
   "metadata": {},
   "source": [
    "🪄learning rate based on the current state of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using q-learning\n",
    "states = len(env)\n",
    "actions = 10\n",
    "q_table = np.zeros((states, actions))\n",
    "\n",
    "learning_rate = 0.7\n",
    "# gamma = 0.618\n",
    "gamma = 0.9\n",
    "\n",
    "epsilon = 1.0\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01\n",
    "max_episodes = 100"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "e98d07be",
   "metadata": {},
   "source": [
    "🪄The number of iterations done on the whole dataset by default it is 5 model.epochs"
=======
   "id": "f81ea296",
   "metadata": {},
   "source": [
    "🪄Randomizes a number to select whether or not to expolit"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs being the number of iterations done on the whole dataset, by default it is 5\n",
    "model.epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614789d",
   "metadata": {},
   "source": [
    "🪄Train a model by tokenizing the corpus count and number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4727130, 5645515)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(df_tokenized, total_examples=model.corpus_count, epochs=model.epochs)"
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploit(eps):\n",
    "    \"\"\"Randomizes a number to select\n",
    "    whether or not to expolit\"\"\"\n",
    "    return np.random.uniform() > eps\n",
    "\n",
    "def random_action():\n",
    "    return np.random.randint(0, 10)"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Saving model"
=======
   "id": "14bae885",
   "metadata": {},
   "source": [
    "🪄Calculates the reward value for each episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Episode: 50\n"
     ]
    }
   ],
   "source": [
    "reward = 0\n",
    "for episode in range(max_episodes):\n",
    "    epsilon *= 2\n",
    "    if episode % 50 == 0:\n",
    "        print(\"Episode: {}\".format(episode))\n",
    "    for state in range(states):\n",
    "        if exploit(epsilon):\n",
    "            action = random_action()\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "        r = env.values[state][action]\n",
    "        reward += r\n",
    "        q_table[state][action] += learning_rate*(r + gamma*np.max(q_table[state, :]) - q_table[state][action])\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate*episode)"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "fc33fb1b",
   "metadata": {},
   "source": [
    "🪄Save the model s file - > vector_mor_dz. model object."
=======
   "id": "8decf96b",
   "metadata": {},
   "source": [
    "🪄Test function for rewards"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./word2vec_mor_dz.model')"
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward collected: 1703\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "rewards = 0\n",
    "for state in range(states):\n",
    "    best_action = np.argmax(q_table[state, :])\n",
    "    r = env.values[state][best_action]\n",
    "    rewards += r\n",
    "print(\"Reward collected: {}\".format(rewards))"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "##### Testing"
=======
   "id": "f3da951d",
   "metadata": {},
   "source": [
    "🪄Returns the sum of values along axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 6, ..., 4, 6, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.values.sum(axis=1)"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "ebe68aeb",
   "metadata": {},
   "source": [
    "🪄Get vector of values in the WV model"
=======
   "id": "99927f25",
   "metadata": {},
   "source": [
    "🪄Get the current state of the graph."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30374986,  0.07175432, -1.9774907 ,  0.8653471 ,  1.0058571 ,\n",
       "        0.03052483,  1.6197143 , -1.0898234 ,  1.1693029 ,  0.96499985,\n",
       "       -1.1037531 , -1.5497943 ,  1.9381372 ,  1.0726736 ,  0.7137537 ,\n",
       "       -1.9590017 , -0.7012492 , -0.37255132, -0.19502258, -0.01550069,\n",
       "        0.30475372,  0.02588587, -0.10248473,  0.75695884,  0.87948567,\n",
       "       -1.8181672 ,  0.20955311, -0.29015642,  0.6445919 , -1.2174771 ,\n",
       "        2.6708517 , -0.37695837,  1.6182309 , -0.16528021, -1.2222136 ,\n",
       "        0.04739395,  0.03246354,  1.685888  ,  0.8174039 , -1.4625372 ,\n",
       "       -1.1201082 ,  0.2508373 ,  1.0266021 , -0.27731118,  0.01646691,\n",
       "       -1.3282051 ,  0.6850137 ,  0.15229063,  0.57460415,  0.7096181 ,\n",
       "        0.83873975, -0.14124483, -0.05335499, -2.1376112 ,  0.7597384 ,\n",
       "        0.00964276,  0.32463962,  1.6149795 ,  0.25036755, -0.84656155,\n",
       "       -0.11048245, -0.41262317,  1.1813644 , -0.61122257, -1.9603467 ,\n",
       "        0.73217666, -0.12566723,  1.2469335 , -1.2762504 ,  1.3140593 ,\n",
       "       -0.0808326 ,  0.67132723,  1.4991429 ,  1.59795   , -0.03220373,\n",
       "       -0.8748432 , -0.5941907 , -0.64879906, -0.08678758,  1.7098435 ,\n",
       "       -0.5889559 , -0.64070845,  0.19907294,  0.086163  , -0.30998918,\n",
       "       -1.4234908 ,  0.7986347 , -0.69719934, -0.9008635 ,  0.01687654,\n",
       "       -0.3002783 ,  0.44608024,  1.938321  , -0.72941923,  0.94874084,\n",
       "       -0.19638109,  1.2977958 ,  0.91942734,  0.67938447, -0.65222347],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('الفيديو')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76afdc01",
   "metadata": {},
   "source": [
    "🪄size of vector in Wv."
=======
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b29ca1c",
   "metadata": {},
   "source": [
    "🪄Get the current state of the graph."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67935737",
   "metadata": {},
   "source": [
    "🪄Return the most similar model to the Wv - L divergence."
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5f3cca7",
   "metadata": {},
   "source": [
    "🪄Get the current state of the graph."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('الفديو', 0.8424222469329834),\n",
       " ('الفيديوهات', 0.8212994337081909),\n",
       " ('اليوم', 0.809577226638794),\n",
       " ('الوصفة', 0.8092324137687683),\n",
       " ('المختلسين', 0.7842799425125122),\n",
       " ('لفيديو', 0.7826778888702393),\n",
       " ('المنبر', 0.7803176641464233),\n",
       " ('الحلقة', 0.7770587205886841),\n",
       " ('الفيديوا', 0.7731214761734009),\n",
       " ('الاغنية', 0.7693439722061157)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('الفيديو')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309c0dc",
   "metadata": {},
   "source": [
    "🪄Return the value of the most similar model."
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "055467f8",
   "metadata": {},
   "source": [
    "🪄Make a dataframe of random values for the given list of values."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('صحة', 0.957695722579956),\n",
       " ('الصحه', 0.9494235515594482),\n",
       " ('صحه', 0.9477626085281372),\n",
       " ('ااصحة', 0.9430625438690186),\n",
       " ('العافيه', 0.938389778137207),\n",
       " ('الصحا', 0.934445858001709),\n",
       " ('ماتتمنى', 0.9239757657051086),\n",
       " ('العافية', 0.921890139579773),\n",
       " ('يمنيك', 0.921332597732544),\n",
       " ('ماتتمنا', 0.920365035533905)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('الصحة')"
=======
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list = [np.random.randint(0, 10) for x in range(10000)]\n",
    "env = np.zeros((10000, 100))\n",
    "i = 0\n",
    "for x in rand_list:\n",
    "    env[i][x] = 1\n",
    "    i += 1\n",
    "env = pd.DataFrame(env)"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "fd9e3e4d",
   "metadata": {},
   "source": [
    "🪄Return the value of the most similar model."
=======
   "id": "8f93ae39",
   "metadata": {},
   "source": [
    "🪄Sum the values of the environment variables."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 31,
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[('سوء', 0.8432469964027405),\n",
       " ('شر', 0.8258323669433594),\n",
       " ('فحياتها', 0.8234294056892395),\n",
       " ('اعتدى', 0.8075923323631287),\n",
       " ('مكروه', 0.8055546283721924),\n",
       " ('وشعبنا', 0.7985508441925049),\n",
       " ('امانيكم', 0.7867958545684814),\n",
       " ('يشافي', 0.7866781949996948),\n",
       " ('مقامها', 0.7856148481369019),\n",
       " ('الخير', 0.7848873138427734)]"
      ]
     },
     "execution_count": 42,
=======
       "10000.0"
      ]
     },
     "execution_count": 31,
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "model.wv.most_similar('خير')"
=======
    "env.sum().sum()"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "40771824",
   "metadata": {},
   "source": [
    "🪄Return the similarity between two words."
=======
   "id": "dccad063",
   "metadata": {},
   "source": [
    "🪄The value of the first environment entry in the list of values."
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.values[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef64e1",
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55149865"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='الخير', w2='صباح')"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e0683708a40e5e31be6eca1343e37f88fae9f778fb3fd433a047241db249add"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.6"
=======
   "version": "3.6.5"
>>>>>>> 19d7bacf3304de7f1189e6ee99c96415235d1a23
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

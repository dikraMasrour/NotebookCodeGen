{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing CodeBERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import torch\n",
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1342,  0.3599,  0.0361,  ..., -0.2329, -0.3161,  0.3294],\n",
       "         [-0.7013,  0.1173,  0.0651,  ..., -0.3564, -0.2514,  0.2654],\n",
       "         [-0.3371,  0.1115,  0.4299,  ..., -0.2361, -0.1156,  0.8037],\n",
       "         ...,\n",
       "         [-0.4057,  0.1638,  0.4813,  ..., -0.1657, -0.2869,  0.7310],\n",
       "         [-0.3968,  0.4617,  0.5130,  ..., -0.3096, -0.6014,  0.4400],\n",
       "         [-0.1354,  0.3618,  0.0367,  ..., -0.2342, -0.3183,  0.3317]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_tokens = tokenizer.tokenize(\"returns maximum value\")\n",
    "code_tokens = tokenizer.tokenize(\"def max(a,b): if a>b: return a else return b\")\n",
    "\n",
    "tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "context_embeddings = model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "context_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test codeBERT for md only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1342,  0.3342,  0.0396,  ..., -0.2193, -0.3251,  0.3286],\n",
       "         [-0.2917,  0.4377,  0.1195,  ..., -0.3086, -0.5924,  0.1050],\n",
       "         [ 0.0023,  0.2300, -0.0107,  ...,  0.0430, -0.4059,  0.0055],\n",
       "         [-0.1335,  0.3338,  0.0403,  ..., -0.2191, -0.3248,  0.3279]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_tokens = tokenizer.tokenize(\"returns category of a notebook\")\n",
    "\n",
    "tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]\n",
    "s\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "context_embeddings_md = model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "context_embeddings_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test codeBERT for code only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1264,  0.3699,  0.0476,  ..., -0.1938, -0.2802,  0.3096],\n",
       "         [-0.5152,  0.4615,  0.2745,  ..., -0.4479, -0.3483,  0.1919],\n",
       "         [-0.1253,  0.3687,  0.0483,  ..., -0.1938, -0.2787,  0.3072]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_tokens = tokenizer.tokenize(\n",
    "    \"\"\"for i in data.index:\n",
    "    if data.loc[i]['subcategory'] == sub:\n",
    "        categ = data.loc[i]['category']\n",
    "    \"\"\")\n",
    "\n",
    "tokens=[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "context_embeddings_code = model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "context_embeddings_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(context_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings.shape\n",
    "# 1 = number of batches\n",
    "# 23 = number of tokens\n",
    "# 768 = number of hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing embedding aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Credits: https://towardsdatascience.com/how-to-do-average-and-max-word-embedding-for-long-sentences-f3531e99d998*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tensor into np array\n",
    "tensor_np = context_embeddings_md.cpu().detach().numpy()\n",
    "# average of embeddings of the tokens in the sequence\n",
    "avg_md = np.mean(tensor_np[0], axis=0)\n",
    "len(avg_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tensor into np array\n",
    "tensor_np = context_embeddings_code.cpu().detach().numpy()\n",
    "# average of embeddings of the tokens in the sequence\n",
    "avg_code = np.mean(tensor_np[0], axis=0)\n",
    "len(avg_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the code and md sequences are semantically similar using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352593421936035"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = 1 - cosine(avg_md, avg_code)\n",
    "cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test CodeBERT for mask prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaTokenizer, RobertaForMaskedLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011970043182373047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading pytorch_model.bin",
       "rate": null,
       "total": 501201999,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1361d602686c4e079acecdf091239434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "mlm_model = RobertaForMaskedLM.from_pretrained(\"microsoft/codebert-base-mlm\")\n",
    "mlm_tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base-mlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.7230142951011658, 'token': 6595, 'token_str': ' import', 'sequence': ' importmatplotlib.pyplot as plt'}, {'score': 0.1273956149816513, 'token': 4, 'token_str': '.', 'sequence': '.matplotlib.pyplot as plt'}, {'score': 0.03073594532907009, 'token': 1215, 'token_str': '_', 'sequence': '_matplotlib.pyplot as plt'}, {'score': 0.023831013590097427, 'token': 479, 'token_str': '.', 'sequence': '.matplotlib.pyplot as plt'}, {'score': 0.010915211401879787, 'token': 18134, 'token_str': ' _', 'sequence': ' _matplotlib.pyplot as plt'}]\n"
     ]
    }
   ],
   "source": [
    "CODE = \"<mask> matplotlib.pyplot as plt\"\n",
    "mlm_model_name = \"microsoft/codebert-base-mlm\"\n",
    "fill_mask = pipeline('fill-mask', model=mlm_model, tokenizer=mlm_tokenizer)\n",
    "\n",
    "outputs = fill_mask(CODE)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test PLBART for code-to-text & text-to-code translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PLBartForConditionalGeneration, PLBartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plbarttokenizer = PLBartTokenizer.from_pretrained(\"uclanlp/plbart-python-en_XX\", src_lang=\"python\", tgt_lang=\"en_XX\")\n",
    "plbart_model = PLBartForConditionalGeneration.from_pretrained(\"uclanlp/plbart-python-en_XX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmasrour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Load the PLBartFornans class.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_python_phrase = \"plbart_model = PLBartForConditionalGeneration.from_pretrained('uclanlp/plbart-python-en_XX')\"\n",
    "inputs = plbarttokenizer(example_python_phrase, return_tensors=\"pt\")\n",
    "translated_tokens = plbart_model.generate(**inputs, decoder_start_token_id=plbarttokenizer.lang_code_to_id[\"en_XX\"])\n",
    "plbarttokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ^^Note to self: pretty good results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and test T5 for text to text tranformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49ab456e11cde720218fba409a85456f40f210cf294d5c8f56d5f4fb69af5c6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

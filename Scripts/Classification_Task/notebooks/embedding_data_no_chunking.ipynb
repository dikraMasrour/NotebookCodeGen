{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing CodeBERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import torch\n",
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1342,  0.3599,  0.0361,  ..., -0.2329, -0.3161,  0.3294],\n",
       "         [-0.7013,  0.1173,  0.0651,  ..., -0.3564, -0.2514,  0.2654],\n",
       "         [-0.3371,  0.1115,  0.4299,  ..., -0.2361, -0.1156,  0.8037],\n",
       "         ...,\n",
       "         [-0.4057,  0.1638,  0.4813,  ..., -0.1657, -0.2869,  0.7310],\n",
       "         [-0.3968,  0.4617,  0.5130,  ..., -0.3096, -0.6014,  0.4400],\n",
       "         [-0.1354,  0.3618,  0.0367,  ..., -0.2342, -0.3183,  0.3317]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_tokens = tokenizer.tokenize(\"returns maximum value\")\n",
    "code_tokens = tokenizer.tokenize(\"def max(a,b): if a>b: return a else return b\")\n",
    "\n",
    "tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "context_embeddings = model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "context_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test codeBERT for md only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1342,  0.3342,  0.0396,  ..., -0.2193, -0.3251,  0.3286],\n",
       "         [-0.2917,  0.4377,  0.1195,  ..., -0.3086, -0.5924,  0.1050],\n",
       "         [ 0.0023,  0.2300, -0.0107,  ...,  0.0430, -0.4059,  0.0055],\n",
       "         [-0.1335,  0.3338,  0.0403,  ..., -0.2191, -0.3248,  0.3279]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_tokens = tokenizer.tokenize(\"returns category of a notebook\")\n",
    "\n",
    "tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]\n",
    "\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "context_embeddings_md = model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "context_embeddings_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test codeBERT for code only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1264,  0.3699,  0.0476,  ..., -0.1938, -0.2802,  0.3096],\n",
       "         [-0.5152,  0.4615,  0.2745,  ..., -0.4479, -0.3483,  0.1919],\n",
       "         [-0.1253,  0.3687,  0.0483,  ..., -0.1938, -0.2787,  0.3072]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_tokens = tokenizer.tokenize(\n",
    "    \"\"\"for i in data.index:\n",
    "    if data.loc[i]['subcategory'] == sub:\n",
    "        categ = data.loc[i]['category']\n",
    "    \"\"\")\n",
    "\n",
    "tokens=[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "context_embeddings_code = model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "context_embeddings_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(context_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings.shape\n",
    "# 1 = number of batches\n",
    "# 23 = number of tokens\n",
    "# 768 = number of hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing embedding aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tensor into np array\n",
    "tensor_np = context_embeddings_md.cpu().detach().numpy()\n",
    "# average of embeddings of the tokens in the sequence\n",
    "avg_md = np.mean(tensor_np[0], axis=0)\n",
    "len(avg_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tensor into np array\n",
    "tensor_np = context_embeddings_code.cpu().detach().numpy()\n",
    "# average of embeddings of the tokens in the sequence\n",
    "avg_code = np.mean(tensor_np[0], axis=0)\n",
    "len(avg_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the code and md sequences are semantically similar using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352593421936035"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = 1 - cosine(avg_md, avg_code)\n",
    "cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test CodeBERT for mask prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaTokenizer, RobertaForMaskedLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011970043182373047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading pytorch_model.bin",
       "rate": null,
       "total": 501201999,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1361d602686c4e079acecdf091239434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "mlm_model = RobertaForMaskedLM.from_pretrained(\"microsoft/codebert-base-mlm\")\n",
    "mlm_tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base-mlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.7230142951011658, 'token': 6595, 'token_str': ' import', 'sequence': ' importmatplotlib.pyplot as plt'}, {'score': 0.1273956149816513, 'token': 4, 'token_str': '.', 'sequence': '.matplotlib.pyplot as plt'}, {'score': 0.03073594532907009, 'token': 1215, 'token_str': '_', 'sequence': '_matplotlib.pyplot as plt'}, {'score': 0.023831013590097427, 'token': 479, 'token_str': '.', 'sequence': '.matplotlib.pyplot as plt'}, {'score': 0.010915211401879787, 'token': 18134, 'token_str': ' _', 'sequence': ' _matplotlib.pyplot as plt'}]\n"
     ]
    }
   ],
   "source": [
    "CODE = \"<mask> matplotlib.pyplot as plt\"\n",
    "mlm_model_name = \"microsoft/codebert-base-mlm\"\n",
    "fill_mask = pipeline('fill-mask', model=mlm_model, tokenizer=mlm_tokenizer)\n",
    "\n",
    "outputs = fill_mask(CODE)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test PLBART for code-to-text & text-to-code translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PLBartForConditionalGeneration, PLBartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plbarttokenizer = PLBartTokenizer.from_pretrained(\"uclanlp/plbart-python-en_XX\", src_lang=\"python\", tgt_lang=\"en_XX\")\n",
    "plbart_model = PLBartForConditionalGeneration.from_pretrained(\"uclanlp/plbart-python-en_XX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmasrour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Load the PLBartFornans class.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_python_phrase = \"plbart_model = PLBartForConditionalGeneration.from_pretrained('uclanlp/plbart-python-en_XX')\"\n",
    "inputs = plbarttokenizer(example_python_phrase, return_tensors=\"pt\")\n",
    "translated_tokens = plbart_model.generate(**inputs, decoder_start_token_id=plbarttokenizer.lang_code_to_id[\"en_XX\"])\n",
    "plbarttokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ^^Note to self: pretty good results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and test T5 for text to text tranformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EMBEDDING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset containing clean text (code and md cells for each notebook and their category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'text_dataset.pkl', 'rb') as f:\n",
    "    text_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell-type</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd import numpy as np import ...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>markdown</td>\n",
       "      <td>try to overfit more pls upvote if you fork lik...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>markdown</td>\n",
       "      <td>sub1 0 869</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>markdown</td>\n",
       "      <td>credit very simple code with score 0 886 by ay...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd import numpy as np from sk...</td>\n",
       "      <td>0-9-try-better-parameters-better-score.ipynb</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cell-type                                             source  \\\n",
       "0      code  import pandas as pd import numpy as np import ...   \n",
       "1  markdown  try to overfit more pls upvote if you fork lik...   \n",
       "2  markdown                                         sub1 0 869   \n",
       "3  markdown  credit very simple code with score 0 886 by ay...   \n",
       "4      code  import pandas as pd import numpy as np from sk...   \n",
       "\n",
       "                                          title         tag  \n",
       "0  0-9-try-better-parameters-better-score.ipynb  regression  \n",
       "1  0-9-try-better-parameters-better-score.ipynb  regression  \n",
       "2  0-9-try-better-parameters-better-score.ipynb  regression  \n",
       "3  0-9-try-better-parameters-better-score.ipynb  regression  \n",
       "4  0-9-try-better-parameters-better-score.ipynb  regression  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332354, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell-type</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344966</th>\n",
       "      <td>code</td>\n",
       "      <td>POI_data = gpd.read_file(\"../input/geospatial...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344967</th>\n",
       "      <td>markdown</td>\n",
       "      <td>next we create a map from all four geodatafram...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344968</th>\n",
       "      <td>code</td>\n",
       "      <td>ax = counties.plot(figsize=(10,10), color='no...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344969</th>\n",
       "      <td>markdown</td>\n",
       "      <td>it looks like the northeastern part of the sta...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344970</th>\n",
       "      <td>markdown</td>\n",
       "      <td>have questions or comments visit the course di...</td>\n",
       "      <td>your-first-map.ipynb</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell-type                                             source  \\\n",
       "344966      code   POI_data = gpd.read_file(\"../input/geospatial...   \n",
       "344967  markdown  next we create a map from all four geodatafram...   \n",
       "344968      code   ax = counties.plot(figsize=(10,10), color='no...   \n",
       "344969  markdown  it looks like the northeastern part of the sta...   \n",
       "344970  markdown  have questions or comments visit the course di...   \n",
       "\n",
       "                       title                     tag  \n",
       "344966  your-first-map.ipynb  reinforcement learning  \n",
       "344967  your-first-map.ipynb  reinforcement learning  \n",
       "344968  your-first-map.ipynb  reinforcement learning  \n",
       "344969  your-first-map.ipynb  reinforcement learning  \n",
       "344970  your-first-map.ipynb  reinforcement learning  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332354, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = text_data.copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding each cell's tokens and averaging them to get a representation for the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_single_row(text, row):\n",
    "    \n",
    "    bert_tokens = tokenizer.tokenize(text)\n",
    "    # print('before', len(bert_tokens))\n",
    "    if len(bert_tokens) > 510: # we choose max_len to be 510 as the tokenizer then adds 2 special tokens <s> and </s>\n",
    "        bert_tokens = bert_tokens[:510]\n",
    "    # print('after', len(bert_tokens))\n",
    "    tokens=[tokenizer.cls_token]+bert_tokens+[tokenizer.sep_token]\n",
    "\n",
    "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    row_embeddings = model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "\n",
    "    if row_embeddings is not None:\n",
    "        return row_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_embeddings(embedding_tensor):\n",
    "    avg_rep = np.empty(1)\n",
    "    if embedding_tensor is not None:\n",
    "        # convert tensor into np array\n",
    "        tensor_np = embedding_tensor.cpu().detach().numpy()\n",
    "        # average of embeddings of the tokens in the sequence\n",
    "        avg_rep = np.mean(tensor_np[0], axis=0)\n",
    "        # return average representation of a sequence of tokens\n",
    "        return avg_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed by chunks of the dataset for time optimization reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_avg_embedding = []\n",
    "for row in text_data.index[:166177]:\n",
    "    embedding = embed_single_row(text_data.loc[row, 'source'], row)\n",
    "    row_avg_embedding.append((average_embeddings(embedding),  text_data.loc[row, 'title'], text_data.loc[row, 'tag']))\n",
    "    print(row)\n",
    "# build intermediary dataframe of averaged row vectors, titles and tags \n",
    "interm_df01 = pd.DataFrame(row_avg_embedding, columns = ['row_vector', 'title', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_avg_embedding = []\n",
    "for row in text_data.index[166177:(166177+100000)]:\n",
    "    embedding = embed_single_row(text_data.loc[row, 'source'], row)\n",
    "    row_avg_embedding.append((average_embeddings(embedding),  text_data.loc[row, 'title'], text_data.loc[row, 'tag']))\n",
    "    print(row)\n",
    "# build intermediary dataframe of averaged row vectors, titles and tags \n",
    "interm_df02 = pd.DataFrame(row_avg_embedding, columns = ['row_vector', 'title', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_avg_embedding = []\n",
    "for row in text_data.index[266177:]:\n",
    "    embedding = embed_single_row(text_data.loc[row, 'source'], row)\n",
    "    row_avg_embedding.append((average_embeddings(embedding),  text_data.loc[row, 'title'], text_data.loc[row, 'tag']))\n",
    "    print(row)\n",
    "# build intermediary dataframe of averaged row vectors, titles and tags \n",
    "interm_df03 = pd.DataFrame(row_avg_embedding, columns = ['row_vector', 'title', 'tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the vectorized chunks to pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_df01.to_pickle(DATA_PATH + 'interm_df_0_166176.pkl')\n",
    "interm_df02.to_pickle(DATA_PATH + 'interm_df_166177_266177.pkl')\n",
    "interm_df03.to_pickle(DATA_PATH + 'interm_df_266177_332354.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49ab456e11cde720218fba409a85456f40f210cf294d5c8f56d5f4fb69af5c6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

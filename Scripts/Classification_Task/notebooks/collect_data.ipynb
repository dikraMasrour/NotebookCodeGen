{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Python public API for data collection : Notebook Classification TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_KEYWORDS = '../data/search_keywords.csv'\n",
    "DATA_PATH_NOTEBOOKS = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file containing the search keywords used to retrieve notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lasso regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>randomforestregression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>sarsa</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ddpg</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>qlearning</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>markov decision</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               subcategory                category\n",
       "0        linear regression              regression\n",
       "1         lasso regression              regression\n",
       "2   randomforestregression              regression\n",
       "3         ridge regression              regression\n",
       "4             XGBRegressor              regression\n",
       "..                     ...                     ...\n",
       "89                   sarsa  reinforcement learning\n",
       "90                    ddpg  reinforcement learning\n",
       "91               qlearning  reinforcement learning\n",
       "92         markov decision  reinforcement learning\n",
       "93           reinforcement  reinforcement learning\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_df = pd.DataFrame(columns=['Category', 'Subcategory'])\n",
    "keywords_df = pd.read_csv(DATA_PATH_KEYWORDS, sep=';') \n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function returns the category of a Notebook based on its subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(sub,data):\n",
    "    for i in data.index:\n",
    "        if data.loc[i]['subcategory'] == sub:\n",
    "            return data.loc[i]['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['title','subcategory','category'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a notebook titles dataframe with category and subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API exception : \" amolambkar/multivariate-linear-regression-using-python-code \" Notebook not found\n",
      "Kaggle API exception : \" fabiendaniel/predicting-flight-delays-tutorial \" Notebook not found\n",
      "Kaggle API exception : \" fabiendaniel/predicting-flight-delays-tutorial \" Notebook not found\n",
      "Kaggle API exception : \" fabiendaniel/predicting-flight-delays-tutorial \" Notebook not found\n",
      "Kaggle API exception : \" vassylkorzh/crime-scale-prediction \" Notebook not found\n",
      "Kaggle API exception : \" juliojaavier/earth-surface-temperature \" Notebook not found\n",
      "Kaggle API exception : \" juliojaavier/earth-surface-temperature \" Notebook not found\n",
      "Kaggle API exception : \" juliojaavier/earth-surface-temperature \" Notebook not found\n",
      "Kaggle API exception : \" rbyron/simple-linear-regression-models \" Notebook not found\n",
      "Kaggle API exception : \" rbyron/simple-linear-regression-models \" Notebook not found\n",
      "Kaggle API exception : \" rbyron/simple-linear-regression-models \" Notebook not found\n",
      "Kaggle API exception : \" rbyron/simple-linear-regression-models \" Notebook not found\n",
      "Kaggle API exception : \" usamabalochhh/eda-xgbregressor-good-accuracy-with-explanation \" Notebook not found\n",
      "Kaggle API exception : \" vikassingh1996/extensive-data-preprocessing-and-modeling \" Notebook not found\n",
      "Kaggle API exception : \" vikassingh1996/extensive-data-preprocessing-and-modeling \" Notebook not found\n",
      "Kaggle API exception : \" devanshbesain/exploration-and-analysis-auto-mpg \" Notebook not found\n",
      "Kaggle API exception : \" devanshbesain/exploration-and-analysis-auto-mpg \" Notebook not found\n",
      "Kaggle API exception : \" venkatapadavala/house-prices-advanced-regression-practice \" Notebook not found\n",
      "Kaggle API exception : \" akouaorsot/mlr-medical-costs \" Notebook not found\n",
      "Kaggle API exception : \" masumrumi/a-detailed-regression-guide-with-house-pricing \" Notebook not found\n",
      "Kaggle API exception : \" kaanboke/car-price-prediction-beginner-friendly-94-3 \" Notebook not found\n",
      "Kaggle API exception : \" kaanboke/car-price-prediction-beginner-friendly-94-3 \" Notebook not found\n",
      "Kaggle API exception : \" brsdincer/fashionmnist-prediction-full-explanation \" Notebook not found\n",
      "Kaggle API exception : \" alaasedeeq/house-price-prediction-top-8 \" Notebook not found\n",
      "Kaggle API exception : \" alaasedeeq/house-price-prediction-top-8 \" Notebook not found\n",
      "Kaggle API exception : \" icaram/rapids-svr-boost-17-8 \" Notebook not found\n",
      "Kaggle API exception : \" elikplim/predict-the-burned-area-of-forest-fires \" Notebook not found\n",
      "Kaggle API exception : \" nilanml/eda-lasso \" Notebook not found\n",
      "Kaggle API exception : \" lemonad/nykdev-single-layer-perceptron \" Notebook not found\n",
      "Kaggle API exception : \" lemonad/nykdev-single-layer-perceptron \" Notebook not found\n",
      "Kaggle API exception : \" lemonad/nykdev-single-layer-perceptron \" Notebook not found\n",
      "Kaggle API exception : \" samhithvasikarla/banknote-authentication-with-multilayer-perceptron \" Notebook not found\n",
      "Kaggle API exception : \" imanjowkar/hyperparameter-effect-on-deep-learning-model-3 \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" vjchoudhary7/logistic-regression-model-in-hr-analytics \" Notebook not found\n",
      "Kaggle API exception : \" jsultan/visualizing-classifier-boundaries-using-kernel-pca \" Notebook not found\n",
      "Kaggle API exception : \" paotografi/customer-churn-eda-95-acc-and-85-recall \" Notebook not found\n",
      "Kaggle API exception : \" cdeotte/private-lb-probing-0-950 \" Notebook not found\n",
      "Kaggle API exception : \" cdeotte/private-lb-probing-0-950 \" Notebook not found\n",
      "Kaggle API exception : \" degravek/a-naive-bayes-tweet-classifier \" Notebook not found\n",
      "Kaggle API exception : \" ranjeetjain3/visualization-machine-learning-deep-learning \" Notebook not found\n",
      "Kaggle API exception : \" kanncaa1/applying-text-mining \" Notebook not found\n",
      "Kaggle API exception : \" rxsraghavagrawal/music-genre-classification-using-knn-begineers \" Notebook not found\n",
      "Kaggle API exception : \" sulianova/knn-and-na-ve-bayes-approaches \" Notebook not found\n",
      "Kaggle API exception : \" dktalaicha/diabetes-prediction-by-knn \" Notebook not found\n",
      "Kaggle API exception : \" nicapotato/titanic-voting-pipeline-stack-and-guide \" Notebook not found\n",
      "Kaggle API exception : \" rajeshjnv/mall-customer-visually-analysis-k-means \" Notebook not found\n",
      "Kaggle API exception : \" beezus666/k-means-and-feature-importance-for-articles \" Notebook not found\n",
      "Kaggle API exception : \" akashchola/customer-segmentation-rfm-model-k-means \" Notebook not found\n",
      "Kaggle API exception : \" gauravduttakiit/clustering-using-k-means-hierarchical-pca \" Notebook not found\n",
      "Kaggle API exception : \" gauravduttakiit/clustering-using-k-means-hierarchical-pca \" Notebook not found\n",
      "Kaggle API exception : \" singhnproud77/hierarchical-clustering-telco-customer-churn \" Notebook not found\n",
      "Kaggle API exception : \" manohar676/a-complete-giude-of-ml-workflow-with-python \" Notebook not found\n",
      "Kaggle API exception : \" agustinpugliese/clustering-model-comparison-with-plotly \" Notebook not found\n",
      "Kaggle API exception : \" jagdmir/help-international-clustering-pca \" Notebook not found\n",
      "Kaggle API exception : \" rsesha/pycaret-vs-auto-viml-on-reg-class-nlp \" Notebook not found\n",
      "Kaggle API exception : \" rsesha/pycaret-vs-auto-viml-on-reg-class-nlp \" Notebook not found\n",
      "Kaggle API exception : \" habibmrad1983/awesome-ml-frameworks-and-mnist-classification \" Notebook not found\n",
      "Kaggle API exception : \" avnika22/world-happiness-report-eda-clustering \" Notebook not found\n",
      "Kaggle API exception : \" avnika22/world-happiness-report-eda-clustering \" Notebook not found\n",
      "Kaggle API exception : \" avnika22/world-happiness-report-eda-clustering \" Notebook not found\n",
      "Kaggle API exception : \" kmader/cellcnn-overview \" Notebook not found\n",
      "Kaggle API exception : \" tadeumesquita/rain-in-australa-random-forest \" Notebook not found\n",
      "Kaggle API exception : \" vedanth777/clustering-customers-heirarchical-pcaplot \" Notebook not found\n",
      "Kaggle API exception : \" pmrich/clustering-approaches-k-mean-birch-agg \" Notebook not found\n",
      "Kaggle API exception : \" tpe3egol/player-characteristics \" Notebook not found\n",
      "Kaggle API exception : \" michaelmeeker/wip-bank-customer-rmf-and-segementation \" Notebook not found\n",
      "Kaggle API exception : \" ayakhaled2/steam-game-analysis \" Notebook not found\n",
      "Kaggle API exception : \" saymasultantufan/k-means-and-birch \" Notebook not found\n",
      "Kaggle API exception : \" shilpyp/world-happiness-report-clustering-analysis-v1 \" Notebook not found\n",
      "Kaggle API exception : \" keisei/tempbook \" Notebook not found\n",
      "Kaggle API exception : \" keisei/tempbook \" Notebook not found\n",
      "Kaggle API exception : \" geetanjali1sharma/data-analysis-for-a-hotel-rating-and-reservations \" Notebook not found\n",
      "Kaggle API exception : \" hitashukanjani/ds5220mergerprediction \" Notebook not found\n",
      "Kaggle API exception : \" piercnic/unsupervised-k-means \" Notebook not found\n",
      "Kaggle API exception : \" mayureshnm/tps-july-22-with-mini-batch-k-means-clustering \" Notebook not found\n",
      "Kaggle API exception : \" nataliashcheglova/clustering-k-means-agglomerative-dbscan \" Notebook not found\n",
      "Kaggle API exception : \" ravirajsinh45/global-wheat-yolo-labels \" Notebook not found\n",
      "Kaggle API exception : \" chizuchizu/japanese-extraction-of-importance \" Notebook not found\n",
      "Kaggle API exception : \" jiangstein/a-very-simple-siamese-network-in-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" sjyangkevin/tf-cots-yolov5-training-pipeline \" Notebook not found\n",
      "Kaggle API exception : \" sjyangkevin/tf-cots-yolov5-training-pipeline \" Notebook not found\n",
      "Kaggle API exception : \" akensert/rsna-inceptionv3-keras-tf1-14-0 \" Notebook not found\n",
      "Kaggle API exception : \" ar2017/pytorch-efficientnet-train-aug-cutmix-fmix \" Notebook not found\n",
      "Kaggle API exception : \" kozodoi/local-installation-for-efficientnet-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" gauravduttakiit/anime-vs-cartoon-mobilenetv2-model \" Notebook not found\n",
      "Kaggle API exception : \" rutwikhiwalkar/introduction-to-transfer-learning-inceptionv3 \" Notebook not found\n",
      "Kaggle API exception : \" aziz69/efficientnets-meta-data-augs-0-939-public-lb \" Notebook not found\n",
      "Kaggle API exception : \" rajkumarl/get-started-with-semantic-segmentation \" Notebook not found\n",
      "Kaggle API exception : \" rajkumarl/get-started-with-semantic-segmentation \" Notebook not found\n",
      "Kaggle API exception : \" giosiolas/3-tensorflow-2-cifar-100-ipynb \" Notebook not found\n",
      "Kaggle API exception : \" mostafaibrahim17/yolov5-vinbigdata \" Notebook not found\n",
      "Kaggle API exception : \" remekkinas/funny-cv-eda-what-we-see-here \" Notebook not found\n",
      "Kaggle API exception : \" xinruizhuang/skin-lesion-classification-acc-90-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" andradaolteanu/sentiment-analysis-rick-and-morty-scripts \" Notebook not found\n",
      "Kaggle API exception : \" andradaolteanu/sentiment-analysis-rick-and-morty-scripts \" Notebook not found\n",
      "Kaggle API exception : \" blessondensil294/beginner-nlp-product-sentiment-analysis-textblob \" Notebook not found\n",
      "Kaggle API exception : \" nirant/hitchhiker-s-guide-to-nlp-in-spacy \" Notebook not found\n",
      "Kaggle API exception : \" tientd95/understanding-attention-in-neural-network \" Notebook not found\n",
      "Kaggle API exception : \" tientd95/understanding-attention-in-neural-network \" Notebook not found\n",
      "Kaggle API exception : \" uom170589c/mbart-model2-part-1 \" Notebook not found\n",
      "Kaggle API exception : \" itratrahman/nlp-tutorial-using-python \" Notebook not found\n",
      "Kaggle API exception : \" zhenyufan/nlp-for-yelp-reviews \" Notebook not found\n",
      "Kaggle API exception : \" zhenyufan/nlp-for-yelp-reviews \" Notebook not found\n",
      "Kaggle API exception : \" zhenyufan/nlp-for-yelp-reviews \" Notebook not found\n",
      "Kaggle API exception : \" zhenyufan/nlp-for-yelp-reviews \" Notebook not found\n",
      "Kaggle API exception : \" saurabh48782/nlp-using-spacy-library-part-1 \" Notebook not found\n",
      "Kaggle API exception : \" yuanzhezhou/ai4code-distilbert-inference-777 \" Notebook not found\n",
      "Kaggle API exception : \" letnzle/t5anddemosystem \" Notebook not found\n",
      "Kaggle API exception : \" kabure/qa-eda-and-nlp-modelling-insights-vis-bert \" Notebook not found\n",
      "Kaggle API exception : \" mpwolke/moby-dick-election-and-battles \" Notebook not found\n",
      "Kaggle API exception : \" mpwolke/moby-dick-election-and-battles \" Notebook not found\n",
      "Kaggle API exception : \" mpwolke/moby-dick-election-and-battles \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" succinctlyai/midjourney-text-prompts-huggingface \" Notebook not found\n",
      "Kaggle API exception : \" succinctlyai/midjourney-text-prompts-huggingface \" Notebook not found\n",
      "Kaggle API exception : \" rihab147/arabert-pytorch-arabic-texts \" Notebook not found\n",
      "Kaggle API exception : \" theoviel/bert-for-question-answering-baseline-inference \" Notebook not found\n",
      "Kaggle API exception : \" theoviel/bert-for-question-answering-baseline-inference \" Notebook not found\n",
      "Kaggle API exception : \" shujian/single-rnn-with-5-folds-snapshot-ensemble \" Notebook not found\n",
      "Kaggle API exception : \" shujian/single-rnn-with-5-folds-snapshot-ensemble \" Notebook not found\n",
      "Kaggle API exception : \" anirbansen3027/jtcc-word2vec \" Notebook not found\n",
      "Kaggle API exception : \" satian/a-look-at-different-embeddings-with-attention \" Notebook not found\n",
      "Kaggle API exception : \" sergeykalutsky/pytorch-starter \" Notebook not found\n",
      "Kaggle API exception : \" kunihikofurugori/torch-multidml-img-text-tfidf-faiss \" Notebook not found\n",
      "Kaggle API exception : \" kunihikofurugori/torch-multidml-img-text-tfidf-faiss \" Notebook not found\n",
      "Kaggle API exception : \" kailex/tidy-xgboost-glmnet-text2vec-lsa \" Notebook not found\n",
      "Kaggle API exception : \" charumakhijani/nlp-tutorial-countvectorizer-tfidf-onehotvector \" Notebook not found\n",
      "Kaggle API exception : \" subhasom/covid-19-chatbot \" Notebook not found\n",
      "Kaggle API exception : \" elvinagammed/starter-intent-recognition-chatbot-8da964e5-5 \" Notebook not found\n",
      "Kaggle API exception : \" lolik228/a2c-try \" Notebook not found\n",
      "Kaggle API exception : \" ariskoutris/nn-ex4 \" Notebook not found\n",
      "Kaggle API exception : \" oskarfirlej/exercise-deep-reinforcement-learning \" Notebook not found\n",
      "Kaggle API exception : \" jhowjhow/mountaincar-dqn \" Notebook not found\n",
      "Kaggle API exception : \" jhowjhow/mountaincar-dqn \" Notebook not found\n",
      "Kaggle API exception : \" mahoy00/deep-reinforcement-learning-on-stock-data \" Notebook not found\n",
      "Kaggle API exception : \" kooaslansefat/concept-drift-adversarial-validation-safeml \" Notebook not found\n",
      "Kaggle API exception : \" jeremygodden/my-self-made-data-science-masters-curriculum \" Notebook not found\n",
      "Kaggle API exception : \" sofyalaskina/covid-19-literature-clustering-part-3 \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n"
     ]
    }
   ],
   "source": [
    "for keyword in keywords_df['subcategory']:\n",
    "    for i in range(1,11):\n",
    "        try :\n",
    "                kernels = api.kernels_list(search = keyword, page=i)\n",
    "                for kernel in kernels:\n",
    "                    # print(kernel.ref)\n",
    "                    df.loc[len(df)]=[kernel.ref,keyword,search(keyword,keywords_df)]\n",
    "        except Exception as e:\n",
    "            print('Kaggle API exception : \"', kernel.ref, '\" Notebook not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudhirnl7/linear-regression-tutorial</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goyalshalini93/car-price-prediction-linear-reg...</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>divan0/multiple-linear-regression</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthonypino/price-analysis-and-linear-regression</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vivinbarath/simple-linear-regression-for-salar...</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10458</th>\n",
       "      <td>fanbyprinciple/reinforcement-learning-on-opena...</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10459</th>\n",
       "      <td>alexisbcook/exercise-one-step-lookahead</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10460</th>\n",
       "      <td>alexisbcook/exercise-interactive-maps</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10461</th>\n",
       "      <td>lbarbosa/connectx-deep-reinforcement-learning</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10462</th>\n",
       "      <td>hsperr/halite-iv-dqn-example-pytorch</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10463 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title        subcategory  \\\n",
       "0                   sudhirnl7/linear-regression-tutorial  linear regression   \n",
       "1      goyalshalini93/car-price-prediction-linear-reg...  linear regression   \n",
       "2                      divan0/multiple-linear-regression  linear regression   \n",
       "3       anthonypino/price-analysis-and-linear-regression  linear regression   \n",
       "4      vivinbarath/simple-linear-regression-for-salar...  linear regression   \n",
       "...                                                  ...                ...   \n",
       "10458  fanbyprinciple/reinforcement-learning-on-opena...      reinforcement   \n",
       "10459            alexisbcook/exercise-one-step-lookahead      reinforcement   \n",
       "10460              alexisbcook/exercise-interactive-maps      reinforcement   \n",
       "10461      lbarbosa/connectx-deep-reinforcement-learning      reinforcement   \n",
       "10462               hsperr/halite-iv-dqn-example-pytorch      reinforcement   \n",
       "\n",
       "                     category  \n",
       "0                  regression  \n",
       "1                  regression  \n",
       "2                  regression  \n",
       "3                  regression  \n",
       "4                  regression  \n",
       "...                       ...  \n",
       "10458  reinforcement learning  \n",
       "10459  reinforcement learning  \n",
       "10460  reinforcement learning  \n",
       "10461  reinforcement learning  \n",
       "10462  reinforcement learning  \n",
       "\n",
       "[10463 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hsperr/halite-iv-dqn-example-pytorch'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.kernels_list(search = 'Halite IV - DQN example - PyTorch')[0].ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                               title        subcategory  \\\n",
       " 0               sudhirnl7/linear-regression-tutorial  linear regression   \n",
       " 1  goyalshalini93/car-price-prediction-linear-reg...  linear regression   \n",
       " 2                  divan0/multiple-linear-regression  linear regression   \n",
       " 3   anthonypino/price-analysis-and-linear-regression  linear regression   \n",
       " 4  vivinbarath/simple-linear-regression-for-salar...  linear regression   \n",
       " 5                 foxtreme/linear-regression-project  linear regression   \n",
       " 6  aakashns/pytorch-basics-linear-regression-from...  linear regression   \n",
       " 7  nitindatta/fifa-in-depth-analysis-with-linear-...  linear regression   \n",
       " 8   ashydv/sales-prediction-simple-linear-regression  linear regression   \n",
       " 9                       aminizahra/linear-regression  linear regression   \n",
       " \n",
       "      category  \n",
       " 0  regression  \n",
       " 1  regression  \n",
       " 2  regression  \n",
       " 3  regression  \n",
       " 4  regression  \n",
       " 5  regression  \n",
       " 6  regression  \n",
       " 7  regression  \n",
       " 8  regression  \n",
       " 9  regression  ,\n",
       " (10463, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10), df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataframe to a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_PATH_NOTEBOOKS+'ntb_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer vision</td>\n",
       "      <td>25.269999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nlp</td>\n",
       "      <td>24.553187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clustering</td>\n",
       "      <td>17.385071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression</td>\n",
       "      <td>14.479595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classification</td>\n",
       "      <td>11.468986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reinforcement learning</td>\n",
       "      <td>5.505113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clusterings</td>\n",
       "      <td>1.338048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category      means\n",
       "0         computer vision  25.269999\n",
       "1                     nlp  24.553187\n",
       "2              clustering  17.385071\n",
       "3              regression  14.479595\n",
       "4          classification  11.468986\n",
       "5  reinforcement learning   5.505113\n",
       "6             clusterings   1.338048"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = (df.category.value_counts() / len(df)) * 100\n",
    "\n",
    "meansdf = pd.DataFrame(columns=['category', 'means'])\n",
    "meansdf.category = means.index\n",
    "meansdf.means = means.values\n",
    "\n",
    "meansdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category', ylabel='means'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x='category', y='means', data=meansdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before collecting\n",
    "- Delete duplicate notebooks : print duplicate categories => choose best category to keep\n",
    "- Delete notebooks with non-english titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudhirnl7/linear-regression-tutorial</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goyalshalini93/car-price-prediction-linear-reg...</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>divan0/multiple-linear-regression</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthonypino/price-analysis-and-linear-regression</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vivinbarath/simple-linear-regression-for-salar...</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        subcategory  \\\n",
       "0               sudhirnl7/linear-regression-tutorial  linear regression   \n",
       "1  goyalshalini93/car-price-prediction-linear-reg...  linear regression   \n",
       "2                  divan0/multiple-linear-regression  linear regression   \n",
       "3   anthonypino/price-analysis-and-linear-regression  linear regression   \n",
       "4  vivinbarath/simple-linear-regression-for-salar...  linear regression   \n",
       "\n",
       "     category  \n",
       "0  regression  \n",
       "1  regression  \n",
       "2  regression  \n",
       "3  regression  \n",
       "4  regression  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH_NOTEBOOKS+'ntb_list.csv', sep=',', encoding='utf-8', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10463, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dict with duplicate titles and their respective positions in the df\n",
    "duplicates = df[df.duplicated('title', keep=False)].groupby('title').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def to_be_dropped_indices(dictionary):\n",
    "    to_be_dropped = [] # indices to be dropped from original df\n",
    "    temp = []\n",
    "\n",
    "    for k,v in dictionary.items():\n",
    "        duplicates_df = df[df.index.isin(v.values)]\n",
    "        \n",
    "        # if the rows have the same category, they are all dropped except the last one\n",
    "        if len(set(list(duplicates_df.category))) == 1:\n",
    "            to_be_dropped.append(list(duplicates_df.index[:len(duplicates_df.category)-1]))\n",
    "\n",
    "        else: \n",
    "            # drop least common category duplicates for a notebook\n",
    "            dup_counter = collections.Counter(duplicates_df.category)\n",
    "            most_common = dup_counter.most_common()[0][0]\n",
    "            most_common_i = duplicates_df.index.where(duplicates_df.category == most_common).dropna()[0]\n",
    "\n",
    "            to_be_dropped.append(duplicates_df.index.where(duplicates_df.index != most_common_i).dropna())\n",
    "\n",
    "    return flatten_list(to_be_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting indices of rows to be dropped (duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1866, [951, 7211.0, 2983, 3555, 2819, 3342, 3606, 3802, 3944, 4069])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_dropped = to_be_dropped_indices(duplicates)\n",
    "len(to_be_dropped), to_be_dropped[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8597, 3)\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "df_clean.drop(to_be_dropped, inplace=True)\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing non-english titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize keywords\n",
    "def list_to_unique_words(list):\n",
    "    unique_words = []\n",
    "    for l in list:\n",
    "        unique_words.append(str(l).lower().split())\n",
    "\n",
    "    return flatten_list(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the default *nltk* words list to add our categories and subcategories and other custom words that are domain specific to avoid them being removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_categ = list_to_unique_words(list(keywords_df.category))\n",
    "lower_subcateg = list_to_unique_words(list(keywords_df.subcategory))\n",
    "custom_list = ['dataset', 'datasets', 'feature', 'transformer', 'transformers', 'using', 'detect', 'detecting', 'machine', 'intro', 'pca', 'connectx', 'xgboost', 'visualising', 'visualizing', 'gaussian', 'bayesian', 'score', 'scores', 'map', 'maps', 'ml', 'dl', 'algorithm', 'algorithms', 'feature', 'features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('words')\n",
    "\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "words.update(lower_categ)\n",
    "words.update(lower_subcateg)\n",
    "words.update(custom_list)\n",
    "\n",
    "# exepected non-english indices : 353 1594 1640 1584 1664 4412 8273 11540 1081 1715 1642 4693 5320 7295 10615 11629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_non_english(df, word_list):\n",
    "    non_english = []\n",
    "    for row in df.index:\n",
    "        \n",
    "        title = df.loc[row, 'title']\n",
    "        try:\n",
    "            # print(df.loc[row, 'title'])\n",
    "            # title = \"Chaii EDA&Baseline 実況\"\n",
    "            clean_title = \" \".join(w for w in nltk.wordpunct_tokenize(title) \\\n",
    "                    if w.lower() in word_list or not w.isalpha())\n",
    "\n",
    "            if ((len(title.split()) - len(clean_title.split())) > 3) or len(clean_title.split()) == 0: \n",
    "                non_english.append(row) # builds list of titles with low # of english words\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return non_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_english = clean_non_english(df_clean, words)\n",
    "non_english[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually detect few titles of notebooks not written in english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_non_english = [353, 1594, 1640, 1584, 1664, 4412, 8273, 11540, 1081, 1715, 1642, 4693, 5320, 7295, 10615, 11629]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_english_to_be_dropped = intersection(non_english, detected_non_english)\n",
    "non_english_to_be_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(non_english_to_be_dropped, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8597, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write it the list of notebooks to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(DATA_PATH_NOTEBOOKS+'ntb_list_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting notebooks by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API exception :  onrcan/spectral-clustering Notebook not found\n",
      "Kaggle API exception :  sujoys/spectral-clustering Notebook not found\n",
      "Kaggle API exception :  saymasultantufan/k-means-and-birch Notebook not found\n",
      "Kaggle API exception :  mushfiqurrahmanrifat/assignment-birch-clustering Notebook not found\n",
      "Kaggle API exception :  vishnumandala/twitter-sentiment-analysis-using-denclue Notebook not found\n",
      "Kaggle API exception :  bagriaditya/minibatchkmeans Notebook not found\n",
      "Kaggle API exception :  sarthakmaniar27/kmeans-and-kmedoids Notebook not found\n",
      "Kaggle API exception :  ashishpatel26/dbscan Notebook not found\n"
     ]
    }
   ],
   "source": [
    "for i in df_clean.index :\n",
    "        try :\n",
    "                api.kernels_pull(df_clean.loc[i]['title'], path = DATA_PATH_NOTEBOOKS + df_clean.loc[i]['category'])\n",
    "        except Exception as e:\n",
    "            print('Kaggle API exception : ', kernel.ref, 'Notebook not found')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49ab456e11cde720218fba409a85456f40f210cf294d5c8f56d5f4fb69af5c6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

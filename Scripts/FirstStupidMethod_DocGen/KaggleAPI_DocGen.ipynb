{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Python public API for data collection\n",
    "### Documentation generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the default download directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dmasrour\\\\Documents\\\\NotebookCodeGen\\\\Scripts\\\\FirstStupidMethod'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddir = kaggle.api.get_default_download_dir()\n",
    "ddir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List 'getting started' competitions sorted by number of teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompetitionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>titanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>house-prices-advanced-regression-techniques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spaceship-titanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digit-recognizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nlp-getting-started</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>store-sales-time-series-forecasting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word2vec-nlp-tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>connectx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data-science-london-scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>facial-keypoints-detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tpu-getting-started</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gan-getting-started</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>street-view-getting-started-with-julia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>just-the-basics-strata-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                CompetitionName\n",
       "0                                       titanic\n",
       "1   house-prices-advanced-regression-techniques\n",
       "2                             spaceship-titanic\n",
       "3                              digit-recognizer\n",
       "4                           nlp-getting-started\n",
       "5           store-sales-time-series-forecasting\n",
       "6                         word2vec-nlp-tutorial\n",
       "7                                      connectx\n",
       "8              data-science-london-scikit-learn\n",
       "9                    facial-keypoints-detection\n",
       "10                          tpu-getting-started\n",
       "11                          gan-getting-started\n",
       "12       street-view-getting-started-with-julia\n",
       "13                 contradictory-my-dear-watson\n",
       "14                  just-the-basics-strata-2013\n",
       "15              just-the-basics-the-after-party"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competitions = pd.DataFrame(kaggle.api.competitions_list(category='gettingStarted', sort_by='numberOfTeams'), columns=['CompetitionName'])\n",
    "competitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List first 10 most voted notebooks from competitions retreived above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_nb = {}\n",
    "for c in competitions['CompetitionName']:\n",
    "    # print(c)\n",
    "    try:\n",
    "        notebooks = kaggle.api.kernels_list(page_size=10, competition=str(c), kernel_type='notebook', sort_by='voteCount')\n",
    "        comp_nb[c] = notebooks\n",
    "    except Exception as e:\n",
    "        print('Kaggle API exception : Notebook not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{titanic: [Titanic Data Science Solutions,\n",
       "  Titanic Tutorial,\n",
       "  Introduction to Ensembling/Stacking in Python,\n",
       "  A Data Science Framework: To Achieve 99% Accuracy,\n",
       "  Titanic Top 4% with ensemble modeling,\n",
       "  EDA To Prediction(DieTanic),\n",
       "  Titanic - Advanced Feature Engineering Tutorial,\n",
       "  A Journey through Titanic,\n",
       "  A Statistical Analysis & ML workflow of Titanic,\n",
       "  Titanic Survival Predictions (Beginner)],\n",
       " house-prices-advanced-regression-techniques: [Comprehensive data exploration with Python,\n",
       "  Stacked Regressions : Top 4% on LeaderBoard,\n",
       "  Regularized Linear Models,\n",
       "  Submitting From A Kernel,\n",
       "  Handling Missing Values,\n",
       "  XGBoost,\n",
       "  A study on Regression applied to the Ames dataset,\n",
       "  How I made top 0.3% on a Kaggle competition,\n",
       "  Using Categorical Data with One Hot Encoding,\n",
       "  Selecting and Filtering in Pandas],\n",
       " spaceship-titanic: [üöÄSpaceship Titanic -üìäEDA + 27 different modelsüìà,\n",
       "  üöÄ Spaceship Titanic: A complete guide üèÜ,\n",
       "  All Imputation Techniques with Pros and Cons,\n",
       "  üöÄüöÄ[TensorFlow]SpaceShip - NeuralDecisionForests,\n",
       "  üöÄ[Pycaret] Visualization + Optimization (0.81),\n",
       "  ‚öôÔ∏è MLops | How to be Rock of ML ‚öôÔ∏è,\n",
       "  Mastering Bias-Variance Tradeoff ,\n",
       "  [Spaceship Titanic] Fast kernel using sklearnex,\n",
       "  üöÄ Spaceship Titanic: EDA + PyTorch Baseline + W&B,\n",
       "  ML Foundation ‚û°Ô∏è Cross Validation ‚úÖ All Methods],\n",
       " digit-recognizer: [Introduction to CNN Keras - 0.997 (top 6%),\n",
       "  Pytorch Tutorial for Deep Learning Lovers,\n",
       "  Deep Neural Network Keras way,\n",
       "  Interactive Intro to Dimensionality Reduction,\n",
       "  Convolutional Neural Network (CNN) Tutorial,\n",
       "  25 Million Images! [0.99757] MNIST,\n",
       "  TensorFlow deep NN,\n",
       "  Knowledge Graph & NLP Tutorial-(BERT,spaCy,NLTK),\n",
       "  How to choose CNN Architecture MNIST,\n",
       "  MLP simples com Keras para Iniciantes],\n",
       " nlp-getting-started: [Basic EDA,Cleaning and GloVe,\n",
       "  NLP with Disaster Tweets - EDA, Cleaning and BERT,\n",
       "  NLP Getting Started Tutorial,\n",
       "  Knowledge Graph & NLP Tutorial-(BERT,spaCy,NLTK),\n",
       "  NLP - EDA, Bag of Words, TF IDF, GloVe, BERT,\n",
       "  Useful Python libraries for Data Science,\n",
       "  üìöNatural Language Processing (NLP)üßæfor Beginners,\n",
       "  Disaster NLP: Keras BERT using TFHub,\n",
       "  In-Depth Guide üìô to Google's BERT  ,\n",
       "  NLP üìù GloVe, BERT, TF-IDF, LSTM... üìù Explained],\n",
       " store-sales-time-series-forecasting: [Store Sales TS Forecasting - A Comprehensive Guide,\n",
       "  üìùStore Sales Analysis‚è≥ Time Serie,\n",
       "  üìàExploring Time Series plots: Beginners Guideüìà,\n",
       "  üéìEconometrics is all you needüéì,\n",
       "  Mastering Bias-Variance Tradeoff ,\n",
       "  Store Sales. Time Series Forecast & Visualization,\n",
       "  First kaggle notebook. Following TS tutorial,\n",
       "  ML Foundation ‚û°Ô∏è Cross Validation ‚úÖ All Methods,\n",
       "  [study series] Uplift modeling,\n",
       "  Hyperparamaters],\n",
       " word2vec-nlp-tutorial: [A Detailed Explanation of Keras Embedding Layer,\n",
       "  IMDB Review  - Deep Model ~ 94.89% Accuracy,\n",
       "  IMDB review Word2Vec & BiLSTM - 99% acc,\n",
       "  Google movie reviews sentiment Deep stack models ,\n",
       "  IMDB Review Data,\n",
       "  Bag of Words,\n",
       "  Popcorn RNN model,\n",
       "  NLP - Word2Vec,\n",
       "  .93 f-score Bag of Words M Bags of Popcorn with RF,\n",
       "  Meets Bags of Popcorn - A Beginner's Notebook],\n",
       " connectx: [ConnectX Getting Started,\n",
       "  Play the Game,\n",
       "  ConnectX with Q-Learning,\n",
       "  ConnectX with Deep Q-Learning,\n",
       "  Create a ConnectX agent,\n",
       "  Deep Reinforcement Learning,\n",
       "  One-Step Lookahead,\n",
       "  N-Step Lookahead,\n",
       "  Reinforcement Learning Chess 1: Policy Iteration,\n",
       "  ConnectX Baseline],\n",
       " data-science-london-scikit-learn: [Data Science London + Scikit ,\n",
       "  Data Science London  Classification ,\n",
       "  Data Science London + Scikit-learn Modeling,\n",
       "  Data_Science_London_Classification,\n",
       "  Data Science London + Scikit-learn,\n",
       "  Data Visualization & Preprocessing & GridSearchCV ,\n",
       "  Simple Gaussian + LGBM: data-science-london,\n",
       "  DS london explaining GaussianMixture preprocessing,\n",
       "  Gaussian Mixture and Grid Search,\n",
       "  Hello, scikit-learn!],\n",
       " facial-keypoints-detection: [Facial Keypoint Detection ,\n",
       "  Data Augmentation for Facial Keypoint Detection,\n",
       "  Basic Fully Connected NN,\n",
       "  facial-keypoints-detection,\n",
       "  Facial Keypoint Detection Udacity,\n",
       "  Facial Keypoint Detection - CNN + Augmentation,\n",
       "  Easy keras facial keypoint detection,\n",
       "  Keras Facial Keypoint Analysis,\n",
       "  Facial Keypoints Detection - Keras+Albumentations,\n",
       "  Image Processing - Face Keypoint Detection],\n",
       " tpu-getting-started: [Rotation Augmentation GPU/TPU - [0.96+],\n",
       "  Create Your First Submission,\n",
       "  CutMix and MixUp on GPU/TPU,\n",
       "  TFRecords Basics,\n",
       "  Computer Vision - Petals to the Metalüåªüå∏üåπ,\n",
       "  FC Ensemble External Data (EffNet+DenseNet),\n",
       "  [JAX+FLAX+TF.DATA] Vision Transformers Tutorial üöÄ,\n",
       "  Flower Classification with TPUs - EDA and Baseline,\n",
       "  TF: Hybrid EfficientNet Swin-Transformer : GradCAM,\n",
       "  A Simple Petals TF 2.2 notebook],\n",
       " gan-getting-started: [Monet CycleGAN Tutorial,\n",
       "  Introduction to CycleGAN - Monet paintings,\n",
       "  Transfering Style!,\n",
       "  Generate Paintings By Image Style Transfer,\n",
       "  Monet - Visualization and Augmentation,\n",
       "  Improving CycleGAN - Monet paintings,\n",
       "  Getting started with GANs ,\n",
       "  UPIT -a package for unpaired img2img translation,\n",
       "  CycleGAN_Pytorch,\n",
       "  The Beauty of CycleGAN],\n",
       " street-view-getting-started-with-julia: [And the Winner is - spaCy Render,\n",
       "  ocr using different methods in python,\n",
       "  second_attempt_2,\n",
       "  fastai_cv,\n",
       "  Character Recognition CNN,\n",
       "  Julia [EN/ES] prediction ü§®,\n",
       "  Julia],\n",
       " contradictory-my-dear-watson: [Tutorial Notebook,\n",
       "  Text-Representations,\n",
       "  TPU Sherlocked: One-stop for ü§ó with TF,\n",
       "  Text Analysis|Topic Modelling with spaCy &¬†GENSIM,\n",
       "  Basics of BERT and XLM-RoBERTa - PyTorch,\n",
       "  Contradictory Watson: Concise Keras XLM-R on TPU,\n",
       "  Watson NLI with Tensorflow and Transformers,\n",
       "  Watson - KFold XLM-R + Translation Augmentation,\n",
       "  Using Google Translate for NLP Augmentation,\n",
       "  More NLI datasets - Hugging Face nlp library],\n",
       " just-the-basics-strata-2013: [],\n",
       " just-the-basics-the-after-party: [SPAM_Detection  Strata2013After-party,\n",
       "  Classification using Machine and Deep Learning,\n",
       "  XGBoost + Feat Imp Acc:93%,\n",
       "  Just The Basics Notebook]}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull notebooks (Run once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "length = 0\n",
    "for c in comp_nb:\n",
    "    for n in comp_nb[c]:\n",
    "        try:\n",
    "            nb = kaggle.api.kernels_pull(n.ref, 'C:\\\\Users\\\\dmasrour\\\\Documents\\\\NotebookCodeGen\\\\Data\\\\Unprocessed_Notebooks')\n",
    "        except Exception as e:\n",
    "            print('Kaggle API exception : Notebook not found')\n",
    "print('DONE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49ab456e11cde720218fba409a85456f40f210cf294d5c8f56d5f4fb69af5c6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

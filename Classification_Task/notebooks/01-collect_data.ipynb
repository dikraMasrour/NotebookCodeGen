{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we provide our strategy on collecting suitable data for Classification task .We have first build a list of wisely choosed keywords based on very specific algorithms and characteristics related to notebook's possible tag - **6**:\n",
    "\n",
    "- Regression\n",
    "- Classification\n",
    "- Clustering\n",
    "- Computer Vision\n",
    "- NLP\n",
    "- Reinforcement Learning\n",
    "\n",
    "We've relied essentialy on kaggle notebooks .Our choice is based in the fact that those notebooks are of good quality and quantity .\n",
    "--> What is Kaggle ?\n",
    "Kaggle is an online community platform for data scientists and machine learning enthusiasts. Kaggle allows users to collaborate with other users, find and publish datasets, use GPU integrated notebooks, and compete with other data scientists to solve data science challenges. The aim of this online platform is to help professionals and learners reach their goals in their data science journey with the powerful tools and resources it provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_KEYWORDS = '../data/search_keywords.csv'\n",
    "DATA_PATH_NOTEBOOKS = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to interact with Kaggle (Kaggle API)\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Used to manipule and analyse data\n",
    "import pandas as pd\n",
    "\n",
    "# Used to work with arrays\n",
    "import numpy as np\n",
    "\n",
    "# Used for plotting\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Used to processing automatic language \n",
    "import nltk\n",
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication \n",
    "\n",
    "To use Kaggle’s API to interact with Kaggle resources (competitions , datasets and kernels) you need to authenticate first using an API token. To do so , you can follow this [Guide](https://towardsdatascience.com/how-to-search-and-download-data-using-kaggle-api-f815f7b98080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file containing the search keywords used to retrieve notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lasso regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>randomforestregression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>sarsa</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ddpg</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>qlearning</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>markov decision</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               subcategory                category\n",
       "0        linear regression              regression\n",
       "1         lasso regression              regression\n",
       "2   randomforestregression              regression\n",
       "3         ridge regression              regression\n",
       "4             XGBRegressor              regression\n",
       "..                     ...                     ...\n",
       "89                   sarsa  reinforcement learning\n",
       "90                    ddpg  reinforcement learning\n",
       "91               qlearning  reinforcement learning\n",
       "92         markov decision  reinforcement learning\n",
       "93           reinforcement  reinforcement learning\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_df = pd.DataFrame(columns=['Category', 'Subcategory'])\n",
    "keywords_df = pd.read_csv(DATA_PATH_KEYWORDS, sep=';') \n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function returns the category of a Notebook based on its subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(sub,data):\n",
    "    for i in data.index:\n",
    "        if data.loc[i]['subcategory'] == sub:\n",
    "            return data.loc[i]['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a new dataframe where we'll store our desired notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['title','subcategory','category'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a notebook titles dataframe with category and subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API exception : \" amolambkar/multivariate-linear-regression-using-python-code \" Notebook not found\n",
      "Kaggle API exception : \" fabiendaniel/predicting-flight-delays-tutorial \" Notebook not found\n",
      "Kaggle API exception : \" fabiendaniel/predicting-flight-delays-tutorial \" Notebook not found\n",
      "Kaggle API exception : \" fabiendaniel/predicting-flight-delays-tutorial \" Notebook not found\n",
      "Kaggle API exception : \" vassylkorzh/crime-scale-prediction \" Notebook not found\n",
      "Kaggle API exception : \" juliojaavier/earth-surface-temperature \" Notebook not found\n",
      "Kaggle API exception : \" juliojaavier/earth-surface-temperature \" Notebook not found\n",
      "Kaggle API exception : \" juliojaavier/earth-surface-temperature \" Notebook not found\n",
      "Kaggle API exception : \" rbyron/simple-linear-regression-models \" Notebook not found\n",
      "Kaggle API exception : \" rbyron/simple-linear-regression-models \" Notebook not found\n",
      "Kaggle API exception : \" rbyron/simple-linear-regression-models \" Notebook not found\n",
      "Kaggle API exception : \" rbyron/simple-linear-regression-models \" Notebook not found\n",
      "Kaggle API exception : \" usamabalochhh/eda-xgbregressor-good-accuracy-with-explanation \" Notebook not found\n",
      "Kaggle API exception : \" vikassingh1996/extensive-data-preprocessing-and-modeling \" Notebook not found\n",
      "Kaggle API exception : \" vikassingh1996/extensive-data-preprocessing-and-modeling \" Notebook not found\n",
      "Kaggle API exception : \" devanshbesain/exploration-and-analysis-auto-mpg \" Notebook not found\n",
      "Kaggle API exception : \" devanshbesain/exploration-and-analysis-auto-mpg \" Notebook not found\n",
      "Kaggle API exception : \" venkatapadavala/house-prices-advanced-regression-practice \" Notebook not found\n",
      "Kaggle API exception : \" akouaorsot/mlr-medical-costs \" Notebook not found\n",
      "Kaggle API exception : \" masumrumi/a-detailed-regression-guide-with-house-pricing \" Notebook not found\n",
      "Kaggle API exception : \" kaanboke/car-price-prediction-beginner-friendly-94-3 \" Notebook not found\n",
      "Kaggle API exception : \" kaanboke/car-price-prediction-beginner-friendly-94-3 \" Notebook not found\n",
      "Kaggle API exception : \" brsdincer/fashionmnist-prediction-full-explanation \" Notebook not found\n",
      "Kaggle API exception : \" alaasedeeq/house-price-prediction-top-8 \" Notebook not found\n",
      "Kaggle API exception : \" alaasedeeq/house-price-prediction-top-8 \" Notebook not found\n",
      "Kaggle API exception : \" icaram/rapids-svr-boost-17-8 \" Notebook not found\n",
      "Kaggle API exception : \" elikplim/predict-the-burned-area-of-forest-fires \" Notebook not found\n",
      "Kaggle API exception : \" nilanml/eda-lasso \" Notebook not found\n",
      "Kaggle API exception : \" lemonad/nykdev-single-layer-perceptron \" Notebook not found\n",
      "Kaggle API exception : \" lemonad/nykdev-single-layer-perceptron \" Notebook not found\n",
      "Kaggle API exception : \" lemonad/nykdev-single-layer-perceptron \" Notebook not found\n",
      "Kaggle API exception : \" samhithvasikarla/banknote-authentication-with-multilayer-perceptron \" Notebook not found\n",
      "Kaggle API exception : \" imanjowkar/hyperparameter-effect-on-deep-learning-model-3 \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" leemun1/predicting-breast-cancer-logistic-regression \" Notebook not found\n",
      "Kaggle API exception : \" vjchoudhary7/logistic-regression-model-in-hr-analytics \" Notebook not found\n",
      "Kaggle API exception : \" jsultan/visualizing-classifier-boundaries-using-kernel-pca \" Notebook not found\n",
      "Kaggle API exception : \" paotografi/customer-churn-eda-95-acc-and-85-recall \" Notebook not found\n",
      "Kaggle API exception : \" cdeotte/private-lb-probing-0-950 \" Notebook not found\n",
      "Kaggle API exception : \" cdeotte/private-lb-probing-0-950 \" Notebook not found\n",
      "Kaggle API exception : \" degravek/a-naive-bayes-tweet-classifier \" Notebook not found\n",
      "Kaggle API exception : \" ranjeetjain3/visualization-machine-learning-deep-learning \" Notebook not found\n",
      "Kaggle API exception : \" kanncaa1/applying-text-mining \" Notebook not found\n",
      "Kaggle API exception : \" rxsraghavagrawal/music-genre-classification-using-knn-begineers \" Notebook not found\n",
      "Kaggle API exception : \" sulianova/knn-and-na-ve-bayes-approaches \" Notebook not found\n",
      "Kaggle API exception : \" dktalaicha/diabetes-prediction-by-knn \" Notebook not found\n",
      "Kaggle API exception : \" nicapotato/titanic-voting-pipeline-stack-and-guide \" Notebook not found\n",
      "Kaggle API exception : \" rajeshjnv/mall-customer-visually-analysis-k-means \" Notebook not found\n",
      "Kaggle API exception : \" beezus666/k-means-and-feature-importance-for-articles \" Notebook not found\n",
      "Kaggle API exception : \" akashchola/customer-segmentation-rfm-model-k-means \" Notebook not found\n",
      "Kaggle API exception : \" gauravduttakiit/clustering-using-k-means-hierarchical-pca \" Notebook not found\n",
      "Kaggle API exception : \" gauravduttakiit/clustering-using-k-means-hierarchical-pca \" Notebook not found\n",
      "Kaggle API exception : \" singhnproud77/hierarchical-clustering-telco-customer-churn \" Notebook not found\n",
      "Kaggle API exception : \" manohar676/a-complete-giude-of-ml-workflow-with-python \" Notebook not found\n",
      "Kaggle API exception : \" agustinpugliese/clustering-model-comparison-with-plotly \" Notebook not found\n",
      "Kaggle API exception : \" jagdmir/help-international-clustering-pca \" Notebook not found\n",
      "Kaggle API exception : \" rsesha/pycaret-vs-auto-viml-on-reg-class-nlp \" Notebook not found\n",
      "Kaggle API exception : \" rsesha/pycaret-vs-auto-viml-on-reg-class-nlp \" Notebook not found\n",
      "Kaggle API exception : \" habibmrad1983/awesome-ml-frameworks-and-mnist-classification \" Notebook not found\n",
      "Kaggle API exception : \" avnika22/world-happiness-report-eda-clustering \" Notebook not found\n",
      "Kaggle API exception : \" avnika22/world-happiness-report-eda-clustering \" Notebook not found\n",
      "Kaggle API exception : \" avnika22/world-happiness-report-eda-clustering \" Notebook not found\n",
      "Kaggle API exception : \" kmader/cellcnn-overview \" Notebook not found\n",
      "Kaggle API exception : \" tadeumesquita/rain-in-australa-random-forest \" Notebook not found\n",
      "Kaggle API exception : \" vedanth777/clustering-customers-heirarchical-pcaplot \" Notebook not found\n",
      "Kaggle API exception : \" pmrich/clustering-approaches-k-mean-birch-agg \" Notebook not found\n",
      "Kaggle API exception : \" tpe3egol/player-characteristics \" Notebook not found\n",
      "Kaggle API exception : \" michaelmeeker/wip-bank-customer-rmf-and-segementation \" Notebook not found\n",
      "Kaggle API exception : \" ayakhaled2/steam-game-analysis \" Notebook not found\n",
      "Kaggle API exception : \" saymasultantufan/k-means-and-birch \" Notebook not found\n",
      "Kaggle API exception : \" shilpyp/world-happiness-report-clustering-analysis-v1 \" Notebook not found\n",
      "Kaggle API exception : \" keisei/tempbook \" Notebook not found\n",
      "Kaggle API exception : \" keisei/tempbook \" Notebook not found\n",
      "Kaggle API exception : \" geetanjali1sharma/data-analysis-for-a-hotel-rating-and-reservations \" Notebook not found\n",
      "Kaggle API exception : \" hitashukanjani/ds5220mergerprediction \" Notebook not found\n",
      "Kaggle API exception : \" piercnic/unsupervised-k-means \" Notebook not found\n",
      "Kaggle API exception : \" mayureshnm/tps-july-22-with-mini-batch-k-means-clustering \" Notebook not found\n",
      "Kaggle API exception : \" nataliashcheglova/clustering-k-means-agglomerative-dbscan \" Notebook not found\n",
      "Kaggle API exception : \" ravirajsinh45/global-wheat-yolo-labels \" Notebook not found\n",
      "Kaggle API exception : \" chizuchizu/japanese-extraction-of-importance \" Notebook not found\n",
      "Kaggle API exception : \" jiangstein/a-very-simple-siamese-network-in-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" sjyangkevin/tf-cots-yolov5-training-pipeline \" Notebook not found\n",
      "Kaggle API exception : \" sjyangkevin/tf-cots-yolov5-training-pipeline \" Notebook not found\n",
      "Kaggle API exception : \" akensert/rsna-inceptionv3-keras-tf1-14-0 \" Notebook not found\n",
      "Kaggle API exception : \" ar2017/pytorch-efficientnet-train-aug-cutmix-fmix \" Notebook not found\n",
      "Kaggle API exception : \" kozodoi/local-installation-for-efficientnet-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" gauravduttakiit/anime-vs-cartoon-mobilenetv2-model \" Notebook not found\n",
      "Kaggle API exception : \" rutwikhiwalkar/introduction-to-transfer-learning-inceptionv3 \" Notebook not found\n",
      "Kaggle API exception : \" aziz69/efficientnets-meta-data-augs-0-939-public-lb \" Notebook not found\n",
      "Kaggle API exception : \" rajkumarl/get-started-with-semantic-segmentation \" Notebook not found\n",
      "Kaggle API exception : \" rajkumarl/get-started-with-semantic-segmentation \" Notebook not found\n",
      "Kaggle API exception : \" giosiolas/3-tensorflow-2-cifar-100-ipynb \" Notebook not found\n",
      "Kaggle API exception : \" mostafaibrahim17/yolov5-vinbigdata \" Notebook not found\n",
      "Kaggle API exception : \" remekkinas/funny-cv-eda-what-we-see-here \" Notebook not found\n",
      "Kaggle API exception : \" xinruizhuang/skin-lesion-classification-acc-90-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" andradaolteanu/sentiment-analysis-rick-and-morty-scripts \" Notebook not found\n",
      "Kaggle API exception : \" andradaolteanu/sentiment-analysis-rick-and-morty-scripts \" Notebook not found\n",
      "Kaggle API exception : \" blessondensil294/beginner-nlp-product-sentiment-analysis-textblob \" Notebook not found\n",
      "Kaggle API exception : \" nirant/hitchhiker-s-guide-to-nlp-in-spacy \" Notebook not found\n",
      "Kaggle API exception : \" tientd95/understanding-attention-in-neural-network \" Notebook not found\n",
      "Kaggle API exception : \" tientd95/understanding-attention-in-neural-network \" Notebook not found\n",
      "Kaggle API exception : \" uom170589c/mbart-model2-part-1 \" Notebook not found\n",
      "Kaggle API exception : \" itratrahman/nlp-tutorial-using-python \" Notebook not found\n",
      "Kaggle API exception : \" zhenyufan/nlp-for-yelp-reviews \" Notebook not found\n",
      "Kaggle API exception : \" zhenyufan/nlp-for-yelp-reviews \" Notebook not found\n",
      "Kaggle API exception : \" zhenyufan/nlp-for-yelp-reviews \" Notebook not found\n",
      "Kaggle API exception : \" zhenyufan/nlp-for-yelp-reviews \" Notebook not found\n",
      "Kaggle API exception : \" saurabh48782/nlp-using-spacy-library-part-1 \" Notebook not found\n",
      "Kaggle API exception : \" yuanzhezhou/ai4code-distilbert-inference-777 \" Notebook not found\n",
      "Kaggle API exception : \" letnzle/t5anddemosystem \" Notebook not found\n",
      "Kaggle API exception : \" kabure/qa-eda-and-nlp-modelling-insights-vis-bert \" Notebook not found\n",
      "Kaggle API exception : \" mpwolke/moby-dick-election-and-battles \" Notebook not found\n",
      "Kaggle API exception : \" mpwolke/moby-dick-election-and-battles \" Notebook not found\n",
      "Kaggle API exception : \" mpwolke/moby-dick-election-and-battles \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" kentaronakanishi/clrp-095-ensemble13-cv-kaggle93 \" Notebook not found\n",
      "Kaggle API exception : \" succinctlyai/midjourney-text-prompts-huggingface \" Notebook not found\n",
      "Kaggle API exception : \" succinctlyai/midjourney-text-prompts-huggingface \" Notebook not found\n",
      "Kaggle API exception : \" rihab147/arabert-pytorch-arabic-texts \" Notebook not found\n",
      "Kaggle API exception : \" theoviel/bert-for-question-answering-baseline-inference \" Notebook not found\n",
      "Kaggle API exception : \" theoviel/bert-for-question-answering-baseline-inference \" Notebook not found\n",
      "Kaggle API exception : \" shujian/single-rnn-with-5-folds-snapshot-ensemble \" Notebook not found\n",
      "Kaggle API exception : \" shujian/single-rnn-with-5-folds-snapshot-ensemble \" Notebook not found\n",
      "Kaggle API exception : \" anirbansen3027/jtcc-word2vec \" Notebook not found\n",
      "Kaggle API exception : \" satian/a-look-at-different-embeddings-with-attention \" Notebook not found\n",
      "Kaggle API exception : \" sergeykalutsky/pytorch-starter \" Notebook not found\n",
      "Kaggle API exception : \" kunihikofurugori/torch-multidml-img-text-tfidf-faiss \" Notebook not found\n",
      "Kaggle API exception : \" kunihikofurugori/torch-multidml-img-text-tfidf-faiss \" Notebook not found\n",
      "Kaggle API exception : \" kailex/tidy-xgboost-glmnet-text2vec-lsa \" Notebook not found\n",
      "Kaggle API exception : \" charumakhijani/nlp-tutorial-countvectorizer-tfidf-onehotvector \" Notebook not found\n",
      "Kaggle API exception : \" subhasom/covid-19-chatbot \" Notebook not found\n",
      "Kaggle API exception : \" elvinagammed/starter-intent-recognition-chatbot-8da964e5-5 \" Notebook not found\n",
      "Kaggle API exception : \" lolik228/a2c-try \" Notebook not found\n",
      "Kaggle API exception : \" ariskoutris/nn-ex4 \" Notebook not found\n",
      "Kaggle API exception : \" oskarfirlej/exercise-deep-reinforcement-learning \" Notebook not found\n",
      "Kaggle API exception : \" jhowjhow/mountaincar-dqn \" Notebook not found\n",
      "Kaggle API exception : \" jhowjhow/mountaincar-dqn \" Notebook not found\n",
      "Kaggle API exception : \" mahoy00/deep-reinforcement-learning-on-stock-data \" Notebook not found\n",
      "Kaggle API exception : \" kooaslansefat/concept-drift-adversarial-validation-safeml \" Notebook not found\n",
      "Kaggle API exception : \" jeremygodden/my-self-made-data-science-masters-curriculum \" Notebook not found\n",
      "Kaggle API exception : \" sofyalaskina/covid-19-literature-clustering-part-3 \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n",
      "Kaggle API exception : \" hsperr/halite-iv-dqn-example-pytorch \" Notebook not found\n"
     ]
    }
   ],
   "source": [
    "for keyword in keywords_df['subcategory']:\n",
    "    for i in range(1,11):\n",
    "        try :\n",
    "                kernels = api.kernels_list(search = keyword, page=i)\n",
    "                for kernel in kernels:\n",
    "                    # print(kernel.ref)\n",
    "                    df.loc[len(df)]=[kernel.ref,keyword,search(keyword,keywords_df)]\n",
    "        except Exception as e:\n",
    "            print('Kaggle API exception : \"', kernel.ref, '\" Notebook not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of all  the successfuly collected  notebooks titles with their corresponding subcateory and category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudhirnl7/linear-regression-tutorial</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goyalshalini93/car-price-prediction-linear-reg...</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>divan0/multiple-linear-regression</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthonypino/price-analysis-and-linear-regression</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vivinbarath/simple-linear-regression-for-salar...</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10458</th>\n",
       "      <td>fanbyprinciple/reinforcement-learning-on-opena...</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10459</th>\n",
       "      <td>alexisbcook/exercise-one-step-lookahead</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10460</th>\n",
       "      <td>alexisbcook/exercise-interactive-maps</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10461</th>\n",
       "      <td>lbarbosa/connectx-deep-reinforcement-learning</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10462</th>\n",
       "      <td>hsperr/halite-iv-dqn-example-pytorch</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>reinforcement learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10463 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title        subcategory  \\\n",
       "0                   sudhirnl7/linear-regression-tutorial  linear regression   \n",
       "1      goyalshalini93/car-price-prediction-linear-reg...  linear regression   \n",
       "2                      divan0/multiple-linear-regression  linear regression   \n",
       "3       anthonypino/price-analysis-and-linear-regression  linear regression   \n",
       "4      vivinbarath/simple-linear-regression-for-salar...  linear regression   \n",
       "...                                                  ...                ...   \n",
       "10458  fanbyprinciple/reinforcement-learning-on-opena...      reinforcement   \n",
       "10459            alexisbcook/exercise-one-step-lookahead      reinforcement   \n",
       "10460              alexisbcook/exercise-interactive-maps      reinforcement   \n",
       "10461      lbarbosa/connectx-deep-reinforcement-learning      reinforcement   \n",
       "10462               hsperr/halite-iv-dqn-example-pytorch      reinforcement   \n",
       "\n",
       "                     category  \n",
       "0                  regression  \n",
       "1                  regression  \n",
       "2                  regression  \n",
       "3                  regression  \n",
       "4                  regression  \n",
       "...                       ...  \n",
       "10458  reinforcement learning  \n",
       "10459  reinforcement learning  \n",
       "10460  reinforcement learning  \n",
       "10461  reinforcement learning  \n",
       "10462  reinforcement learning  \n",
       "\n",
       "[10463 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                               title        subcategory  \\\n",
       " 0               sudhirnl7/linear-regression-tutorial  linear regression   \n",
       " 1  goyalshalini93/car-price-prediction-linear-reg...  linear regression   \n",
       " 2                  divan0/multiple-linear-regression  linear regression   \n",
       " 3   anthonypino/price-analysis-and-linear-regression  linear regression   \n",
       " 4  vivinbarath/simple-linear-regression-for-salar...  linear regression   \n",
       " 5                 foxtreme/linear-regression-project  linear regression   \n",
       " 6  aakashns/pytorch-basics-linear-regression-from...  linear regression   \n",
       " 7  nitindatta/fifa-in-depth-analysis-with-linear-...  linear regression   \n",
       " 8   ashydv/sales-prediction-simple-linear-regression  linear regression   \n",
       " 9                       aminizahra/linear-regression  linear regression   \n",
       " \n",
       "      category  \n",
       " 0  regression  \n",
       " 1  regression  \n",
       " 2  regression  \n",
       " 3  regression  \n",
       " 4  regression  \n",
       " 5  regression  \n",
       " 6  regression  \n",
       " 7  regression  \n",
       " 8  regression  \n",
       " 9  regression  ,\n",
       " (10463, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10), df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_PATH_NOTEBOOKS+'ntb_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer vision</td>\n",
       "      <td>25.269999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nlp</td>\n",
       "      <td>24.553187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clustering</td>\n",
       "      <td>18.723120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression</td>\n",
       "      <td>14.479595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classification</td>\n",
       "      <td>11.468986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reinforcement learning</td>\n",
       "      <td>5.505113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category      means\n",
       "0         computer vision  25.269999\n",
       "1                     nlp  24.553187\n",
       "2              clustering  18.723120\n",
       "3              regression  14.479595\n",
       "4          classification  11.468986\n",
       "5  reinforcement learning   5.505113"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = (df.category.value_counts() / len(df)) * 100\n",
    "\n",
    "meansdf = pd.DataFrame(columns=['category', 'means'])\n",
    "meansdf.category = means.index\n",
    "meansdf.means = means.values\n",
    "\n",
    "meansdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category', ylabel='means'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x='category', y='means', data=meansdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly , we 'll have to face : **Class Imbalance** problem ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before collecting\n",
    "- Delete duplicate notebooks : print duplicate categories => choose best category to keep\n",
    "- Delete notebooks with non-english titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sudhirnl7/linear-regression-tutorial</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goyalshalini93/car-price-prediction-linear-reg...</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>divan0/multiple-linear-regression</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthonypino/price-analysis-and-linear-regression</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vivinbarath/simple-linear-regression-for-salar...</td>\n",
       "      <td>linear regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        subcategory  \\\n",
       "0               sudhirnl7/linear-regression-tutorial  linear regression   \n",
       "1  goyalshalini93/car-price-prediction-linear-reg...  linear regression   \n",
       "2                  divan0/multiple-linear-regression  linear regression   \n",
       "3   anthonypino/price-analysis-and-linear-regression  linear regression   \n",
       "4  vivinbarath/simple-linear-regression-for-salar...  linear regression   \n",
       "\n",
       "     category  \n",
       "0  regression  \n",
       "1  regression  \n",
       "2  regression  \n",
       "3  regression  \n",
       "4  regression  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH_NOTEBOOKS+'ntb_list.csv', sep=',', encoding='utf-8', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10463, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dict with duplicate titles and their respective positions in the df\n",
    "duplicates = df[df.duplicated('title', keep=False)].groupby('title').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def to_be_dropped_indices(dictionary):\n",
    "    to_be_dropped = [] # indices to be dropped from original df\n",
    "    temp = []\n",
    "\n",
    "    for k,v in dictionary.items():\n",
    "        duplicates_df = df[df.index.isin(v.values)]\n",
    "        \n",
    "        # if the rows have the same category, they are all dropped except the last one\n",
    "        if len(set(list(duplicates_df.category))) == 1:\n",
    "            to_be_dropped.append(list(duplicates_df.index[:len(duplicates_df.category)-1]))\n",
    "\n",
    "        else: \n",
    "            # drop least common category duplicates for a notebook\n",
    "            dup_counter = collections.Counter(duplicates_df.category)\n",
    "            most_common = dup_counter.most_common()[0][0]\n",
    "            most_common_i = duplicates_df.index.where(duplicates_df.category == most_common).dropna()[0]\n",
    "\n",
    "            to_be_dropped.append(duplicates_df.index.where(duplicates_df.index != most_common_i).dropna())\n",
    "\n",
    "    return flatten_list(to_be_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting indices of rows to be dropped (duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1866, [951, 7211.0, 2983, 3555, 2819, 3342, 3606, 3802, 3944, 4069])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_dropped = to_be_dropped_indices(duplicates)\n",
    "len(to_be_dropped), to_be_dropped[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8597, 3)\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "df_clean.drop(to_be_dropped, inplace=True)\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing non-english titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize keywords\n",
    "def list_to_unique_words(list):\n",
    "    unique_words = []\n",
    "    for l in list:\n",
    "        unique_words.append(str(l).lower().split())\n",
    "\n",
    "    return flatten_list(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the default *nltk* words list to add our categories and subcategories and other custom words that are domain specific to avoid them being removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_categ = list_to_unique_words(list(keywords_df.category))\n",
    "lower_subcateg = list_to_unique_words(list(keywords_df.subcategory))\n",
    "custom_list = ['dataset', 'datasets', 'feature', 'transformer', 'transformers', 'using', 'detect', 'detecting', 'machine', 'intro', 'pca', 'connectx', 'xgboost', 'visualising', 'visualizing', 'gaussian', 'bayesian', 'score', 'scores', 'map', 'maps', 'ml', 'dl', 'algorithm', 'algorithms', 'feature', 'features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('words')\n",
    "\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "words.update(lower_categ)\n",
    "words.update(lower_subcateg)\n",
    "words.update(custom_list)\n",
    "\n",
    "# exepected non-english indices : 353 1594 1640 1584 1664 4412 8273 11540 1081 1715 1642 4693 5320 7295 10615 11629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_non_english(df, word_list):\n",
    "    non_english = []\n",
    "    for row in df.index:\n",
    "        \n",
    "        title = df.loc[row, 'title']\n",
    "        try:\n",
    "            # print(df.loc[row, 'title'])\n",
    "            # title = \"Chaii EDA&Baseline 実況\"\n",
    "            clean_title = \" \".join(w for w in nltk.wordpunct_tokenize(title) \\\n",
    "                    if w.lower() in word_list or not w.isalpha())\n",
    "\n",
    "            if ((len(title.split()) - len(clean_title.split())) > 3) or len(clean_title.split()) == 0: \n",
    "                non_english.append(row) # builds list of titles with low # of english words\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return non_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_english = clean_non_english(df_clean, words)\n",
    "non_english[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually detect few titles of notebooks not written in english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_non_english = [353, 1594, 1640, 1584, 1664, 4412, 8273, 11540, 1081, 1715, 1642, 4693, 5320, 7295, 10615, 11629]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_english_to_be_dropped = intersection(non_english, detected_non_english)\n",
    "non_english_to_be_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(non_english_to_be_dropped, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8597, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write it the list of notebooks to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(DATA_PATH_NOTEBOOKS+'ntb_list_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting notebooks by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API exception :  onrcan/spectral-clustering Notebook not found\n",
      "Kaggle API exception :  sujoys/spectral-clustering Notebook not found\n",
      "Kaggle API exception :  saymasultantufan/k-means-and-birch Notebook not found\n",
      "Kaggle API exception :  mushfiqurrahmanrifat/assignment-birch-clustering Notebook not found\n",
      "Kaggle API exception :  vishnumandala/twitter-sentiment-analysis-using-denclue Notebook not found\n",
      "Kaggle API exception :  bagriaditya/minibatchkmeans Notebook not found\n",
      "Kaggle API exception :  sarthakmaniar27/kmeans-and-kmedoids Notebook not found\n",
      "Kaggle API exception :  ashishpatel26/dbscan Notebook not found\n"
     ]
    }
   ],
   "source": [
    "for i in df_clean.index :\n",
    "        try :\n",
    "                api.kernels_pull(df_clean.loc[i]['title'], path = DATA_PATH_NOTEBOOKS + df_clean.loc[i]['category'])\n",
    "        except Exception as e:\n",
    "            print('Kaggle API exception : ', kernel.ref, 'Notebook not found')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5093ef3c9eba5a2350b58945b72c1f122b8b5551b9ae00db57837a16e1175c4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

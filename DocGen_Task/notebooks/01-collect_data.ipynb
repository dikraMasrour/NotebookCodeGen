{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we provide our strategy on collecting suitable data for documentation generation task .We've relied essentialy on kaggle notebooks .We've decided to utilize the top voted notebooks from 'getting started' competitions on Kaggle to construct our dataset , we've added also notebooks in the courses section . Our choice is based in the fact that those notebooks are of good quality in code documentation since they are used for learning purposes .\n",
    "\n",
    "--> What is Kaggle ?\n",
    "Kaggle is an online community platform for data scientists and machine learning enthusiasts. Kaggle allows users to collaborate with other users, find and publish datasets, use GPU integrated notebooks, and compete with other data scientists to solve data science challenges. The aim of this online platform is to help professionals and learners reach their goals in their data science journey with the powerful tools and resources it provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to interact with Kaggle (Kaggle API)\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Used to manipule and analyse data\n",
    "import pandas as pd\n",
    "\n",
    "# Used to processing automatic language \n",
    "import nltk\n",
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "from langdetect import DetectorFactory\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=\"../data_/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication \n",
    "\n",
    "To use Kaggle’s API to interact with Kaggle resources (competitions , datasets and kernels) you need to authenticate first using an API token. To do so , you can follow this [Guide](https://towardsdatascience.com/how-to-search-and-download-data-using-kaggle-api-f815f7b98080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our main dataframe where we'll store our desired notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel_ref</th>\n",
       "      <th>title</th>\n",
       "      <th>competition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [kernel_ref, title, competition]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['kernel_ref','title','competition'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Kernel references of the well documented notebooks that we have selected from Learn section on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Kernels_Courses = ['dansbecker/basic-data-exploration','dansbecker/your-first-machine-learning-model','dansbecker/model-validation','dansbecker/underfitting-and-overfitting','dansbecker/random-forests','alexisbcook/missing-values','alexisbcook/categorical-variables','alexisbcook/pipelines','alexisbcook/cross-validation','alexisbcook/xgboost','alexisbcook/data-leakage','ryanholbrook/what-is-feature-engineering','ryanholbrook/mutual-information','ryanholbrook/creating-features','ryanholbrook/clustering-with-k-means','ryanholbrook/principal-component-analysis','ryanholbrook/target-encoding','ryanholbrook/stochastic-gradient-descent','ryanholbrook/overfitting-and-underfitting','ryanholbrook/dropout-and-batch-normalization','ryanholbrook/binary-classification','ryanholbrook/the-convolutional-classifier','ryanholbrook/convolution-and-relu','ryanholbrook/maximum-pooling','ryanholbrook/the-sliding-window','ryanholbrook/custom-convnets','ryanholbrook/data-augmentation','ryanholbrook/linear-regression-with-time-series','ryanholbrook/trend','ryanholbrook/time-series-as-features','ryanholbrook/hybrid-models','ryanholbrook/forecasting-with-machine-learning','dansbecker/partial-plots','dansbecker/shap-values','dansbecker/advanced-uses-of-shap-values']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save locally collected notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ntb in List_Kernels_Courses :\n",
    "        try :\n",
    "                api.kernels_pull(ntb, path = DATA_PATH)\n",
    "        except Exception as e:\n",
    "            print('Kaggle API exception : ',ntb, 'Notebook not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of getting started competitions **(16 competitions)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[contradictory-my-dear-watson,\n",
       " gan-getting-started,\n",
       " store-sales-time-series-forecasting,\n",
       " tpu-getting-started,\n",
       " digit-recognizer,\n",
       " titanic,\n",
       " house-prices-advanced-regression-techniques,\n",
       " connectx,\n",
       " nlp-getting-started,\n",
       " spaceship-titanic,\n",
       " facial-keypoints-detection,\n",
       " street-view-getting-started-with-julia,\n",
       " word2vec-nlp-tutorial,\n",
       " data-science-london-scikit-learn,\n",
       " just-the-basics-the-after-party,\n",
       " just-the-basics-strata-2013]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competitions = api.competitions_list(category=\"gettingStarted\")\n",
    "competitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect **most voted** *notebooks* for each **getting-started** *competitions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in competitions :\n",
    "    try :\n",
    "        kernels_list = api.kernels_list(page=1,competition = str(comp),sort_by=\"voteCount\")\n",
    "        for k in kernels_list :\n",
    "                df.loc[len(df)] = [str(k.ref),str(k),str(comp)]         \n",
    "    except Exception as e:\n",
    "                        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of all  the successfuly collected  notebooks titles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel_ref</th>\n",
       "      <th>title</th>\n",
       "      <th>competition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anasofiauzsoy/tutorial-notebook</td>\n",
       "      <td>Tutorial Notebook</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nkitgupta/text-representations</td>\n",
       "      <td>Text-Representations</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rohanrao/tpu-sherlocked-one-stop-for-with-tf</td>\n",
       "      <td>TPU Sherlocked: One-stop for 🤗 with TF</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faressayah/text-analysis-topic-modelling-with-...</td>\n",
       "      <td>Text Analysis|Topic Modelling with spaCy &amp; GENSIM</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vbookshelf/basics-of-bert-and-xlm-roberta-pytorch</td>\n",
       "      <td>Basics of BERT and XLM-RoBERTa - PyTorch</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>irinana/spam-detection-strata2013after-party</td>\n",
       "      <td>SPAM_Detection  Strata2013After-party</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>nikosavgeros/classification-using-machine-and-...</td>\n",
       "      <td>Classification using Machine and Deep Learning</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>meln1337/just-the-basics-notebook</td>\n",
       "      <td>Just The Basics Notebook</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>pythonkumar/xgboost-feat-imp-acc-93</td>\n",
       "      <td>XGBoost + Feat Imp Acc:93%</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>ragvendrapal/model-training</td>\n",
       "      <td>model_training</td>\n",
       "      <td>just-the-basics-strata-2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            kernel_ref  \\\n",
       "0                      anasofiauzsoy/tutorial-notebook   \n",
       "1                       nkitgupta/text-representations   \n",
       "2         rohanrao/tpu-sherlocked-one-stop-for-with-tf   \n",
       "3    faressayah/text-analysis-topic-modelling-with-...   \n",
       "4    vbookshelf/basics-of-bert-and-xlm-roberta-pytorch   \n",
       "..                                                 ...   \n",
       "267       irinana/spam-detection-strata2013after-party   \n",
       "268  nikosavgeros/classification-using-machine-and-...   \n",
       "269                  meln1337/just-the-basics-notebook   \n",
       "270                pythonkumar/xgboost-feat-imp-acc-93   \n",
       "271                        ragvendrapal/model-training   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                    Tutorial Notebook   \n",
       "1                                 Text-Representations   \n",
       "2               TPU Sherlocked: One-stop for 🤗 with TF   \n",
       "3    Text Analysis|Topic Modelling with spaCy & GENSIM   \n",
       "4             Basics of BERT and XLM-RoBERTa - PyTorch   \n",
       "..                                                 ...   \n",
       "267              SPAM_Detection  Strata2013After-party   \n",
       "268     Classification using Machine and Deep Learning   \n",
       "269                           Just The Basics Notebook   \n",
       "270                         XGBoost + Feat Imp Acc:93%   \n",
       "271                                     model_training   \n",
       "\n",
       "                         competition  \n",
       "0       contradictory-my-dear-watson  \n",
       "1       contradictory-my-dear-watson  \n",
       "2       contradictory-my-dear-watson  \n",
       "3       contradictory-my-dear-watson  \n",
       "4       contradictory-my-dear-watson  \n",
       "..                               ...  \n",
       "267  just-the-basics-the-after-party  \n",
       "268  just-the-basics-the-after-party  \n",
       "269  just-the-basics-the-after-party  \n",
       "270  just-the-basics-the-after-party  \n",
       "271      just-the-basics-strata-2013  \n",
       "\n",
       "[272 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning \n",
    "\n",
    "Now let's try to remove non-english notebooks based first on their titles ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of words relatively linked to ML & DS domain so as not to deceive our model given that among these words, there are many abbreviations ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_list = ['dataset', 'datasets', 'feature', 'transformer', 'transformers', 'using', 'detect', 'detecting', 'machine', 'intro', 'pca', 'connectx', 'xgboost', 'visualising', 'visualizing', 'gaussian', 'bayesian', 'score', 'scores', 'map', 'maps', 'ml', 'dl', 'algorithm', 'algorithms', 'feature', 'features','model','models','Hyperparameters','Hyperparameter','preprocessing','CNN','Keras','Tensorflow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to use NLTK and Langdetect combine with each other to detect non-english notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(nltk.corpus.words.words())\n",
    "words.update(custom_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_non_english(df, word_list):\n",
    "    non_english = []\n",
    "    for row in df.index:\n",
    "        \n",
    "        title = df.loc[row, 'title']\n",
    "        try:\n",
    "            # title = \"Chaii EDA&Baseline 実況\"\n",
    "            clean_title = \" \".join(w for w in nltk.wordpunct_tokenize(title) \\\n",
    "                    if w.lower() in word_list or not w.isalpha())\n",
    "\n",
    "            if ((len(title.split()) - len(clean_title.split())) > 3) or len(clean_title.split()) == 0: \n",
    "                non_english.append(row) # builds list of titles with low # of english words\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return non_english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the index of non-english detected titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39, 49, 63, 89, 94, 138, 210, 226]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_english = clean_non_english(df, words)\n",
    "non_english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need first to examine those titles in order to validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 upamanyumukherjee/cyclegan CycleGAN\n",
      "49 andrej0marinchenko/hyperparamaters Hyperparamaters\n",
      "63 ryanholbrook/tfrecords-basics TFRecords Basics\n",
      "89 mauriciofigueiredo/mlp-simples-com-keras-para-iniciantes MLP simples com Keras para Iniciantes\n",
      "94 mauriciofigueiredo/cnn-simples-com-keras-para-iniciantes CNN simples com Keras para Iniciantes\n",
      "138 marsggbo/kaggle 房价预测kaggle入门项目\n",
      "210 ritvik1909/facial-keypoint-detection-cnn-aug-tl Facial Keypoint Detection - CNN + Aug + TL\n",
      "226 piterrudyy/julia Julia\n"
     ]
    }
   ],
   "source": [
    "for i in non_english:\n",
    "    print(i,df.loc[i]['kernel_ref'],df.loc[i]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the real non-english ones after examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_english_to_be_dropped = non_english[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we have dropped them directly from our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel_ref</th>\n",
       "      <th>title</th>\n",
       "      <th>competition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anasofiauzsoy/tutorial-notebook</td>\n",
       "      <td>Tutorial Notebook</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nkitgupta/text-representations</td>\n",
       "      <td>Text-Representations</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rohanrao/tpu-sherlocked-one-stop-for-with-tf</td>\n",
       "      <td>TPU Sherlocked: One-stop for 🤗 with TF</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faressayah/text-analysis-topic-modelling-with-...</td>\n",
       "      <td>Text Analysis|Topic Modelling with spaCy &amp; GENSIM</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vbookshelf/basics-of-bert-and-xlm-roberta-pytorch</td>\n",
       "      <td>Basics of BERT and XLM-RoBERTa - PyTorch</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>irinana/spam-detection-strata2013after-party</td>\n",
       "      <td>SPAM_Detection  Strata2013After-party</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>nikosavgeros/classification-using-machine-and-...</td>\n",
       "      <td>Classification using Machine and Deep Learning</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>meln1337/just-the-basics-notebook</td>\n",
       "      <td>Just The Basics Notebook</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>pythonkumar/xgboost-feat-imp-acc-93</td>\n",
       "      <td>XGBoost + Feat Imp Acc:93%</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>ragvendrapal/model-training</td>\n",
       "      <td>model_training</td>\n",
       "      <td>just-the-basics-strata-2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            kernel_ref  \\\n",
       "0                      anasofiauzsoy/tutorial-notebook   \n",
       "1                       nkitgupta/text-representations   \n",
       "2         rohanrao/tpu-sherlocked-one-stop-for-with-tf   \n",
       "3    faressayah/text-analysis-topic-modelling-with-...   \n",
       "4    vbookshelf/basics-of-bert-and-xlm-roberta-pytorch   \n",
       "..                                                 ...   \n",
       "262       irinana/spam-detection-strata2013after-party   \n",
       "263  nikosavgeros/classification-using-machine-and-...   \n",
       "264                  meln1337/just-the-basics-notebook   \n",
       "265                pythonkumar/xgboost-feat-imp-acc-93   \n",
       "266                        ragvendrapal/model-training   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                    Tutorial Notebook   \n",
       "1                                 Text-Representations   \n",
       "2               TPU Sherlocked: One-stop for 🤗 with TF   \n",
       "3    Text Analysis|Topic Modelling with spaCy & GENSIM   \n",
       "4             Basics of BERT and XLM-RoBERTa - PyTorch   \n",
       "..                                                 ...   \n",
       "262              SPAM_Detection  Strata2013After-party   \n",
       "263     Classification using Machine and Deep Learning   \n",
       "264                           Just The Basics Notebook   \n",
       "265                         XGBoost + Feat Imp Acc:93%   \n",
       "266                                     model_training   \n",
       "\n",
       "                         competition  \n",
       "0       contradictory-my-dear-watson  \n",
       "1       contradictory-my-dear-watson  \n",
       "2       contradictory-my-dear-watson  \n",
       "3       contradictory-my-dear-watson  \n",
       "4       contradictory-my-dear-watson  \n",
       "..                               ...  \n",
       "262  just-the-basics-the-after-party  \n",
       "263  just-the-basics-the-after-party  \n",
       "264  just-the-basics-the-after-party  \n",
       "265  just-the-basics-the-after-party  \n",
       "266      just-the-basics-strata-2013  \n",
       "\n",
       "[267 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(non_english_to_be_dropped, inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another test using Langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 anasofiauzsoy/tutorial-notebook Tutorial Notebook\n",
      "14 qinhui1999/more-nli-datasets-xmlr-large More NLI datasets xmlr-large\n",
      "18 jswxhd/nli-beginner-eda-bert-baseline NLI Beginner: EDA & Bert Baseline\n",
      "22 ohseokkim/transfering-style Transfering Style!\n",
      "28 nachiket273/cyclegan-pytorch CycleGAN_Pytorch\n",
      "35 dapy15/monet-using-gan Monet using GAN\n",
      "39 upamanyumukherjee/cyclegan CycleGAN\n",
      "49 andrej0marinchenko/hyperparamaters Hyperparamaters\n",
      "50 vanguarde/study-series-uplift-modeling [study series] Uplift modeling\n",
      "51 mpwolke/vacaciones-en-ecuador-with-galearn Vacaciones en Ecuador with Galearn\n",
      "52 hiro5299834/store-sales-ridge-voting-bagging-et-bagging-rf Store Sales: Ridge+Voting(Bagging(ET)+Bagging(RF))\n",
      "56 romaupgini/guide-external-data-features-for-multivariatets 🌎Guide: External Data&Features for MultivariateTS\n",
      "65 atamazian/fc-ensemble-external-data-effnet-densenet FC Ensemble External Data (EffNet+DenseNet)\n",
      "73 allunia/differential-evolution Differential Evolution\n",
      "82 poonaml/deep-neural-network-keras-way Deep Neural Network Keras way\n",
      "85 cdeotte/25-million-images-0-99757-mnist 25 Million Images! [0.99757] MNIST\n",
      "86 kakauandme/tensorflow-deep-nn TensorFlow deep NN\n",
      "96 kmader/capsulenet-on-mnist CapsuleNet on MNIST\n",
      "99 alexisbcook/titanic-tutorial Titanic Tutorial\n",
      "111 subinium/simple-matplotlib-visualization-tips Simple Matplotlib & Visualization Tips 💡\n",
      "114 kenjee/titanic-project-example Titanic Project Example\n",
      "115 nareshbhat/outlier-the-silent-killer Outlier!!! The Silent Killer\n",
      "123 dansbecker/handling-missing-values Handling Missing Values\n",
      "124 dansbecker/xgboost XGBoost\n",
      "131 nareshbhat/outlier-the-silent-killer Outlier!!! The Silent Killer\n",
      "143 alexisbcook/one-step-lookahead One-Step Lookahead\n",
      "145 alexisbcook/n-step-lookahead N-Step Lookahead\n",
      "146 brendan45774/connectx-baseline ConnectX Baseline\n",
      "152 yegorbiryukov/cell-swarm Cell Swarm\n",
      "154 jamesmcguigan/connectx-mcts-bitboard-bitsquares-heuristic ConnectX - MCTS Bitboard + Bitsquares Heuristic\n",
      "164 xhlulu/disaster-nlp-keras-bert-using-tfhub Disaster NLP: Keras BERT using TFHub\n",
      "178 samuelcortinhas/spaceship-titanic-a-complete-guide 🚀 Spaceship Titanic: A complete guide 🏆\n",
      "183 arootda/pycaret-visualization-optimization-0-81 🚀[Pycaret] Visualization + Optimization (0.81)\n",
      "191 vicsonsam/sst-eda-17-models-dl-top-7 🚀 SST - 📊 EDA |17 models+DL🤖 🔥 TOP 7% 🔥 \n",
      "220 martinhaha/fastai-cv fastai_cv\n",
      "225 rohandx1996/google-movie-reviews-sentiment-deep-stack-models Google movie reviews sentiment Deep stack models \n",
      "228 xchmiao/popcorn-rnn-model Popcorn RNN model\n",
      "229 harshitmakkar/nlp-word2vec NLP - Word2Vec\n",
      "234 jatinmittal0001/word2vec Word2Vec\n",
      "243 chahat1/data-science-london-classification Data Science London  Classification \n",
      "246 abdelwahed43/data-science-london-classification Data_Science_London_Classification\n",
      "249 zhengkunzhang/simple-gaussian-lgbm-data-science-london Simple Gaussian + LGBM: data-science-london\n",
      "258 ruchibahl18/neural-network-version Neural Network version\n",
      "265 pythonkumar/xgboost-feat-imp-acc-93 XGBoost + Feat Imp Acc:93%\n",
      "266 ragvendrapal/model-training model_training\n"
     ]
    }
   ],
   "source": [
    "for i in df.index :\n",
    "    if detect(df.loc[i]['title']) != 'en':\n",
    "        print(i,df.loc[i]['kernel_ref'],df.loc[i]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the non-english ones after examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel_ref</th>\n",
       "      <th>title</th>\n",
       "      <th>competition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anasofiauzsoy/tutorial-notebook</td>\n",
       "      <td>Tutorial Notebook</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nkitgupta/text-representations</td>\n",
       "      <td>Text-Representations</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rohanrao/tpu-sherlocked-one-stop-for-with-tf</td>\n",
       "      <td>TPU Sherlocked: One-stop for 🤗 with TF</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faressayah/text-analysis-topic-modelling-with-...</td>\n",
       "      <td>Text Analysis|Topic Modelling with spaCy &amp; GENSIM</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vbookshelf/basics-of-bert-and-xlm-roberta-pytorch</td>\n",
       "      <td>Basics of BERT and XLM-RoBERTa - PyTorch</td>\n",
       "      <td>contradictory-my-dear-watson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>rocklen/data-science-london-scikit-learn</td>\n",
       "      <td>🏢 Data Science London + Scikit-learn 🏢</td>\n",
       "      <td>data-science-london-scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>irinana/spam-detection-strata2013after-party</td>\n",
       "      <td>SPAM_Detection  Strata2013After-party</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>nikosavgeros/classification-using-machine-and-...</td>\n",
       "      <td>Classification using Machine and Deep Learning</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>meln1337/just-the-basics-notebook</td>\n",
       "      <td>Just The Basics Notebook</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>pythonkumar/xgboost-feat-imp-acc-93</td>\n",
       "      <td>XGBoost + Feat Imp Acc:93%</td>\n",
       "      <td>just-the-basics-the-after-party</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            kernel_ref  \\\n",
       "0                      anasofiauzsoy/tutorial-notebook   \n",
       "1                       nkitgupta/text-representations   \n",
       "2         rohanrao/tpu-sherlocked-one-stop-for-with-tf   \n",
       "3    faressayah/text-analysis-topic-modelling-with-...   \n",
       "4    vbookshelf/basics-of-bert-and-xlm-roberta-pytorch   \n",
       "..                                                 ...   \n",
       "259           rocklen/data-science-london-scikit-learn   \n",
       "260       irinana/spam-detection-strata2013after-party   \n",
       "261  nikosavgeros/classification-using-machine-and-...   \n",
       "262                  meln1337/just-the-basics-notebook   \n",
       "263                pythonkumar/xgboost-feat-imp-acc-93   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                    Tutorial Notebook   \n",
       "1                                 Text-Representations   \n",
       "2               TPU Sherlocked: One-stop for 🤗 with TF   \n",
       "3    Text Analysis|Topic Modelling with spaCy & GENSIM   \n",
       "4             Basics of BERT and XLM-RoBERTa - PyTorch   \n",
       "..                                                 ...   \n",
       "259             🏢 Data Science London + Scikit-learn 🏢   \n",
       "260              SPAM_Detection  Strata2013After-party   \n",
       "261     Classification using Machine and Deep Learning   \n",
       "262                           Just The Basics Notebook   \n",
       "263                         XGBoost + Feat Imp Acc:93%   \n",
       "\n",
       "                          competition  \n",
       "0        contradictory-my-dear-watson  \n",
       "1        contradictory-my-dear-watson  \n",
       "2        contradictory-my-dear-watson  \n",
       "3        contradictory-my-dear-watson  \n",
       "4        contradictory-my-dear-watson  \n",
       "..                                ...  \n",
       "259  data-science-london-scikit-learn  \n",
       "260   just-the-basics-the-after-party  \n",
       "261   just-the-basics-the-after-party  \n",
       "262   just-the-basics-the-after-party  \n",
       "263   just-the-basics-the-after-party  \n",
       "\n",
       "[264 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([51,52,266], inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now , we have a complete clean list of suitable notebooks .Let's get them now using kaggle API :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index :\n",
    "        try :\n",
    "                api.kernels_pull(df.loc[i]['kernel_ref'], path = DATA_PATH )\n",
    "        except Exception as e:\n",
    "            print('Kaggle API exception : ',df.loc[i]['title'], 'Notebook not found')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5093ef3c9eba5a2350b58945b72c1f122b8b5551b9ae00db57837a16e1175c4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
